2020-03-09 14:55:48,011 maskrcnn_benchmark INFO: Using 2 GPUs
2020-03-09 14:55:48,011 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'False', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'none', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'sum', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'SOLVER.IMS_PER_BATCH', '12', 'TEST.IMS_PER_BATCH', '2', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '50000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', '/home/kaihua/glove', 'MODEL.PRETRAINED_DETECTOR_CKPT', '/home/kaihua/checkpoints/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', '/home/kaihua/checkpoints/upload_causal_motif_sgcls'], skip_test=False)
2020-03-09 14:55:48,011 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-03-09 14:55:49,548 maskrcnn_benchmark INFO: 
PyTorch version: 1.4.0
Is debug build: No
CUDA used to build PyTorch: 10.0

OS: Ubuntu 16.04.5 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: Could not collect

Python version: 3.8
Is CUDA available: Yes
CUDA runtime version: 10.0.130
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti

Nvidia driver version: 415.27
cuDNN version: Could not collect

Versions of relevant libraries:
[pip] numpy==1.18.1
[pip] torch==1.4.0
[pip] torchvision==0.5.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2019.4                      243  
[conda] mkl-service               2.3.0            py38he904b0f_0  
[conda] mkl_fft                   1.0.15           py38ha843d7b_0  
[conda] mkl_random                1.1.0            py38h962f231_0  
[conda] pytorch                   1.4.0           py3.8_cuda10.0.130_cudnn7.6.3_0    pytorch
[conda] torchvision               0.5.0                py38_cu100    pytorch
        Pillow (7.0.0)
2020-03-09 14:55:49,548 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-03-09 14:55:49,548 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-03-09 14:55:49,549 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: /home/kaihua/glove
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: /home/kaihua/checkpoints/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: /home/kaihua/checkpoints/upload_causal_motif_sgcls
PATHS_CATALOG: /data1/kaihua/projects/sgg-test/scene-graph-benchmark/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /data1/kaihua/projects/sgg-test/scene-graph-benchmark/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 12
  MAX_ITER: 50000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-03-09 14:55:49,550 maskrcnn_benchmark INFO: Saving config into: /home/kaihua/checkpoints/upload_causal_motif_sgcls/config.yml
2020-03-09 14:55:49,575 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-03-09 14:55:52,222 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-03-09 14:55:52,222 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-03-09 14:56:17,494 maskrcnn_benchmark.data.build INFO: finish
2020-03-09 14:56:17,494 maskrcnn_benchmark.data.build INFO: Save data statistics to: /home/kaihua/checkpoints/upload_causal_motif_sgcls/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-03-09 14:56:17,494 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-03-09 14:56:18,344 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-03-09 14:56:18,743 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-03-09 14:56:18,767 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-03-09 14:56:18,768 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /home/kaihua/checkpoints/pretrained_faster_rcnn/model_final.pth
2020-03-09 14:56:19,196 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.
2020-03-09 14:56:19,197 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.
2020-03-09 14:56:19,197 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.
2020-03-09 14:56:19,197 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.
2020-03-09 14:56:19,197 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.
2020-03-09 14:56:19,197 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.
2020-03-09 14:56:19,197 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.
2020-03-09 14:56:19,197 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.
2020-03-09 14:56:19,197 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.
2020-03-09 14:56:19,197 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.
2020-03-09 14:56:19,237 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.bias                                           loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2020-03-09 14:56:19,237 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.weight                                         loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.bias                                           loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.weight                                         loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.avg_post_ctx of shape (4096,)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias of shape (3072,)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight of shape (3072, 5136)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight of shape (152, 200)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias of shape (151,)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight of shape (151, 512)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias of shape (2560,)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight of shape (2560, 512)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0 of shape (2048,)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0 of shape (2048,)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0 of shape (2048, 4808)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4808)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias of shape (512,)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight of shape (512, 1024)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias of shape (512,)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight of shape (512, 1024)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0 of shape (2048,)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0 of shape (2048,)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0 of shape (2048, 4424)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4424)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight of shape (151, 200)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight of shape (151, 200)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias of shape (32,)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight of shape (32, 9)
2020-03-09 14:56:19,238 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias of shape (32,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.num_batches_tracked of shape ()
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_mean of shape (32,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_var of shape (32,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight of shape (32,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias of shape (128,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight of shape (128, 32)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_dcd_feat of shape (4936,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_edg_feat of shape (4296,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_obj_feat of shape (4424,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.bias of shape (51,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.weight of shape (51, 4096)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight of shape (22801, 51)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.bias of shape (4096,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.weight of shape (4096, 1024)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.bias of shape (1024,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.weight of shape (1024, 512)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.bias of shape (512,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.weight of shape (512, 32)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.bias of shape (4096,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.weight of shape (4096, 512)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_conv_spt of shape (4096,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_feat of shape (4096,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_spt of shape (32,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.bias of shape (51,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.weight of shape (51, 4096)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                       loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                     loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                       loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                     loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)
2020-03-09 14:56:19,239 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()
2020-03-09 14:56:19,240 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)
2020-03-09 14:56:19,240 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)
2020-03-09 14:56:19,240 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)
2020-03-09 14:56:19,240 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)
2020-03-09 14:56:19,240 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)
2020-03-09 14:56:19,240 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)
2020-03-09 14:56:19,240 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()
2020-03-09 14:56:19,240 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)
2020-03-09 14:56:19,240 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)
2020-03-09 14:56:19,240 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)
2020-03-09 14:56:19,427 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-03-09 14:56:19,438 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-03-09 14:56:21,531 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into /home/kaihua/checkpoints/upload_causal_motif_sgcls/labels.json
2020-03-09 14:56:22,372 maskrcnn_benchmark INFO: #################### end dataloader ####################
2020-03-09 14:56:22,372 maskrcnn_benchmark INFO: Validate before training
2020-03-09 14:56:22,381 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 15:03:25,357 maskrcnn_benchmark INFO: Total run time: 0:07:02.976161 (0.16919046459197998 s / img per device, on 2 devices)
2020-03-09 15:03:25,358 maskrcnn_benchmark INFO: Model inference time: 0:06:26.650878 (0.1546603512763977 s / img per device, on 2 devices)
2020-03-09 15:04:18,269 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.0006
====================================================================================================
SGG eval:   R @ 20: 0.0001;   R @ 50: 0.0001;   R @ 100: 0.0001;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.0001; ngR @ 50: 0.0001; ngR @ 100: 0.0001;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0000;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0000;  mR @ 50: 0.0000;  mR @ 100: 0.0000;  for mode=sgcls, type=Mean Recall.
(above:0.0000) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0000) (attached to:0.0000) (behind:0.0000) (belonging to:0.0000) (between:0.0000) (carrying:0.0000) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.0003) (holding:0.0000) (in:0.0010) (in front of:0.0000) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0000) (of:0.0000) (on:0.0000) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.0000) (says:0.0000) (sitting on:0.0000) (standing on:0.0000) (to:0.0000) (under:0.0000) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.0000) (wears:0.0000) (with:0.0000) 
SGG eval:   A @ 20: 0.0000;   A @ 50: 0.0000;   A @ 100: 0.0000;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 15:04:19,025 maskrcnn_benchmark INFO: Start training
2020-03-09 15:04:20,607 maskrcnn_benchmark INFO: ---Total norm inf clip coef 0.00000-----------------
2020-03-09 15:04:20,618 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: inf, (torch.Size([51]))
2020-03-09 15:04:20,618 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: inf, (torch.Size([51, 4096]))
2020-03-09 15:04:20,618 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: inf, (torch.Size([51]))
2020-03-09 15:04:20,618 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 20.29231, (torch.Size([4096, 4096]))
2020-03-09 15:04:20,618 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 19.67414, (torch.Size([4096, 12544]))
2020-03-09 15:04:20,618 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 4.27845, (torch.Size([256, 1024, 3, 3]))
2020-03-09 15:04:20,618 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 1.78502, (torch.Size([256, 128, 3, 3]))
2020-03-09 15:04:20,618 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 1.17952, (torch.Size([3072, 5136]))
2020-03-09 15:04:20,618 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.94082, (torch.Size([51, 4096]))
2020-03-09 15:04:20,618 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.89104, (torch.Size([4096, 512]))
2020-03-09 15:04:20,618 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.83761, (torch.Size([4096, 4096]))
2020-03-09 15:04:20,618 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.66287, (torch.Size([4096, 12544]))
2020-03-09 15:04:20,618 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.59139, (torch.Size([4096, 1024]))
2020-03-09 15:04:20,618 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.57718, (torch.Size([512, 1024]))
2020-03-09 15:04:20,618 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.52455, (torch.Size([128, 2, 7, 7]))
2020-03-09 15:04:20,618 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.37444, (torch.Size([151, 512]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.30842, (torch.Size([2048, 4808]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.29755, (torch.Size([2048, 4808]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.29184, (torch.Size([512, 32]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.27586, (torch.Size([4096]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.23228, (torch.Size([4096]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.21371, (torch.Size([512]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.15309, (torch.Size([151]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.14960, (torch.Size([256]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.10067, (torch.Size([4096]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.08858, (torch.Size([512]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.08783, (torch.Size([128]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.08021, (torch.Size([512, 1024]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.07914, (torch.Size([256]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.05149, (torch.Size([3072]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.04544, (torch.Size([2048, 512]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.04497, (torch.Size([2048, 512]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.04275, (torch.Size([2048, 4424]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.04135, (torch.Size([2048, 4424]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.03658, (torch.Size([256]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.03486, (torch.Size([2560, 512]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.03479, (torch.Size([4096]))
2020-03-09 15:04:20,619 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.03256, (torch.Size([22801, 51]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.03236, (torch.Size([256]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.03197, (torch.Size([128]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.02960, (torch.Size([128]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.02773, (torch.Size([2048]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.02773, (torch.Size([2048]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.02715, (torch.Size([2048]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.02715, (torch.Size([2048]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02607, (torch.Size([1024, 512]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.02470, (torch.Size([512]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.02170, (torch.Size([1024]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.02093, (torch.Size([2560]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01619, (torch.Size([4096]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.01330, (torch.Size([128, 32]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00702, (torch.Size([32, 9]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00644, (torch.Size([2048, 512]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00631, (torch.Size([2048, 512]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00484, (torch.Size([151, 200]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00475, (torch.Size([4096]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00386, (torch.Size([152, 200]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00340, (torch.Size([151, 200]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00336, (torch.Size([2048]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00336, (torch.Size([2048]))
2020-03-09 15:04:20,620 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00316, (torch.Size([2048]))
2020-03-09 15:04:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00316, (torch.Size([2048]))
2020-03-09 15:04:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00282, (torch.Size([128]))
2020-03-09 15:04:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00162, (torch.Size([32]))
2020-03-09 15:04:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00139, (torch.Size([32]))
2020-03-09 15:04:20,621 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-09 15:04:20,621 maskrcnn_benchmark INFO: -------------------------------
2020-03-09 15:07:50,940 maskrcnn_benchmark INFO: eta: 14:39:26  iter: 200  loss: 2.2718 (3.4265)  auxiliary_ctx: 0.1809 (0.4729)  auxiliary_frq: 0.1954 (0.2118)  auxiliary_vis: 0.1882 (0.3169)  loss_refine_obj: 1.4112 (2.0406)  loss_rel: 0.2826 (0.3844)  time: 1.0713 (1.0596)  data: 0.0108 (0.0132)  lr: 0.054984  max mem: 6243
2020-03-09 15:11:24,839 maskrcnn_benchmark INFO: eta: 14:40:00  iter: 400  loss: 2.3705 (2.8692)  auxiliary_ctx: 0.1889 (0.3350)  auxiliary_frq: 0.2053 (0.2109)  auxiliary_vis: 0.2182 (0.2635)  loss_refine_obj: 1.3702 (1.7076)  loss_rel: 0.3198 (0.3522)  time: 1.0571 (1.0645)  data: 0.0108 (0.0120)  lr: 0.098184  max mem: 6243
2020-03-09 15:14:57,677 maskrcnn_benchmark INFO: eta: 14:36:22  iter: 600  loss: 2.0839 (2.6594)  auxiliary_ctx: 0.1809 (0.2889)  auxiliary_frq: 0.2058 (0.2115)  auxiliary_vis: 0.2039 (0.2473)  loss_refine_obj: 1.2213 (1.5688)  loss_rel: 0.2751 (0.3429)  time: 1.0563 (1.0644)  data: 0.0110 (0.0117)  lr: 0.120000  max mem: 6243
2020-03-09 15:18:29,992 maskrcnn_benchmark INFO: eta: 14:32:14  iter: 800  loss: 1.9368 (2.5193)  auxiliary_ctx: 0.1664 (0.2637)  auxiliary_frq: 0.2062 (0.2118)  auxiliary_vis: 0.1967 (0.2374)  loss_refine_obj: 1.0624 (1.4721)  loss_rel: 0.2578 (0.3343)  time: 1.0652 (1.0637)  data: 0.0090 (0.0112)  lr: 0.120000  max mem: 6243
2020-03-09 15:22:02,533 maskrcnn_benchmark INFO: eta: 14:28:31  iter: 1000  loss: 1.9556 (2.4162)  auxiliary_ctx: 0.1760 (0.2465)  auxiliary_frq: 0.2098 (0.2113)  auxiliary_vis: 0.1867 (0.2292)  loss_refine_obj: 1.1467 (1.4026)  loss_rel: 0.2917 (0.3267)  time: 1.0682 (1.0635)  data: 0.0092 (0.0111)  lr: 0.120000  max mem: 6243
2020-03-09 15:25:34,652 maskrcnn_benchmark INFO: eta: 14:24:35  iter: 1200  loss: 2.0346 (2.3401)  auxiliary_ctx: 0.1598 (0.2348)  auxiliary_frq: 0.2107 (0.2111)  auxiliary_vis: 0.1859 (0.2234)  loss_refine_obj: 1.1321 (1.3502)  loss_rel: 0.2812 (0.3206)  time: 1.0576 (1.0630)  data: 0.0111 (0.0111)  lr: 0.120000  max mem: 6243
2020-03-09 15:29:07,148 maskrcnn_benchmark INFO: eta: 14:20:59  iter: 1400  loss: 1.8936 (2.2843)  auxiliary_ctx: 0.1555 (0.2258)  auxiliary_frq: 0.1999 (0.2110)  auxiliary_vis: 0.1728 (0.2187)  loss_refine_obj: 1.0025 (1.3132)  loss_rel: 0.2426 (0.3156)  time: 1.0516 (1.0629)  data: 0.0113 (0.0111)  lr: 0.120000  max mem: 6243
2020-03-09 15:32:40,322 maskrcnn_benchmark INFO: eta: 14:17:44  iter: 1600  loss: 1.8060 (2.2392)  auxiliary_ctx: 0.1616 (0.2196)  auxiliary_frq: 0.2007 (0.2110)  auxiliary_vis: 0.1813 (0.2157)  loss_refine_obj: 0.9847 (1.2806)  loss_rel: 0.2572 (0.3123)  time: 1.0615 (1.0633)  data: 0.0093 (0.0111)  lr: 0.120000  max mem: 6243
2020-03-09 15:36:13,773 maskrcnn_benchmark INFO: eta: 14:14:32  iter: 1800  loss: 1.7110 (2.2024)  auxiliary_ctx: 0.1527 (0.2142)  auxiliary_frq: 0.1953 (0.2106)  auxiliary_vis: 0.1639 (0.2127)  loss_refine_obj: 0.9393 (1.2557)  loss_rel: 0.2522 (0.3092)  time: 1.0651 (1.0637)  data: 0.0091 (0.0110)  lr: 0.120000  max mem: 6243
2020-03-09 15:39:46,234 maskrcnn_benchmark INFO: eta: 14:10:52  iter: 2000  loss: 1.8756 (2.1706)  auxiliary_ctx: 0.1684 (0.2100)  auxiliary_frq: 0.1977 (0.2106)  auxiliary_vis: 0.1809 (0.2105)  loss_refine_obj: 0.9993 (1.2326)  loss_rel: 0.2675 (0.3068)  time: 1.0452 (1.0636)  data: 0.0109 (0.0110)  lr: 0.120000  max mem: 6259
2020-03-09 15:39:46,236 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgcls/model_0002000.pth
2020-03-09 15:39:47,847 maskrcnn_benchmark INFO: Start validating
2020-03-09 15:39:47,874 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 15:46:55,515 maskrcnn_benchmark INFO: Total run time: 0:07:07.640568 (0.17105622730255127 s / img per device, on 2 devices)
2020-03-09 15:46:55,515 maskrcnn_benchmark INFO: Model inference time: 0:06:29.783458 (0.15591338310241698 s / img per device, on 2 devices)
2020-03-09 15:48:14,399 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5511
====================================================================================================
SGG eval:   R @ 20: 0.3569;   R @ 50: 0.3835;   R @ 100: 0.3907;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4023; ngR @ 50: 0.4701; ngR @ 100: 0.5044;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0207;  zR @ 50: 0.0474;  zR @ 100: 0.0519;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0505;  mR @ 50: 0.0592;  mR @ 100: 0.0628;  for mode=sgcls, type=Mean Recall.
(above:0.0287) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0202) (attached to:0.0000) (behind:0.2873) (belonging to:0.0000) (between:0.0000) (carrying:0.0000) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.4999) (holding:0.2667) (in:0.1490) (in front of:0.0000) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.2823) (of:0.2467) (on:0.5445) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1220) (says:0.0000) (sitting on:0.1094) (standing on:0.0000) (to:0.0000) (under:0.0472) (using:0.0000) (walking in:0.0000) (walking on:0.0401) (watching:0.0000) (wearing:0.4796) (wears:0.0000) (with:0.0156) 
SGG eval:   A @ 20: 0.4202;   A @ 50: 0.4231;   A @ 100: 0.4231;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 15:48:15,023 maskrcnn_benchmark INFO: Validation Result: 0.3907
2020-03-09 15:51:47,511 maskrcnn_benchmark INFO: eta: 17:11:29  iter: 2200  loss: 1.7791 (2.1449)  auxiliary_ctx: 0.1651 (0.2064)  auxiliary_frq: 0.2086 (0.2105)  auxiliary_vis: 0.1959 (0.2085)  loss_refine_obj: 0.9628 (1.2149)  loss_rel: 0.2760 (0.3045)  time: 1.0528 (1.2948)  data: 0.0095 (0.2422)  lr: 0.120000  max mem: 6259
2020-03-09 15:55:19,980 maskrcnn_benchmark INFO: eta: 16:51:48  iter: 2400  loss: 1.8035 (2.1198)  auxiliary_ctx: 0.1683 (0.2031)  auxiliary_frq: 0.2078 (0.2104)  auxiliary_vis: 0.1920 (0.2065)  loss_refine_obj: 0.9309 (1.1978)  loss_rel: 0.2840 (0.3020)  time: 1.0487 (1.2754)  data: 0.0111 (0.2230)  lr: 0.120000  max mem: 6259
2020-03-09 15:58:52,891 maskrcnn_benchmark INFO: eta: 16:34:45  iter: 2600  loss: 1.9577 (2.0989)  auxiliary_ctx: 0.1782 (0.2005)  auxiliary_frq: 0.2131 (0.2103)  auxiliary_vis: 0.1993 (0.2050)  loss_refine_obj: 1.0200 (1.1829)  loss_rel: 0.2854 (0.3002)  time: 1.0524 (1.2592)  data: 0.0112 (0.2066)  lr: 0.120000  max mem: 6259
2020-03-09 16:02:26,576 maskrcnn_benchmark INFO: eta: 16:19:50  iter: 2800  loss: 1.7599 (2.0808)  auxiliary_ctx: 0.1504 (0.1983)  auxiliary_frq: 0.2000 (0.2102)  auxiliary_vis: 0.1641 (0.2037)  loss_refine_obj: 1.0082 (1.1698)  loss_rel: 0.2450 (0.2987)  time: 1.0734 (1.2456)  data: 0.0114 (0.1927)  lr: 0.120000  max mem: 6392
2020-03-09 16:05:58,472 maskrcnn_benchmark INFO: eta: 16:05:57  iter: 3000  loss: 1.8356 (2.0652)  auxiliary_ctx: 0.1605 (0.1965)  auxiliary_frq: 0.2066 (0.2103)  auxiliary_vis: 0.1789 (0.2027)  loss_refine_obj: 0.9663 (1.1582)  loss_rel: 0.2511 (0.2975)  time: 1.0605 (1.2331)  data: 0.0115 (0.1806)  lr: 0.120000  max mem: 6392
2020-03-09 16:09:31,484 maskrcnn_benchmark INFO: eta: 15:53:39  iter: 3200  loss: 1.6957 (2.0497)  auxiliary_ctx: 0.1640 (0.1947)  auxiliary_frq: 0.2078 (0.2102)  auxiliary_vis: 0.1755 (0.2016)  loss_refine_obj: 0.8679 (1.1469)  loss_rel: 0.2547 (0.2962)  time: 1.0664 (1.2226)  data: 0.0108 (0.1700)  lr: 0.120000  max mem: 6392
2020-03-09 16:13:04,024 maskrcnn_benchmark INFO: eta: 15:42:16  iter: 3400  loss: 1.8800 (2.0363)  auxiliary_ctx: 0.1741 (0.1931)  auxiliary_frq: 0.2111 (0.2103)  auxiliary_vis: 0.1908 (0.2006)  loss_refine_obj: 0.8870 (1.1374)  loss_rel: 0.2792 (0.2949)  time: 1.0497 (1.2132)  data: 0.0109 (0.1607)  lr: 0.120000  max mem: 6392
2020-03-09 16:16:37,220 maskrcnn_benchmark INFO: eta: 15:31:54  iter: 3600  loss: 1.8638 (2.0236)  auxiliary_ctx: 0.1637 (0.1917)  auxiliary_frq: 0.2153 (0.2102)  auxiliary_vis: 0.1854 (0.1998)  loss_refine_obj: 0.9274 (1.1282)  loss_rel: 0.2845 (0.2938)  time: 1.0561 (1.2051)  data: 0.0109 (0.1523)  lr: 0.120000  max mem: 6392
2020-03-09 16:20:10,056 maskrcnn_benchmark INFO: eta: 15:22:10  iter: 3800  loss: 1.7507 (2.0115)  auxiliary_ctx: 0.1470 (0.1901)  auxiliary_frq: 0.1986 (0.2099)  auxiliary_vis: 0.1694 (0.1987)  loss_refine_obj: 0.9875 (1.1204)  loss_rel: 0.2380 (0.2923)  time: 1.0493 (1.1976)  data: 0.0106 (0.1449)  lr: 0.120000  max mem: 6392
2020-03-09 16:23:41,482 maskrcnn_benchmark INFO: ---Total norm 2.13904 clip coef 2.33749-----------------
2020-03-09 16:23:41,492 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 1.31853, (torch.Size([4096, 4096]))
2020-03-09 16:23:41,492 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 1.14313, (torch.Size([4096, 12544]))
2020-03-09 16:23:41,492 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.95711, (torch.Size([3072, 5136]))
2020-03-09 16:23:41,492 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.47969, (torch.Size([151, 512]))
2020-03-09 16:23:41,492 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.35021, (torch.Size([4096, 12544]))
2020-03-09 16:23:41,492 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.20817, (torch.Size([256, 1024, 3, 3]))
2020-03-09 16:23:41,492 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.19649, (torch.Size([4096, 4096]))
2020-03-09 16:23:41,492 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.18293, (torch.Size([2560, 512]))
2020-03-09 16:23:41,492 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.16315, (torch.Size([51, 4096]))
2020-03-09 16:23:41,492 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.14913, (torch.Size([51, 4096]))
2020-03-09 16:23:41,492 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.11678, (torch.Size([2048, 4808]))
2020-03-09 16:23:41,492 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.10848, (torch.Size([4096, 1024]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.10296, (torch.Size([2048, 4808]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.08715, (torch.Size([256, 128, 3, 3]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.07739, (torch.Size([512, 32]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.07611, (torch.Size([151, 200]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.07585, (torch.Size([512, 1024]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.07023, (torch.Size([128, 2, 7, 7]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.07019, (torch.Size([2048, 4424]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.06206, (torch.Size([151]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.06048, (torch.Size([4096, 512]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.05413, (torch.Size([2048, 4424]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.04560, (torch.Size([3072]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.04313, (torch.Size([512, 1024]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.03983, (torch.Size([128, 32]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.03669, (torch.Size([32, 9]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.03179, (torch.Size([51]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.03151, (torch.Size([4096]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.03013, (torch.Size([512]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.02882, (torch.Size([152, 200]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.02626, (torch.Size([2560]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.02519, (torch.Size([151, 200]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.01998, (torch.Size([51]))
2020-03-09 16:23:41,493 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01872, (torch.Size([2048, 512]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.01848, (torch.Size([512]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01778, (torch.Size([22801, 51]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01579, (torch.Size([256]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01507, (torch.Size([2048, 512]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.01318, (torch.Size([512]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01295, (torch.Size([4096]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01216, (torch.Size([2048]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01216, (torch.Size([2048]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01207, (torch.Size([2048]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01207, (torch.Size([2048]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.01184, (torch.Size([128]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.01168, (torch.Size([128]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.01112, (torch.Size([4096]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01023, (torch.Size([1024, 512]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00854, (torch.Size([32]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00778, (torch.Size([2048, 512]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00753, (torch.Size([128]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00705, (torch.Size([256]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00705, (torch.Size([32]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00594, (torch.Size([4096]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00546, (torch.Size([2048, 512]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00440, (torch.Size([2048]))
2020-03-09 16:23:41,494 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00440, (torch.Size([2048]))
2020-03-09 16:23:41,495 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00395, (torch.Size([4096]))
2020-03-09 16:23:41,495 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00381, (torch.Size([4096]))
2020-03-09 16:23:41,495 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00364, (torch.Size([128]))
2020-03-09 16:23:41,495 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00356, (torch.Size([1024]))
2020-03-09 16:23:41,495 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00302, (torch.Size([256]))
2020-03-09 16:23:41,495 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00298, (torch.Size([2048]))
2020-03-09 16:23:41,495 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00298, (torch.Size([2048]))
2020-03-09 16:23:41,495 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00203, (torch.Size([256]))
2020-03-09 16:23:41,495 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00002, (torch.Size([32]))
2020-03-09 16:23:41,495 maskrcnn_benchmark INFO: -------------------------------
2020-03-09 16:23:41,498 maskrcnn_benchmark INFO: eta: 15:12:48  iter: 4000  loss: 1.7674 (2.0006)  auxiliary_ctx: 0.1607 (0.1886)  auxiliary_frq: 0.1968 (0.2096)  auxiliary_vis: 0.1660 (0.1976)  loss_refine_obj: 0.9872 (1.1137)  loss_rel: 0.2454 (0.2910)  time: 1.0480 (1.1906)  data: 0.0097 (0.1381)  lr: 0.120000  max mem: 6392
2020-03-09 16:23:41,499 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgcls/model_0004000.pth
2020-03-09 16:23:43,061 maskrcnn_benchmark INFO: Start validating
2020-03-09 16:23:43,072 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 16:30:52,101 maskrcnn_benchmark INFO: Total run time: 0:07:09.028501 (0.1716114005088806 s / img per device, on 2 devices)
2020-03-09 16:30:52,101 maskrcnn_benchmark INFO: Model inference time: 0:06:31.029669 (0.15641186771392823 s / img per device, on 2 devices)
2020-03-09 16:32:09,812 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5449
====================================================================================================
SGG eval:   R @ 20: 0.3553;   R @ 50: 0.3814;   R @ 100: 0.3891;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4066; ngR @ 50: 0.4717; ngR @ 100: 0.5056;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0089;  zR @ 50: 0.0222;  zR @ 100: 0.0296;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0548;  mR @ 50: 0.0650;  mR @ 100: 0.0692;  for mode=sgcls, type=Mean Recall.
(above:0.0372) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2616) (attached to:0.0000) (behind:0.3299) (belonging to:0.0000) (between:0.0000) (carrying:0.0044) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5025) (holding:0.2359) (in:0.1530) (in front of:0.0226) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.2600) (of:0.2207) (on:0.5299) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1801) (says:0.0000) (sitting on:0.1089) (standing on:0.0000) (to:0.0000) (under:0.0787) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.5167) (wears:0.0000) (with:0.0178) 
SGG eval:   A @ 20: 0.4116;   A @ 50: 0.4138;   A @ 100: 0.4138;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 16:32:10,466 maskrcnn_benchmark INFO: Validation Result: 0.3891
2020-03-09 16:35:42,047 maskrcnn_benchmark INFO: eta: 16:36:31  iter: 4200  loss: 1.7774 (1.9906)  auxiliary_ctx: 0.1732 (0.1874)  auxiliary_frq: 0.2115 (0.2095)  auxiliary_vis: 0.1862 (0.1968)  loss_refine_obj: 0.9705 (1.1070)  loss_rel: 0.2968 (0.2899)  time: 1.0605 (1.3055)  data: 0.0113 (0.2533)  lr: 0.120000  max mem: 6392
2020-03-09 16:39:15,805 maskrcnn_benchmark INFO: eta: 16:23:59  iter: 4400  loss: 1.8113 (1.9829)  auxiliary_ctx: 0.1468 (0.1863)  auxiliary_frq: 0.1984 (0.2094)  auxiliary_vis: 0.1750 (0.1960)  loss_refine_obj: 1.0448 (1.1023)  loss_rel: 0.2465 (0.2889)  time: 1.0437 (1.2947)  data: 0.0115 (0.2423)  lr: 0.120000  max mem: 6392
2020-03-09 16:42:47,604 maskrcnn_benchmark INFO: eta: 16:11:55  iter: 4600  loss: 1.8294 (1.9751)  auxiliary_ctx: 0.1659 (0.1854)  auxiliary_frq: 0.2084 (0.2093)  auxiliary_vis: 0.1779 (0.1953)  loss_refine_obj: 1.0162 (1.0970)  loss_rel: 0.2608 (0.2881)  time: 1.0467 (1.2845)  data: 0.0115 (0.2322)  lr: 0.120000  max mem: 6392
2020-03-09 16:46:19,777 maskrcnn_benchmark INFO: eta: 16:00:37  iter: 4800  loss: 1.7475 (1.9674)  auxiliary_ctx: 0.1519 (0.1847)  auxiliary_frq: 0.2033 (0.2094)  auxiliary_vis: 0.1691 (0.1949)  loss_refine_obj: 0.9228 (1.0907)  loss_rel: 0.2480 (0.2878)  time: 1.0608 (1.2752)  data: 0.0117 (0.2230)  lr: 0.120000  max mem: 6392
2020-03-09 16:49:50,240 maskrcnn_benchmark INFO: eta: 15:49:40  iter: 5000  loss: 1.7389 (1.9598)  auxiliary_ctx: 0.1659 (0.1839)  auxiliary_frq: 0.2002 (0.2093)  auxiliary_vis: 0.1683 (0.1944)  loss_refine_obj: 0.9645 (1.0851)  loss_rel: 0.2520 (0.2870)  time: 1.0710 (1.2662)  data: 0.0117 (0.2146)  lr: 0.120000  max mem: 6392
2020-03-09 16:53:21,460 maskrcnn_benchmark INFO: eta: 15:39:25  iter: 5200  loss: 1.7926 (1.9510)  auxiliary_ctx: 0.1571 (0.1830)  auxiliary_frq: 0.2102 (0.2091)  auxiliary_vis: 0.1854 (0.1937)  loss_refine_obj: 0.8933 (1.0793)  loss_rel: 0.2791 (0.2860)  time: 1.0421 (1.2582)  data: 0.0118 (0.2068)  lr: 0.120000  max mem: 6392
2020-03-09 16:56:54,028 maskrcnn_benchmark INFO: eta: 15:29:51  iter: 5400  loss: 1.7223 (1.9447)  auxiliary_ctx: 0.1639 (0.1823)  auxiliary_frq: 0.2107 (0.2091)  auxiliary_vis: 0.1804 (0.1931)  loss_refine_obj: 0.9307 (1.0749)  loss_rel: 0.2725 (0.2853)  time: 1.0614 (1.2509)  data: 0.0113 (0.1995)  lr: 0.120000  max mem: 6392
2020-03-09 17:00:25,998 maskrcnn_benchmark INFO: eta: 15:20:38  iter: 5600  loss: 1.7015 (1.9375)  auxiliary_ctx: 0.1651 (0.1815)  auxiliary_frq: 0.2046 (0.2090)  auxiliary_vis: 0.1715 (0.1925)  loss_refine_obj: 0.9234 (1.0700)  loss_rel: 0.2497 (0.2845)  time: 1.0409 (1.2441)  data: 0.0111 (0.1928)  lr: 0.120000  max mem: 6392
2020-03-09 17:03:57,965 maskrcnn_benchmark INFO: eta: 15:11:48  iter: 5800  loss: 1.8293 (1.9319)  auxiliary_ctx: 0.1578 (0.1809)  auxiliary_frq: 0.2064 (0.2089)  auxiliary_vis: 0.1847 (0.1920)  loss_refine_obj: 1.0240 (1.0663)  loss_rel: 0.2781 (0.2838)  time: 1.0566 (1.2377)  data: 0.0113 (0.1865)  lr: 0.120000  max mem: 6392
2020-03-09 17:07:30,082 maskrcnn_benchmark INFO: eta: 15:03:21  iter: 6000  loss: 1.7710 (1.9262)  auxiliary_ctx: 0.1565 (0.1803)  auxiliary_frq: 0.2041 (0.2089)  auxiliary_vis: 0.1727 (0.1917)  loss_refine_obj: 0.9708 (1.0619)  loss_rel: 0.2671 (0.2834)  time: 1.0532 (1.2318)  data: 0.0112 (0.1807)  lr: 0.120000  max mem: 6392
2020-03-09 17:07:30,084 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgcls/model_0006000.pth
2020-03-09 17:07:31,630 maskrcnn_benchmark INFO: Start validating
2020-03-09 17:07:31,644 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 17:14:41,892 maskrcnn_benchmark INFO: Total run time: 0:07:10.248280 (0.17209931201934814 s / img per device, on 2 devices)
2020-03-09 17:14:41,893 maskrcnn_benchmark INFO: Model inference time: 0:06:31.619475 (0.15664778995513917 s / img per device, on 2 devices)
2020-03-09 17:16:00,563 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5604
====================================================================================================
SGG eval:   R @ 20: 0.3754;   R @ 50: 0.4009;   R @ 100: 0.4083;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4268; ngR @ 50: 0.4929; ngR @ 100: 0.5263;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0222;  zR @ 50: 0.0400;  zR @ 100: 0.0444;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0559;  mR @ 50: 0.0652;  mR @ 100: 0.0692;  for mode=sgcls, type=Mean Recall.
(above:0.0626) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0623) (attached to:0.0000) (behind:0.3430) (belonging to:0.0000) (between:0.0000) (carrying:0.0263) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5037) (holding:0.2885) (in:0.1715) (in front of:0.0070) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3392) (of:0.2339) (on:0.5571) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1086) (says:0.0000) (sitting on:0.1361) (standing on:0.0000) (to:0.0000) (under:0.0336) (using:0.0000) (walking in:0.0000) (walking on:0.0166) (watching:0.0000) (wearing:0.5125) (wears:0.0000) (with:0.0583) 
SGG eval:   A @ 20: 0.4391;   A @ 50: 0.4416;   A @ 100: 0.4416;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 17:16:01,168 maskrcnn_benchmark INFO: Validation Result: 0.4083
2020-03-09 17:19:33,425 maskrcnn_benchmark INFO: eta: 15:55:24  iter: 6200  loss: 1.6651 (1.9205)  auxiliary_ctx: 0.1479 (0.1797)  auxiliary_frq: 0.1978 (0.2088)  auxiliary_vis: 0.1594 (0.1912)  loss_refine_obj: 0.9320 (1.0581)  loss_rel: 0.2034 (0.2827)  time: 1.0708 (1.3088)  data: 0.0115 (0.2576)  lr: 0.120000  max mem: 6430
2020-03-09 17:23:05,689 maskrcnn_benchmark INFO: eta: 15:45:25  iter: 6400  loss: 1.7848 (1.9158)  auxiliary_ctx: 0.1522 (0.1792)  auxiliary_frq: 0.1984 (0.2087)  auxiliary_vis: 0.1614 (0.1908)  loss_refine_obj: 0.9790 (1.0549)  loss_rel: 0.2581 (0.2823)  time: 1.0677 (1.3010)  data: 0.0113 (0.2499)  lr: 0.120000  max mem: 6430
2020-03-09 17:26:38,808 maskrcnn_benchmark INFO: eta: 15:35:55  iter: 6600  loss: 1.6546 (1.9106)  auxiliary_ctx: 0.1472 (0.1786)  auxiliary_frq: 0.1948 (0.2086)  auxiliary_vis: 0.1503 (0.1903)  loss_refine_obj: 0.9004 (1.0516)  loss_rel: 0.2338 (0.2816)  time: 1.0505 (1.2939)  data: 0.0113 (0.2427)  lr: 0.120000  max mem: 6430
2020-03-09 17:30:13,027 maskrcnn_benchmark INFO: eta: 15:26:53  iter: 6800  loss: 1.6497 (1.9052)  auxiliary_ctx: 0.1457 (0.1779)  auxiliary_frq: 0.1888 (0.2084)  auxiliary_vis: 0.1597 (0.1898)  loss_refine_obj: 0.8959 (1.0483)  loss_rel: 0.2152 (0.2808)  time: 1.0803 (1.2874)  data: 0.0114 (0.2359)  lr: 0.120000  max mem: 6430
2020-03-09 17:33:46,705 maskrcnn_benchmark INFO: eta: 15:18:07  iter: 7000  loss: 1.7207 (1.9003)  auxiliary_ctx: 0.1509 (0.1773)  auxiliary_frq: 0.1898 (0.2083)  auxiliary_vis: 0.1629 (0.1893)  loss_refine_obj: 0.9705 (1.0453)  loss_rel: 0.2286 (0.2801)  time: 1.0569 (1.2811)  data: 0.0114 (0.2295)  lr: 0.120000  max mem: 6430
2020-03-09 17:37:20,276 maskrcnn_benchmark INFO: eta: 15:09:37  iter: 7200  loss: 1.8149 (1.8969)  auxiliary_ctx: 0.1706 (0.1769)  auxiliary_frq: 0.2039 (0.2083)  auxiliary_vis: 0.1834 (0.1890)  loss_refine_obj: 1.0243 (1.0429)  loss_rel: 0.2629 (0.2798)  time: 1.0428 (1.2752)  data: 0.0109 (0.2234)  lr: 0.120000  max mem: 6430
2020-03-09 17:40:53,623 maskrcnn_benchmark INFO: eta: 15:01:22  iter: 7400  loss: 1.7921 (1.8933)  auxiliary_ctx: 0.1494 (0.1765)  auxiliary_frq: 0.2106 (0.2082)  auxiliary_vis: 0.1771 (0.1886)  loss_refine_obj: 0.9824 (1.0407)  loss_rel: 0.2559 (0.2792)  time: 1.0402 (1.2695)  data: 0.0113 (0.2177)  lr: 0.120000  max mem: 6430
2020-03-09 17:44:26,700 maskrcnn_benchmark INFO: eta: 14:53:20  iter: 7600  loss: 1.6385 (1.8891)  auxiliary_ctx: 0.1617 (0.1760)  auxiliary_frq: 0.1950 (0.2080)  auxiliary_vis: 0.1756 (0.1882)  loss_refine_obj: 0.8517 (1.0383)  loss_rel: 0.2356 (0.2786)  time: 1.0628 (1.2642)  data: 0.0120 (0.2122)  lr: 0.120000  max mem: 6430
2020-03-09 17:48:00,961 maskrcnn_benchmark INFO: eta: 14:45:39  iter: 7800  loss: 1.6175 (1.8859)  auxiliary_ctx: 0.1408 (0.1756)  auxiliary_frq: 0.1936 (0.2079)  auxiliary_vis: 0.1552 (0.1879)  loss_refine_obj: 0.8883 (1.0363)  loss_rel: 0.2500 (0.2782)  time: 1.0667 (1.2592)  data: 0.0117 (0.2071)  lr: 0.120000  max mem: 6430
2020-03-09 17:51:34,465 maskrcnn_benchmark INFO: ---Total norm 1.24071 clip coef 4.02995-----------------
2020-03-09 17:51:34,475 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.71504, (torch.Size([4096, 4096]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.69217, (torch.Size([4096, 12544]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.49458, (torch.Size([3072, 5136]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.39348, (torch.Size([151, 512]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.15452, (torch.Size([4096, 12544]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.12905, (torch.Size([51, 4096]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.12275, (torch.Size([151, 200]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.11204, (torch.Size([2560, 512]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.10393, (torch.Size([256, 1024, 3, 3]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.08939, (torch.Size([51, 4096]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.08502, (torch.Size([4096, 4096]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.07978, (torch.Size([4096, 1024]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.07957, (torch.Size([512, 32]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.07140, (torch.Size([151]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.06533, (torch.Size([32, 9]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.06147, (torch.Size([2048, 4808]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.06059, (torch.Size([2048, 4808]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.05864, (torch.Size([2048, 4424]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.05296, (torch.Size([3072]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.05134, (torch.Size([4096, 512]))
2020-03-09 17:51:34,476 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.04830, (torch.Size([512, 1024]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.04710, (torch.Size([128, 32]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.03748, (torch.Size([2048, 4424]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.03510, (torch.Size([256, 128, 3, 3]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.03386, (torch.Size([51]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.03031, (torch.Size([152, 200]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.02799, (torch.Size([151, 200]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.02798, (torch.Size([512]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.02744, (torch.Size([128, 2, 7, 7]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.02454, (torch.Size([2560]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.02435, (torch.Size([4096]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.02223, (torch.Size([512]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.02172, (torch.Size([512, 1024]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.01893, (torch.Size([51]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.01783, (torch.Size([32]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.01674, (torch.Size([512]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01435, (torch.Size([2048]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01435, (torch.Size([2048]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01368, (torch.Size([2048, 512]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.01350, (torch.Size([128]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01334, (torch.Size([2048]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01334, (torch.Size([2048]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01292, (torch.Size([1024, 512]))
2020-03-09 17:51:34,477 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01228, (torch.Size([256]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01202, (torch.Size([2048, 512]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.01048, (torch.Size([32]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00969, (torch.Size([22801, 51]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00839, (torch.Size([4096]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00836, (torch.Size([2048, 512]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00726, (torch.Size([256]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00693, (torch.Size([2048]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00693, (torch.Size([2048]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00675, (torch.Size([4096]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00528, (torch.Size([4096]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00493, (torch.Size([1024]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00475, (torch.Size([128]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00403, (torch.Size([128]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00391, (torch.Size([4096]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00377, (torch.Size([2048]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00377, (torch.Size([2048]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00364, (torch.Size([2048, 512]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00239, (torch.Size([128]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00225, (torch.Size([4096]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00152, (torch.Size([256]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00108, (torch.Size([256]))
2020-03-09 17:51:34,478 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00001, (torch.Size([32]))
2020-03-09 17:51:34,479 maskrcnn_benchmark INFO: -------------------------------
2020-03-09 17:51:34,481 maskrcnn_benchmark INFO: eta: 14:38:06  iter: 8000  loss: 1.7773 (1.8825)  auxiliary_ctx: 0.1624 (0.1751)  auxiliary_frq: 0.1931 (0.2078)  auxiliary_vis: 0.1718 (0.1875)  loss_refine_obj: 0.9602 (1.0343)  loss_rel: 0.2553 (0.2777)  time: 1.0575 (1.2544)  data: 0.0113 (0.2022)  lr: 0.120000  max mem: 6430
2020-03-09 17:51:34,483 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgcls/model_0008000.pth
2020-03-09 17:51:35,994 maskrcnn_benchmark INFO: Start validating
2020-03-09 17:51:36,014 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 17:58:48,115 maskrcnn_benchmark INFO: Total run time: 0:07:12.101090 (0.17284043588638306 s / img per device, on 2 devices)
2020-03-09 17:58:48,116 maskrcnn_benchmark INFO: Model inference time: 0:06:33.639043 (0.15745561714172362 s / img per device, on 2 devices)
2020-03-09 18:00:06,019 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5599
====================================================================================================
SGG eval:   R @ 20: 0.3659;   R @ 50: 0.3918;   R @ 100: 0.3992;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4197; ngR @ 50: 0.4852; ngR @ 100: 0.5179;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0178;  zR @ 50: 0.0311;  zR @ 100: 0.0356;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0495;  mR @ 50: 0.0594;  mR @ 100: 0.0637;  for mode=sgcls, type=Mean Recall.
(above:0.0616) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0918) (attached to:0.0000) (behind:0.2681) (belonging to:0.0000) (between:0.0000) (carrying:0.0789) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5132) (holding:0.2616) (in:0.1693) (in front of:0.0318) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.2888) (of:0.1836) (on:0.5626) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.0000) (says:0.0000) (sitting on:0.0911) (standing on:0.0000) (to:0.0000) (under:0.0740) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.4868) (wears:0.0000) (with:0.0233) 
SGG eval:   A @ 20: 0.4298;   A @ 50: 0.4324;   A @ 100: 0.4324;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 18:00:06,639 maskrcnn_benchmark INFO: Validation Result: 0.3992
2020-03-09 18:03:39,308 maskrcnn_benchmark INFO: eta: 15:14:11  iter: 8200  loss: 1.8237 (1.8797)  auxiliary_ctx: 0.1653 (0.1748)  auxiliary_frq: 0.2095 (0.2077)  auxiliary_vis: 0.1941 (0.1873)  loss_refine_obj: 0.9156 (1.0324)  loss_rel: 0.2958 (0.2774)  time: 1.0711 (1.3122)  data: 0.0098 (0.2600)  lr: 0.120000  max mem: 6430
2020-03-09 18:07:13,834 maskrcnn_benchmark INFO: eta: 15:05:51  iter: 8400  loss: 1.6593 (1.8763)  auxiliary_ctx: 0.1468 (0.1743)  auxiliary_frq: 0.1924 (0.2076)  auxiliary_vis: 0.1547 (0.1869)  loss_refine_obj: 0.8691 (1.0307)  loss_rel: 0.2054 (0.2769)  time: 1.0631 (1.3065)  data: 0.0116 (0.2540)  lr: 0.120000  max mem: 6430
2020-03-09 18:10:48,214 maskrcnn_benchmark INFO: eta: 14:57:44  iter: 8600  loss: 1.6999 (1.8733)  auxiliary_ctx: 0.1571 (0.1739)  auxiliary_frq: 0.2090 (0.2075)  auxiliary_vis: 0.1751 (0.1866)  loss_refine_obj: 0.9493 (1.0288)  loss_rel: 0.2645 (0.2765)  time: 1.0538 (1.3011)  data: 0.0114 (0.2484)  lr: 0.120000  max mem: 6430
2020-03-09 18:14:22,333 maskrcnn_benchmark INFO: eta: 14:49:48  iter: 8800  loss: 1.7819 (1.8703)  auxiliary_ctx: 0.1633 (0.1736)  auxiliary_frq: 0.2081 (0.2074)  auxiliary_vis: 0.1802 (0.1863)  loss_refine_obj: 0.9422 (1.0269)  loss_rel: 0.2755 (0.2761)  time: 1.0753 (1.2958)  data: 0.0114 (0.2430)  lr: 0.120000  max mem: 6430
2020-03-09 18:17:56,349 maskrcnn_benchmark INFO: eta: 14:42:03  iter: 9000  loss: 1.6940 (1.8670)  auxiliary_ctx: 0.1435 (0.1733)  auxiliary_frq: 0.1938 (0.2073)  auxiliary_vis: 0.1571 (0.1860)  loss_refine_obj: 0.9259 (1.0247)  loss_rel: 0.2424 (0.2758)  time: 1.0592 (1.2908)  data: 0.0109 (0.2379)  lr: 0.120000  max mem: 6430
2020-03-09 18:21:29,856 maskrcnn_benchmark INFO: eta: 14:34:27  iter: 9200  loss: 1.7366 (1.8641)  auxiliary_ctx: 0.1607 (0.1729)  auxiliary_frq: 0.1989 (0.2071)  auxiliary_vis: 0.1761 (0.1857)  loss_refine_obj: 0.9390 (1.0230)  loss_rel: 0.2228 (0.2753)  time: 1.0632 (1.2860)  data: 0.0113 (0.2329)  lr: 0.120000  max mem: 6430
2020-03-09 18:25:01,858 maskrcnn_benchmark INFO: eta: 14:26:54  iter: 9400  loss: 1.7256 (1.8620)  auxiliary_ctx: 0.1538 (0.1728)  auxiliary_frq: 0.2071 (0.2072)  auxiliary_vis: 0.1710 (0.1857)  loss_refine_obj: 0.8795 (1.0211)  loss_rel: 0.2573 (0.2753)  time: 1.0613 (1.2812)  data: 0.0115 (0.2282)  lr: 0.120000  max mem: 6430
2020-03-09 18:28:34,852 maskrcnn_benchmark INFO: eta: 14:19:36  iter: 9600  loss: 1.7753 (1.8606)  auxiliary_ctx: 0.1792 (0.1726)  auxiliary_frq: 0.2136 (0.2072)  auxiliary_vis: 0.1786 (0.1856)  loss_refine_obj: 0.9531 (1.0201)  loss_rel: 0.2522 (0.2752)  time: 1.0717 (1.2766)  data: 0.0113 (0.2237)  lr: 0.120000  max mem: 6430
2020-03-09 18:32:06,929 maskrcnn_benchmark INFO: eta: 14:12:23  iter: 9800  loss: 1.7533 (1.8580)  auxiliary_ctx: 0.1541 (0.1723)  auxiliary_frq: 0.1986 (0.2071)  auxiliary_vis: 0.1718 (0.1853)  loss_refine_obj: 0.9359 (1.0183)  loss_rel: 0.2565 (0.2749)  time: 1.0447 (1.2722)  data: 0.0114 (0.2194)  lr: 0.120000  max mem: 6430
2020-03-09 18:35:40,553 maskrcnn_benchmark INFO: eta: 14:05:26  iter: 10000  loss: 1.7334 (1.8557)  auxiliary_ctx: 0.1475 (0.1721)  auxiliary_frq: 0.1964 (0.2071)  auxiliary_vis: 0.1659 (0.1851)  loss_refine_obj: 0.8923 (1.0168)  loss_rel: 0.2390 (0.2746)  time: 1.0754 (1.2682)  data: 0.0120 (0.2152)  lr: 0.120000  max mem: 6430
2020-03-09 18:35:40,555 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgcls/model_0010000.pth
2020-03-09 18:35:42,105 maskrcnn_benchmark INFO: Start validating
2020-03-09 18:35:42,119 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 18:42:53,267 maskrcnn_benchmark INFO: Total run time: 0:07:11.148071 (0.1724592282295227 s / img per device, on 2 devices)
2020-03-09 18:42:53,268 maskrcnn_benchmark INFO: Model inference time: 0:06:32.674926 (0.15706997032165526 s / img per device, on 2 devices)
2020-03-09 18:44:11,777 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5617
====================================================================================================
SGG eval:   R @ 20: 0.3750;   R @ 50: 0.4023;   R @ 100: 0.4095;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4256; ngR @ 50: 0.4920; ngR @ 100: 0.5248;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0311;  zR @ 50: 0.0667;  zR @ 100: 0.0696;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0571;  mR @ 50: 0.0661;  mR @ 100: 0.0723;  for mode=sgcls, type=Mean Recall.
(above:0.0855) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0429) (attached to:0.0000) (behind:0.2016) (belonging to:0.0000) (between:0.0000) (carrying:0.0263) (covered in:0.0000) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5093) (holding:0.3374) (in:0.1758) (in front of:0.0173) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3794) (of:0.2271) (on:0.5588) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.0312) (says:0.0000) (sitting on:0.1269) (standing on:0.0000) (to:0.0000) (under:0.0748) (using:0.0000) (walking in:0.0000) (walking on:0.0783) (watching:0.0980) (wearing:0.4957) (wears:0.0000) (with:0.0070) 
SGG eval:   A @ 20: 0.4399;   A @ 50: 0.4422;   A @ 100: 0.4422;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 18:44:12,413 maskrcnn_benchmark INFO: Validation Result: 0.4095
2020-03-09 18:47:44,672 maskrcnn_benchmark INFO: eta: 14:31:48  iter: 10200  loss: 1.6389 (1.8526)  auxiliary_ctx: 0.1538 (0.1718)  auxiliary_frq: 0.1925 (0.2070)  auxiliary_vis: 0.1701 (0.1848)  loss_refine_obj: 0.8773 (1.0146)  loss_rel: 0.2464 (0.2742)  time: 1.0749 (1.3143)  data: 0.0116 (0.2614)  lr: 0.120000  max mem: 6430
2020-03-09 18:51:18,271 maskrcnn_benchmark INFO: eta: 14:24:17  iter: 10400  loss: 1.6325 (1.8497)  auxiliary_ctx: 0.1647 (0.1716)  auxiliary_frq: 0.2003 (0.2069)  auxiliary_vis: 0.1755 (0.1846)  loss_refine_obj: 0.8924 (1.0127)  loss_rel: 0.2291 (0.2739)  time: 1.0472 (1.3095)  data: 0.0109 (0.2566)  lr: 0.120000  max mem: 6430
2020-03-09 18:54:50,903 maskrcnn_benchmark INFO: eta: 14:16:52  iter: 10600  loss: 1.7550 (1.8473)  auxiliary_ctx: 0.1481 (0.1714)  auxiliary_frq: 0.1954 (0.2069)  auxiliary_vis: 0.1723 (0.1844)  loss_refine_obj: 0.9657 (1.0109)  loss_rel: 0.2580 (0.2737)  time: 1.0628 (1.3049)  data: 0.0114 (0.2519)  lr: 0.120000  max mem: 6430
2020-03-09 18:58:25,261 maskrcnn_benchmark INFO: eta: 14:09:42  iter: 10800  loss: 1.7426 (1.8445)  auxiliary_ctx: 0.1580 (0.1711)  auxiliary_frq: 0.1993 (0.2068)  auxiliary_vis: 0.1591 (0.1841)  loss_refine_obj: 0.9074 (1.0093)  loss_rel: 0.2465 (0.2733)  time: 1.0792 (1.3006)  data: 0.0114 (0.2475)  lr: 0.120000  max mem: 6540
2020-03-09 19:01:57,686 maskrcnn_benchmark INFO: eta: 14:02:33  iter: 11000  loss: 1.7315 (1.8429)  auxiliary_ctx: 0.1641 (0.1709)  auxiliary_frq: 0.2002 (0.2068)  auxiliary_vis: 0.1800 (0.1839)  loss_refine_obj: 0.8676 (1.0081)  loss_rel: 0.2686 (0.2732)  time: 1.0569 (1.2962)  data: 0.0109 (0.2432)  lr: 0.120000  max mem: 6540
2020-03-09 19:05:31,070 maskrcnn_benchmark INFO: eta: 13:55:35  iter: 11200  loss: 1.6524 (1.8408)  auxiliary_ctx: 0.1500 (0.1707)  auxiliary_frq: 0.1945 (0.2067)  auxiliary_vis: 0.1673 (0.1837)  loss_refine_obj: 0.9545 (1.0068)  loss_rel: 0.2372 (0.2729)  time: 1.0572 (1.2921)  data: 0.0116 (0.2390)  lr: 0.120000  max mem: 6540
2020-03-09 19:09:04,238 maskrcnn_benchmark INFO: eta: 13:48:43  iter: 11400  loss: 1.7173 (1.8387)  auxiliary_ctx: 0.1524 (0.1705)  auxiliary_frq: 0.2038 (0.2066)  auxiliary_vis: 0.1684 (0.1835)  loss_refine_obj: 0.9199 (1.0056)  loss_rel: 0.2393 (0.2726)  time: 1.0584 (1.2882)  data: 0.0115 (0.2351)  lr: 0.120000  max mem: 6540
2020-03-09 19:12:36,781 maskrcnn_benchmark INFO: eta: 13:41:56  iter: 11600  loss: 1.6186 (1.8373)  auxiliary_ctx: 0.1555 (0.1703)  auxiliary_frq: 0.1975 (0.2065)  auxiliary_vis: 0.1658 (0.1833)  loss_refine_obj: 0.9252 (1.0048)  loss_rel: 0.2469 (0.2724)  time: 1.0601 (1.2843)  data: 0.0106 (0.2312)  lr: 0.120000  max mem: 6540
2020-03-09 19:16:10,978 maskrcnn_benchmark INFO: eta: 13:35:21  iter: 11800  loss: 1.7683 (1.8352)  auxiliary_ctx: 0.1662 (0.1700)  auxiliary_frq: 0.2062 (0.2064)  auxiliary_vis: 0.1762 (0.1831)  loss_refine_obj: 0.9478 (1.0036)  loss_rel: 0.2707 (0.2720)  time: 1.0645 (1.2807)  data: 0.0115 (0.2275)  lr: 0.120000  max mem: 6540
2020-03-09 19:19:45,723 maskrcnn_benchmark INFO: ---Total norm 0.97648 clip coef 5.12045-----------------
2020-03-09 19:19:45,733 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.53638, (torch.Size([4096, 4096]))
2020-03-09 19:19:45,733 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.48472, (torch.Size([4096, 12544]))
2020-03-09 19:19:45,733 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.43704, (torch.Size([3072, 5136]))
2020-03-09 19:19:45,733 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.27288, (torch.Size([151, 512]))
2020-03-09 19:19:45,733 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.18804, (torch.Size([4096, 12544]))
2020-03-09 19:19:45,733 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.12877, (torch.Size([2048, 4808]))
2020-03-09 19:19:45,733 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.12259, (torch.Size([2048, 4808]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.12120, (torch.Size([151, 200]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.11500, (torch.Size([256, 1024, 3, 3]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.10353, (torch.Size([51, 4096]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.09729, (torch.Size([2560, 512]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.09129, (torch.Size([4096, 4096]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.07604, (torch.Size([51, 4096]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.07306, (torch.Size([4096, 1024]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.06675, (torch.Size([512, 32]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.05344, (torch.Size([151]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.05099, (torch.Size([2048, 4424]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.04811, (torch.Size([512, 1024]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.04806, (torch.Size([3072]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.04326, (torch.Size([4096, 512]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.04236, (torch.Size([256, 128, 3, 3]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.03956, (torch.Size([128, 2, 7, 7]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.03427, (torch.Size([2048, 4424]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.03282, (torch.Size([151, 200]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.03206, (torch.Size([128, 32]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.02981, (torch.Size([32, 9]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.02964, (torch.Size([152, 200]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.02840, (torch.Size([512]))
2020-03-09 19:19:45,734 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.02631, (torch.Size([51]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.01917, (torch.Size([2560]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.01897, (torch.Size([512]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01812, (torch.Size([1024, 512]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.01724, (torch.Size([512, 1024]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.01710, (torch.Size([4096]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.01647, (torch.Size([128]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.01563, (torch.Size([32]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01474, (torch.Size([2048]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01474, (torch.Size([2048]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01382, (torch.Size([22801, 51]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.01270, (torch.Size([128]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.01247, (torch.Size([32]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01210, (torch.Size([2048]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01210, (torch.Size([2048]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.01183, (torch.Size([512]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01171, (torch.Size([256]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.01159, (torch.Size([51]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01143, (torch.Size([2048, 512]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00935, (torch.Size([2048, 512]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00793, (torch.Size([128]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00734, (torch.Size([2048, 512]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00725, (torch.Size([2048]))
2020-03-09 19:19:45,735 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00725, (torch.Size([2048]))
2020-03-09 19:19:45,736 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00654, (torch.Size([1024]))
2020-03-09 19:19:45,736 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00647, (torch.Size([4096]))
2020-03-09 19:19:45,736 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00631, (torch.Size([4096]))
2020-03-09 19:19:45,736 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00605, (torch.Size([128]))
2020-03-09 19:19:45,736 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00596, (torch.Size([256]))
2020-03-09 19:19:45,736 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00548, (torch.Size([4096]))
2020-03-09 19:19:45,736 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00439, (torch.Size([2048]))
2020-03-09 19:19:45,736 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00439, (torch.Size([2048]))
2020-03-09 19:19:45,736 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00347, (torch.Size([256]))
2020-03-09 19:19:45,736 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00313, (torch.Size([2048, 512]))
2020-03-09 19:19:45,736 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00267, (torch.Size([4096]))
2020-03-09 19:19:45,736 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00264, (torch.Size([4096]))
2020-03-09 19:19:45,736 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00124, (torch.Size([256]))
2020-03-09 19:19:45,736 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00001, (torch.Size([32]))
2020-03-09 19:19:45,736 maskrcnn_benchmark INFO: -------------------------------
2020-03-09 19:19:45,739 maskrcnn_benchmark INFO: eta: 13:28:54  iter: 12000  loss: 1.6512 (1.8331)  auxiliary_ctx: 0.1421 (0.1698)  auxiliary_frq: 0.1857 (0.2063)  auxiliary_vis: 0.1587 (0.1829)  loss_refine_obj: 0.9426 (1.0025)  loss_rel: 0.2156 (0.2717)  time: 1.0780 (1.2772)  data: 0.0117 (0.2239)  lr: 0.120000  max mem: 6540
2020-03-09 19:19:45,740 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgcls/model_0012000.pth
2020-03-09 19:19:47,298 maskrcnn_benchmark INFO: Start validating
2020-03-09 19:19:47,312 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 19:26:59,523 maskrcnn_benchmark INFO: Total run time: 0:07:12.211068 (0.17288442726135253 s / img per device, on 2 devices)
2020-03-09 19:26:59,523 maskrcnn_benchmark INFO: Model inference time: 0:06:34.680048 (0.15787201919555663 s / img per device, on 2 devices)
2020-03-09 19:28:18,198 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5645
====================================================================================================
SGG eval:   R @ 20: 0.3739;   R @ 50: 0.4015;   R @ 100: 0.4089;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4258; ngR @ 50: 0.4915; ngR @ 100: 0.5240;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0178;  zR @ 50: 0.0422;  zR @ 100: 0.0444;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0615;  mR @ 50: 0.0718;  mR @ 100: 0.0783;  for mode=sgcls, type=Mean Recall.
(above:0.0689) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0404) (attached to:0.0000) (behind:0.2788) (belonging to:0.0000) (between:0.0000) (carrying:0.0132) (covered in:0.0714) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5131) (holding:0.3278) (in:0.1759) (in front of:0.0030) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3321) (of:0.2654) (on:0.5567) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2217) (says:0.0000) (sitting on:0.1086) (standing on:0.0000) (to:0.0000) (under:0.0944) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.1863) (wearing:0.5049) (wears:0.0000) (with:0.0095) 
SGG eval:   A @ 20: 0.4344;   A @ 50: 0.4372;   A @ 100: 0.4372;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 19:28:18,844 maskrcnn_benchmark INFO: Validation Result: 0.4089
2020-03-09 19:31:52,018 maskrcnn_benchmark INFO: eta: 13:48:57  iter: 12200  loss: 1.6180 (1.8315)  auxiliary_ctx: 0.1520 (0.1696)  auxiliary_frq: 0.2045 (0.2062)  auxiliary_vis: 0.1696 (0.1827)  loss_refine_obj: 0.8314 (1.0014)  loss_rel: 0.2546 (0.2715)  time: 1.0646 (1.3158)  data: 0.0117 (0.2624)  lr: 0.120000  max mem: 6540
2020-03-09 19:35:25,784 maskrcnn_benchmark INFO: eta: 13:42:04  iter: 12400  loss: 1.7649 (1.8296)  auxiliary_ctx: 0.1537 (0.1694)  auxiliary_frq: 0.1922 (0.2062)  auxiliary_vis: 0.1571 (0.1826)  loss_refine_obj: 0.9011 (1.0002)  loss_rel: 0.2352 (0.2713)  time: 1.0519 (1.3118)  data: 0.0117 (0.2584)  lr: 0.120000  max mem: 6540
2020-03-09 19:38:58,749 maskrcnn_benchmark INFO: eta: 13:35:15  iter: 12600  loss: 1.6055 (1.8281)  auxiliary_ctx: 0.1484 (0.1693)  auxiliary_frq: 0.1895 (0.2061)  auxiliary_vis: 0.1526 (0.1825)  loss_refine_obj: 0.8683 (0.9989)  loss_rel: 0.2269 (0.2712)  time: 1.0681 (1.3079)  data: 0.0111 (0.2545)  lr: 0.120000  max mem: 6540
2020-03-09 19:42:30,842 maskrcnn_benchmark INFO: eta: 13:28:30  iter: 12800  loss: 1.6297 (1.8265)  auxiliary_ctx: 0.1399 (0.1691)  auxiliary_frq: 0.1842 (0.2060)  auxiliary_vis: 0.1481 (0.1823)  loss_refine_obj: 0.9312 (0.9981)  loss_rel: 0.2103 (0.2710)  time: 1.0586 (1.3040)  data: 0.0111 (0.2507)  lr: 0.120000  max mem: 6540
2020-03-09 19:46:03,171 maskrcnn_benchmark INFO: eta: 13:21:51  iter: 13000  loss: 1.6289 (1.8245)  auxiliary_ctx: 0.1517 (0.1689)  auxiliary_frq: 0.1975 (0.2059)  auxiliary_vis: 0.1543 (0.1821)  loss_refine_obj: 0.8640 (0.9969)  loss_rel: 0.2347 (0.2707)  time: 1.0605 (1.3003)  data: 0.0117 (0.2470)  lr: 0.120000  max mem: 6540
2020-03-09 19:49:35,644 maskrcnn_benchmark INFO: eta: 13:15:19  iter: 13200  loss: 1.8332 (1.8228)  auxiliary_ctx: 0.1543 (0.1687)  auxiliary_frq: 0.1958 (0.2058)  auxiliary_vis: 0.1757 (0.1819)  loss_refine_obj: 0.9774 (0.9960)  loss_rel: 0.2469 (0.2704)  time: 1.0539 (1.2967)  data: 0.0116 (0.2434)  lr: 0.120000  max mem: 6540
2020-03-09 19:53:09,882 maskrcnn_benchmark INFO: eta: 13:08:56  iter: 13400  loss: 1.7349 (1.8211)  auxiliary_ctx: 0.1521 (0.1685)  auxiliary_frq: 0.1992 (0.2057)  auxiliary_vis: 0.1755 (0.1818)  loss_refine_obj: 0.9460 (0.9949)  loss_rel: 0.2409 (0.2702)  time: 1.0582 (1.2933)  data: 0.0116 (0.2400)  lr: 0.120000  max mem: 6540
2020-03-09 19:56:44,645 maskrcnn_benchmark INFO: eta: 13:02:40  iter: 13600  loss: 1.6928 (1.8195)  auxiliary_ctx: 0.1421 (0.1683)  auxiliary_frq: 0.1928 (0.2057)  auxiliary_vis: 0.1638 (0.1816)  loss_refine_obj: 0.9279 (0.9939)  loss_rel: 0.2236 (0.2700)  time: 1.0759 (1.2901)  data: 0.0116 (0.2366)  lr: 0.120000  max mem: 6540
2020-03-09 20:00:17,384 maskrcnn_benchmark INFO: eta: 12:56:23  iter: 13800  loss: 1.6506 (1.8184)  auxiliary_ctx: 0.1528 (0.1682)  auxiliary_frq: 0.1996 (0.2056)  auxiliary_vis: 0.1740 (0.1816)  loss_refine_obj: 0.9046 (0.9931)  loss_rel: 0.2319 (0.2699)  time: 1.0527 (1.2868)  data: 0.0116 (0.2333)  lr: 0.120000  max mem: 6540
2020-03-09 20:03:50,619 maskrcnn_benchmark INFO: eta: 12:50:12  iter: 14000  loss: 1.6505 (1.8169)  auxiliary_ctx: 0.1583 (0.1681)  auxiliary_frq: 0.2012 (0.2056)  auxiliary_vis: 0.1685 (0.1815)  loss_refine_obj: 0.8294 (0.9919)  loss_rel: 0.2510 (0.2698)  time: 1.0767 (1.2837)  data: 0.0115 (0.2302)  lr: 0.120000  max mem: 6540
2020-03-09 20:03:50,621 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgcls/model_0014000.pth
2020-03-09 20:03:52,187 maskrcnn_benchmark INFO: Start validating
2020-03-09 20:03:52,200 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 20:11:04,646 maskrcnn_benchmark INFO: Total run time: 0:07:12.445328 (0.17297813138961793 s / img per device, on 2 devices)
2020-03-09 20:11:04,646 maskrcnn_benchmark INFO: Model inference time: 0:06:33.668447 (0.1574673789024353 s / img per device, on 2 devices)
2020-03-09 20:12:23,885 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5622
====================================================================================================
SGG eval:   R @ 20: 0.3613;   R @ 50: 0.3892;   R @ 100: 0.3978;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4127; ngR @ 50: 0.4766; ngR @ 100: 0.5110;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0222;  zR @ 50: 0.0489;  zR @ 100: 0.0533;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0559;  mR @ 50: 0.0655;  mR @ 100: 0.0725;  for mode=sgcls, type=Mean Recall.
(above:0.0659) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0328) (attached to:0.0000) (behind:0.3178) (belonging to:0.0000) (between:0.0000) (carrying:0.0000) (covered in:0.0000) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5048) (holding:0.3081) (in:0.1633) (in front of:0.0203) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3117) (of:0.2186) (on:0.5455) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2217) (says:0.0000) (sitting on:0.1251) (standing on:0.0000) (to:0.0000) (under:0.0621) (using:0.0000) (walking in:0.0000) (walking on:0.0187) (watching:0.0392) (wearing:0.5022) (wears:0.0000) (with:0.0248) 
SGG eval:   A @ 20: 0.4250;   A @ 50: 0.4278;   A @ 100: 0.4278;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 20:12:24,500 maskrcnn_benchmark INFO: Validation Result: 0.3978
2020-03-09 20:12:24,500 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-03-09 20:15:57,478 maskrcnn_benchmark INFO: eta: 13:05:41  iter: 14200  loss: 1.6554 (1.8149)  auxiliary_ctx: 0.1542 (0.1679)  auxiliary_frq: 0.1958 (0.2055)  auxiliary_vis: 0.1631 (0.1813)  loss_refine_obj: 0.9074 (0.9906)  loss_rel: 0.2364 (0.2695)  time: 1.0580 (1.3168)  data: 0.0111 (0.2633)  lr: 0.012000  max mem: 6540
2020-03-09 20:19:31,648 maskrcnn_benchmark INFO: eta: 12:59:16  iter: 14400  loss: 1.6869 (1.8122)  auxiliary_ctx: 0.1455 (0.1677)  auxiliary_frq: 0.1914 (0.2054)  auxiliary_vis: 0.1553 (0.1810)  loss_refine_obj: 0.9814 (0.9889)  loss_rel: 0.2295 (0.2692)  time: 1.0786 (1.3134)  data: 0.0110 (0.2598)  lr: 0.012000  max mem: 6540
2020-03-09 20:23:04,337 maskrcnn_benchmark INFO: eta: 12:52:52  iter: 14600  loss: 1.4337 (1.8096)  auxiliary_ctx: 0.1408 (0.1675)  auxiliary_frq: 0.1907 (0.2054)  auxiliary_vis: 0.1489 (0.1808)  loss_refine_obj: 0.7545 (0.9870)  loss_rel: 0.2057 (0.2689)  time: 1.0668 (1.3100)  data: 0.0107 (0.2564)  lr: 0.012000  max mem: 6540
2020-03-09 20:26:37,821 maskrcnn_benchmark INFO: eta: 12:46:34  iter: 14800  loss: 1.5716 (1.8068)  auxiliary_ctx: 0.1495 (0.1672)  auxiliary_frq: 0.1984 (0.2053)  auxiliary_vis: 0.1605 (0.1805)  loss_refine_obj: 0.7939 (0.9852)  loss_rel: 0.2498 (0.2685)  time: 1.0677 (1.3067)  data: 0.0114 (0.2531)  lr: 0.012000  max mem: 6540
2020-03-09 20:30:11,408 maskrcnn_benchmark INFO: eta: 12:40:22  iter: 15000  loss: 1.5031 (1.8039)  auxiliary_ctx: 0.1532 (0.1670)  auxiliary_frq: 0.2001 (0.2053)  auxiliary_vis: 0.1660 (0.1803)  loss_refine_obj: 0.7648 (0.9832)  loss_rel: 0.2304 (0.2682)  time: 1.0645 (1.3035)  data: 0.0118 (0.2498)  lr: 0.012000  max mem: 6540
2020-03-09 20:33:45,807 maskrcnn_benchmark INFO: eta: 12:34:15  iter: 15200  loss: 1.5323 (1.8007)  auxiliary_ctx: 0.1424 (0.1668)  auxiliary_frq: 0.1896 (0.2052)  auxiliary_vis: 0.1551 (0.1800)  loss_refine_obj: 0.8178 (0.9810)  loss_rel: 0.2133 (0.2678)  time: 1.0714 (1.3004)  data: 0.0114 (0.2467)  lr: 0.012000  max mem: 6540
2020-03-09 20:37:20,580 maskrcnn_benchmark INFO: eta: 12:28:13  iter: 15400  loss: 1.5346 (1.7975)  auxiliary_ctx: 0.1395 (0.1666)  auxiliary_frq: 0.1861 (0.2051)  auxiliary_vis: 0.1414 (0.1797)  loss_refine_obj: 0.8323 (0.9788)  loss_rel: 0.2029 (0.2674)  time: 1.0778 (1.2975)  data: 0.0116 (0.2437)  lr: 0.012000  max mem: 6540
2020-03-09 20:40:54,321 maskrcnn_benchmark INFO: eta: 12:22:13  iter: 15600  loss: 1.4330 (1.7945)  auxiliary_ctx: 0.1491 (0.1664)  auxiliary_frq: 0.1882 (0.2050)  auxiliary_vis: 0.1544 (0.1794)  loss_refine_obj: 0.7731 (0.9766)  loss_rel: 0.2206 (0.2671)  time: 1.0661 (1.2946)  data: 0.0117 (0.2407)  lr: 0.012000  max mem: 6540
2020-03-09 20:44:28,211 maskrcnn_benchmark INFO: eta: 12:16:16  iter: 15800  loss: 1.5574 (1.7916)  auxiliary_ctx: 0.1379 (0.1662)  auxiliary_frq: 0.1923 (0.2050)  auxiliary_vis: 0.1534 (0.1792)  loss_refine_obj: 0.7732 (0.9744)  loss_rel: 0.2226 (0.2667)  time: 1.0727 (1.2917)  data: 0.0118 (0.2378)  lr: 0.012000  max mem: 6540
2020-03-09 20:48:01,652 maskrcnn_benchmark INFO: ---Total norm 1.50425 clip coef 3.32391-----------------
2020-03-09 20:48:01,662 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.72514, (torch.Size([4096, 12544]))
2020-03-09 20:48:01,662 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.67066, (torch.Size([4096, 4096]))
2020-03-09 20:48:01,662 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.57096, (torch.Size([4096, 12544]))
2020-03-09 20:48:01,662 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.46296, (torch.Size([3072, 5136]))
2020-03-09 20:48:01,662 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.42839, (torch.Size([256, 1024, 3, 3]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.32687, (torch.Size([151, 512]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.27187, (torch.Size([4096, 4096]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.24104, (torch.Size([512, 32]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.23742, (torch.Size([51, 4096]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.23604, (torch.Size([51, 4096]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.17809, (torch.Size([151, 200]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.16797, (torch.Size([4096, 1024]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.16611, (torch.Size([2048, 4808]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.14776, (torch.Size([4096, 512]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.13002, (torch.Size([2048, 4808]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.11651, (torch.Size([2560, 512]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.10906, (torch.Size([256, 128, 3, 3]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.09788, (torch.Size([128, 2, 7, 7]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.07278, (torch.Size([3072]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.06924, (torch.Size([512, 1024]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.06595, (torch.Size([512]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.06587, (torch.Size([2048, 4424]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.05634, (torch.Size([151, 200]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.05550, (torch.Size([151]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.05394, (torch.Size([51]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.04624, (torch.Size([4096]))
2020-03-09 20:48:01,663 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.04421, (torch.Size([32, 9]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.04165, (torch.Size([2048, 4424]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.04009, (torch.Size([152, 200]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.04008, (torch.Size([512]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.03994, (torch.Size([512, 1024]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.03983, (torch.Size([51]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.03708, (torch.Size([1024, 512]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.03232, (torch.Size([256]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.03118, (torch.Size([128, 32]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.02556, (torch.Size([22801, 51]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.02362, (torch.Size([512]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.02255, (torch.Size([2560]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.02122, (torch.Size([128]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.02120, (torch.Size([2048, 512]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.02092, (torch.Size([32]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.02046, (torch.Size([4096]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.02004, (torch.Size([128]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.01971, (torch.Size([128]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.01916, (torch.Size([256]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01902, (torch.Size([2048]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01902, (torch.Size([2048]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01694, (torch.Size([4096]))
2020-03-09 20:48:01,664 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01644, (torch.Size([2048]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01644, (torch.Size([2048]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01549, (torch.Size([2048, 512]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01201, (torch.Size([1024]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.01160, (torch.Size([2048, 512]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01100, (torch.Size([4096]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.01089, (torch.Size([2048]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.01089, (torch.Size([2048]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.01088, (torch.Size([32]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00959, (torch.Size([256]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00883, (torch.Size([128]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00730, (torch.Size([4096]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00486, (torch.Size([2048, 512]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00411, (torch.Size([256]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00405, (torch.Size([2048]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00405, (torch.Size([2048]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00400, (torch.Size([4096]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00001, (torch.Size([32]))
2020-03-09 20:48:01,665 maskrcnn_benchmark INFO: -------------------------------
2020-03-09 20:48:01,668 maskrcnn_benchmark INFO: eta: 12:10:23  iter: 16000  loss: 1.5744 (1.7892)  auxiliary_ctx: 0.1352 (0.1660)  auxiliary_frq: 0.1912 (0.2050)  auxiliary_vis: 0.1469 (0.1790)  loss_refine_obj: 0.8582 (0.9726)  loss_rel: 0.2220 (0.2665)  time: 1.0825 (1.2889)  data: 0.0112 (0.2349)  lr: 0.012000  max mem: 6540
2020-03-09 20:48:01,670 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgcls/model_0016000.pth
2020-03-09 20:48:03,208 maskrcnn_benchmark INFO: Start validating
2020-03-09 20:48:03,221 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 20:55:15,558 maskrcnn_benchmark INFO: Total run time: 0:07:12.336057 (0.17293442287445068 s / img per device, on 2 devices)
2020-03-09 20:55:15,558 maskrcnn_benchmark INFO: Model inference time: 0:06:34.870331 (0.15794813222885132 s / img per device, on 2 devices)
2020-03-09 20:56:35,976 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5887
====================================================================================================
SGG eval:   R @ 20: 0.3897;   R @ 50: 0.4179;   R @ 100: 0.4262;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4455; ngR @ 50: 0.5126; ngR @ 100: 0.5478;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0289;  zR @ 50: 0.0830;  zR @ 100: 0.0874;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0650;  mR @ 50: 0.0760;  mR @ 100: 0.0831;  for mode=sgcls, type=Mean Recall.
(above:0.0989) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0530) (attached to:0.0000) (behind:0.3335) (belonging to:0.0000) (between:0.0000) (carrying:0.0175) (covered in:0.0714) (covering:0.0000) (eating:0.2143) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5357) (holding:0.3196) (in:0.1787) (in front of:0.0377) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3379) (of:0.2474) (on:0.5856) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1830) (says:0.0000) (sitting on:0.1304) (standing on:0.0000) (to:0.0000) (under:0.0927) (using:0.0000) (walking in:0.0000) (walking on:0.0296) (watching:0.1373) (wearing:0.5247) (wears:0.0000) (with:0.0263) 
SGG eval:   A @ 20: 0.4509;   A @ 50: 0.4541;   A @ 100: 0.4541;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 20:56:36,608 maskrcnn_benchmark INFO: Validation Result: 0.4262
2020-03-09 21:00:09,582 maskrcnn_benchmark INFO: eta: 12:22:26  iter: 16200  loss: 1.4706 (1.7868)  auxiliary_ctx: 0.1481 (0.1659)  auxiliary_frq: 0.1932 (0.2050)  auxiliary_vis: 0.1469 (0.1788)  loss_refine_obj: 0.8110 (0.9707)  loss_rel: 0.2030 (0.2663)  time: 1.0607 (1.3179)  data: 0.0110 (0.2640)  lr: 0.012000  max mem: 6540
2020-03-09 21:03:42,299 maskrcnn_benchmark INFO: eta: 12:16:18  iter: 16400  loss: 1.5642 (1.7842)  auxiliary_ctx: 0.1551 (0.1658)  auxiliary_frq: 0.2043 (0.2050)  auxiliary_vis: 0.1600 (0.1786)  loss_refine_obj: 0.7545 (0.9687)  loss_rel: 0.2387 (0.2661)  time: 1.0491 (1.3148)  data: 0.0113 (0.2609)  lr: 0.012000  max mem: 6540
2020-03-09 21:07:16,045 maskrcnn_benchmark INFO: eta: 12:10:16  iter: 16600  loss: 1.5241 (1.7814)  auxiliary_ctx: 0.1547 (0.1656)  auxiliary_frq: 0.2057 (0.2049)  auxiliary_vis: 0.1593 (0.1784)  loss_refine_obj: 0.7629 (0.9667)  loss_rel: 0.2335 (0.2658)  time: 1.0596 (1.3119)  data: 0.0115 (0.2579)  lr: 0.012000  max mem: 6540
2020-03-09 21:10:49,783 maskrcnn_benchmark INFO: eta: 12:04:17  iter: 16800  loss: 1.4912 (1.7785)  auxiliary_ctx: 0.1530 (0.1654)  auxiliary_frq: 0.2073 (0.2049)  auxiliary_vis: 0.1631 (0.1781)  loss_refine_obj: 0.7761 (0.9646)  loss_rel: 0.2345 (0.2654)  time: 1.0590 (1.3090)  data: 0.0116 (0.2549)  lr: 0.012000  max mem: 6540
2020-03-09 21:14:24,388 maskrcnn_benchmark INFO: eta: 11:58:24  iter: 17000  loss: 1.5619 (1.7757)  auxiliary_ctx: 0.1417 (0.1652)  auxiliary_frq: 0.1959 (0.2049)  auxiliary_vis: 0.1457 (0.1779)  loss_refine_obj: 0.7955 (0.9626)  loss_rel: 0.2031 (0.2651)  time: 1.0728 (1.3062)  data: 0.0117 (0.2521)  lr: 0.012000  max mem: 6540
2020-03-09 21:17:59,220 maskrcnn_benchmark INFO: eta: 11:52:34  iter: 17200  loss: 1.4259 (1.7728)  auxiliary_ctx: 0.1502 (0.1650)  auxiliary_frq: 0.1941 (0.2048)  auxiliary_vis: 0.1530 (0.1777)  loss_refine_obj: 0.7023 (0.9605)  loss_rel: 0.2304 (0.2648)  time: 1.0747 (1.3035)  data: 0.0113 (0.2493)  lr: 0.012000  max mem: 6540
2020-03-09 21:21:34,364 maskrcnn_benchmark INFO: eta: 11:46:48  iter: 17400  loss: 1.5390 (1.7701)  auxiliary_ctx: 0.1451 (0.1648)  auxiliary_frq: 0.1882 (0.2047)  auxiliary_vis: 0.1559 (0.1774)  loss_refine_obj: 0.8328 (0.9587)  loss_rel: 0.2231 (0.2645)  time: 1.0698 (1.3009)  data: 0.0116 (0.2465)  lr: 0.012000  max mem: 6540
2020-03-09 21:25:08,419 maskrcnn_benchmark INFO: eta: 11:41:03  iter: 17600  loss: 1.5332 (1.7674)  auxiliary_ctx: 0.1549 (0.1646)  auxiliary_frq: 0.2002 (0.2047)  auxiliary_vis: 0.1571 (0.1772)  loss_refine_obj: 0.8161 (0.9568)  loss_rel: 0.2270 (0.2642)  time: 1.0640 (1.2983)  data: 0.0111 (0.2439)  lr: 0.012000  max mem: 6540
2020-03-09 21:28:43,389 maskrcnn_benchmark INFO: eta: 11:35:23  iter: 17800  loss: 1.4844 (1.7649)  auxiliary_ctx: 0.1543 (0.1644)  auxiliary_frq: 0.2004 (0.2046)  auxiliary_vis: 0.1568 (0.1769)  loss_refine_obj: 0.7460 (0.9551)  loss_rel: 0.2279 (0.2638)  time: 1.0667 (1.2958)  data: 0.0113 (0.2412)  lr: 0.012000  max mem: 6540
2020-03-09 21:32:17,088 maskrcnn_benchmark INFO: eta: 11:29:43  iter: 18000  loss: 1.4361 (1.7624)  auxiliary_ctx: 0.1434 (0.1643)  auxiliary_frq: 0.1972 (0.2045)  auxiliary_vis: 0.1535 (0.1767)  loss_refine_obj: 0.7265 (0.9534)  loss_rel: 0.2304 (0.2636)  time: 1.0611 (1.2932)  data: 0.0102 (0.2387)  lr: 0.012000  max mem: 6540
2020-03-09 21:32:17,090 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgcls/model_0018000.pth
2020-03-09 21:32:18,641 maskrcnn_benchmark INFO: Start validating
2020-03-09 21:32:18,660 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 21:39:30,282 maskrcnn_benchmark INFO: Total run time: 0:07:11.621447 (0.17264857864379882 s / img per device, on 2 devices)
2020-03-09 21:39:30,282 maskrcnn_benchmark INFO: Model inference time: 0:06:34.316919 (0.15772676753997802 s / img per device, on 2 devices)
2020-03-09 21:40:50,187 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5926
====================================================================================================
SGG eval:   R @ 20: 0.3927;   R @ 50: 0.4210;   R @ 100: 0.4292;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4484; ngR @ 50: 0.5169; ngR @ 100: 0.5517;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0244;  zR @ 50: 0.0533;  zR @ 100: 0.0556;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0674;  mR @ 50: 0.0794;  mR @ 100: 0.0864;  for mode=sgcls, type=Mean Recall.
(above:0.0883) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0530) (attached to:0.0000) (behind:0.3190) (belonging to:0.0000) (between:0.0000) (carrying:0.1491) (covered in:0.0714) (covering:0.0000) (eating:0.2143) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5322) (holding:0.2996) (in:0.1819) (in front of:0.0423) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3530) (of:0.2854) (on:0.5824) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2515) (says:0.0000) (sitting on:0.1164) (standing on:0.0000) (to:0.0000) (under:0.0978) (using:0.0000) (walking in:0.0000) (walking on:0.0104) (watching:0.1176) (wearing:0.5289) (wears:0.0000) (with:0.0230) 
SGG eval:   A @ 20: 0.4535;   A @ 50: 0.4568;   A @ 100: 0.4568;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 21:40:50,793 maskrcnn_benchmark INFO: Validation Result: 0.4292
2020-03-09 21:44:22,919 maskrcnn_benchmark INFO: eta: 11:39:00  iter: 18200  loss: 1.5228 (1.7602)  auxiliary_ctx: 0.1513 (0.1641)  auxiliary_frq: 0.1942 (0.2045)  auxiliary_vis: 0.1544 (0.1766)  loss_refine_obj: 0.7359 (0.9516)  loss_rel: 0.2137 (0.2633)  time: 1.0551 (1.3189)  data: 0.0115 (0.2644)  lr: 0.012000  max mem: 6540
2020-03-09 21:47:56,353 maskrcnn_benchmark INFO: eta: 11:33:10  iter: 18400  loss: 1.4246 (1.7576)  auxiliary_ctx: 0.1441 (0.1639)  auxiliary_frq: 0.1928 (0.2044)  auxiliary_vis: 0.1473 (0.1763)  loss_refine_obj: 0.7090 (0.9498)  loss_rel: 0.2141 (0.2631)  time: 1.0637 (1.3162)  data: 0.0101 (0.2616)  lr: 0.012000  max mem: 6540
2020-03-09 21:51:31,057 maskrcnn_benchmark INFO: eta: 11:27:25  iter: 18600  loss: 1.4907 (1.7553)  auxiliary_ctx: 0.1301 (0.1638)  auxiliary_frq: 0.1930 (0.2044)  auxiliary_vis: 0.1446 (0.1761)  loss_refine_obj: 0.8208 (0.9483)  loss_rel: 0.2059 (0.2627)  time: 1.0668 (1.3135)  data: 0.0117 (0.2590)  lr: 0.012000  max mem: 6540
2020-03-09 21:55:05,403 maskrcnn_benchmark INFO: eta: 11:21:42  iter: 18800  loss: 1.5239 (1.7531)  auxiliary_ctx: 0.1542 (0.1636)  auxiliary_frq: 0.2120 (0.2044)  auxiliary_vis: 0.1561 (0.1760)  loss_refine_obj: 0.7906 (0.9466)  loss_rel: 0.2517 (0.2626)  time: 1.0844 (1.3110)  data: 0.0118 (0.2563)  lr: 0.012000  max mem: 6540
2020-03-09 21:58:39,746 maskrcnn_benchmark INFO: eta: 11:16:02  iter: 19000  loss: 1.4968 (1.7509)  auxiliary_ctx: 0.1341 (0.1635)  auxiliary_frq: 0.1905 (0.2043)  auxiliary_vis: 0.1475 (0.1758)  loss_refine_obj: 0.8035 (0.9450)  loss_rel: 0.2125 (0.2623)  time: 1.0741 (1.3085)  data: 0.0118 (0.2537)  lr: 0.012000  max mem: 6540
2020-03-09 22:02:14,007 maskrcnn_benchmark INFO: eta: 11:10:24  iter: 19200  loss: 1.5556 (1.7489)  auxiliary_ctx: 0.1332 (0.1634)  auxiliary_frq: 0.1969 (0.2043)  auxiliary_vis: 0.1437 (0.1756)  loss_refine_obj: 0.8338 (0.9435)  loss_rel: 0.2342 (0.2621)  time: 1.0637 (1.3060)  data: 0.0122 (0.2512)  lr: 0.012000  max mem: 6540
2020-03-09 22:05:46,715 maskrcnn_benchmark INFO: eta: 11:04:46  iter: 19400  loss: 1.5235 (1.7462)  auxiliary_ctx: 0.1549 (0.1632)  auxiliary_frq: 0.1981 (0.2043)  auxiliary_vis: 0.1547 (0.1754)  loss_refine_obj: 0.7780 (0.9416)  loss_rel: 0.2411 (0.2618)  time: 1.0626 (1.3035)  data: 0.0122 (0.2488)  lr: 0.012000  max mem: 6540
2020-03-09 22:09:20,457 maskrcnn_benchmark INFO: eta: 10:59:13  iter: 19600  loss: 1.4500 (1.7436)  auxiliary_ctx: 0.1494 (0.1630)  auxiliary_frq: 0.2057 (0.2042)  auxiliary_vis: 0.1551 (0.1751)  loss_refine_obj: 0.7292 (0.9398)  loss_rel: 0.2196 (0.2614)  time: 1.0561 (1.3011)  data: 0.0111 (0.2463)  lr: 0.012000  max mem: 6540
2020-03-09 22:12:54,919 maskrcnn_benchmark INFO: eta: 10:53:43  iter: 19800  loss: 1.4274 (1.7407)  auxiliary_ctx: 0.1263 (0.1628)  auxiliary_frq: 0.1893 (0.2041)  auxiliary_vis: 0.1320 (0.1749)  loss_refine_obj: 0.7174 (0.9377)  loss_rel: 0.1922 (0.2611)  time: 1.0633 (1.2988)  data: 0.0101 (0.2440)  lr: 0.012000  max mem: 6540
2020-03-09 22:16:27,571 maskrcnn_benchmark INFO: ---Total norm 1.42312 clip coef 3.51340-----------------
2020-03-09 22:16:27,581 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.84251, (torch.Size([4096, 12544]))
2020-03-09 22:16:27,581 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.81224, (torch.Size([4096, 4096]))
2020-03-09 22:16:27,581 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.59628, (torch.Size([3072, 5136]))
2020-03-09 22:16:27,581 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.33410, (torch.Size([151, 512]))
2020-03-09 22:16:27,581 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.23751, (torch.Size([4096, 12544]))
2020-03-09 22:16:27,581 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.14200, (torch.Size([256, 1024, 3, 3]))
2020-03-09 22:16:27,581 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.11762, (torch.Size([4096, 4096]))
2020-03-09 22:16:27,581 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.11158, (torch.Size([2560, 512]))
2020-03-09 22:16:27,581 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.10777, (torch.Size([151, 200]))
2020-03-09 22:16:27,581 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.09944, (torch.Size([51, 4096]))
2020-03-09 22:16:27,581 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.09936, (torch.Size([51, 4096]))
2020-03-09 22:16:27,581 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.09257, (torch.Size([2048, 4808]))
2020-03-09 22:16:27,581 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.09123, (torch.Size([2048, 4424]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.07385, (torch.Size([4096, 1024]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.07004, (torch.Size([2048, 4808]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.05561, (torch.Size([256, 128, 3, 3]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.05208, (torch.Size([2048, 4424]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.05144, (torch.Size([4096, 512]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.05117, (torch.Size([512, 32]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.05081, (torch.Size([151]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.04995, (torch.Size([128, 2, 7, 7]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.04418, (torch.Size([3072]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.03228, (torch.Size([32, 9]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.03193, (torch.Size([512, 1024]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.02770, (torch.Size([512, 1024]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.02621, (torch.Size([152, 200]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.02530, (torch.Size([128, 32]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.02175, (torch.Size([151, 200]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01908, (torch.Size([1024, 512]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.01892, (torch.Size([2560]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01787, (torch.Size([512]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.01758, (torch.Size([512]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.01580, (torch.Size([51]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01443, (torch.Size([22801, 51]))
2020-03-09 22:16:27,582 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01429, (torch.Size([128]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01322, (torch.Size([256]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.01320, (torch.Size([51]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.01304, (torch.Size([128]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.01287, (torch.Size([4096]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01249, (torch.Size([4096]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.01209, (torch.Size([512]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.01163, (torch.Size([32]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.01108, (torch.Size([2048, 512]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.01073, (torch.Size([32]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01063, (torch.Size([2048, 512]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00885, (torch.Size([2048]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00885, (torch.Size([2048]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00881, (torch.Size([256]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00850, (torch.Size([4096]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00777, (torch.Size([2048]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00777, (torch.Size([2048]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00770, (torch.Size([4096]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00769, (torch.Size([2048, 512]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00731, (torch.Size([128]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00697, (torch.Size([1024]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00693, (torch.Size([2048]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00693, (torch.Size([2048]))
2020-03-09 22:16:27,583 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00538, (torch.Size([128]))
2020-03-09 22:16:27,584 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00436, (torch.Size([2048, 512]))
2020-03-09 22:16:27,584 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00432, (torch.Size([4096]))
2020-03-09 22:16:27,584 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00400, (torch.Size([256]))
2020-03-09 22:16:27,584 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00309, (torch.Size([4096]))
2020-03-09 22:16:27,584 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00308, (torch.Size([2048]))
2020-03-09 22:16:27,584 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00308, (torch.Size([2048]))
2020-03-09 22:16:27,584 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00141, (torch.Size([256]))
2020-03-09 22:16:27,584 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00001, (torch.Size([32]))
2020-03-09 22:16:27,584 maskrcnn_benchmark INFO: -------------------------------
2020-03-09 22:16:27,587 maskrcnn_benchmark INFO: eta: 10:48:12  iter: 20000  loss: 1.3631 (1.7383)  auxiliary_ctx: 0.1268 (0.1627)  auxiliary_frq: 0.1818 (0.2041)  auxiliary_vis: 0.1287 (0.1747)  loss_refine_obj: 0.6831 (0.9359)  loss_rel: 0.2002 (0.2609)  time: 1.0767 (1.2964)  data: 0.0116 (0.2416)  lr: 0.012000  max mem: 6540
2020-03-09 22:16:27,588 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgcls/model_0020000.pth
2020-03-09 22:16:29,144 maskrcnn_benchmark INFO: Start validating
2020-03-09 22:16:29,161 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 22:23:39,769 maskrcnn_benchmark INFO: Total run time: 0:07:10.607574 (0.17224302968978883 s / img per device, on 2 devices)
2020-03-09 22:23:39,769 maskrcnn_benchmark INFO: Model inference time: 0:06:31.971688 (0.15678867511749267 s / img per device, on 2 devices)
2020-03-09 22:24:59,319 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5917
====================================================================================================
SGG eval:   R @ 20: 0.3913;   R @ 50: 0.4192;   R @ 100: 0.4268;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4499; ngR @ 50: 0.5183; ngR @ 100: 0.5526;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0311;  zR @ 50: 0.0593;  zR @ 100: 0.0719;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0664;  mR @ 50: 0.0772;  mR @ 100: 0.0835;  for mode=sgcls, type=Mean Recall.
(above:0.1032) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0463) (attached to:0.0000) (behind:0.3036) (belonging to:0.0000) (between:0.0000) (carrying:0.1491) (covered in:0.0714) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5327) (holding:0.3023) (in:0.1827) (in front of:0.0634) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3375) (of:0.2699) (on:0.5853) (on back of:0.0000) (over:0.0122) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1830) (says:0.0000) (sitting on:0.1164) (standing on:0.0000) (to:0.0000) (under:0.0944) (using:0.0000) (walking in:0.0000) (walking on:0.0060) (watching:0.0882) (wearing:0.5281) (wears:0.0000) (with:0.0175) 
SGG eval:   A @ 20: 0.4511;   A @ 50: 0.4543;   A @ 100: 0.4543;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 22:24:59,904 maskrcnn_benchmark INFO: Validation Result: 0.4268
2020-03-09 22:28:31,722 maskrcnn_benchmark INFO: eta: 10:55:19  iter: 20200  loss: 1.4262 (1.7356)  auxiliary_ctx: 0.1453 (0.1625)  auxiliary_frq: 0.2006 (0.2041)  auxiliary_vis: 0.1513 (0.1745)  loss_refine_obj: 0.7454 (0.9339)  loss_rel: 0.2295 (0.2606)  time: 1.0576 (1.3194)  data: 0.0114 (0.2647)  lr: 0.012000  max mem: 6540
2020-03-09 22:32:05,851 maskrcnn_benchmark INFO: eta: 10:49:43  iter: 20400  loss: 1.5008 (1.7333)  auxiliary_ctx: 0.1329 (0.1624)  auxiliary_frq: 0.1842 (0.2041)  auxiliary_vis: 0.1443 (0.1743)  loss_refine_obj: 0.7607 (0.9321)  loss_rel: 0.2135 (0.2604)  time: 1.0784 (1.3170)  data: 0.0101 (0.2622)  lr: 0.012000  max mem: 6540
2020-03-09 22:35:40,555 maskrcnn_benchmark INFO: eta: 10:44:10  iter: 20600  loss: 1.3851 (1.7308)  auxiliary_ctx: 0.1271 (0.1623)  auxiliary_frq: 0.1878 (0.2040)  auxiliary_vis: 0.1337 (0.1741)  loss_refine_obj: 0.7353 (0.9303)  loss_rel: 0.2008 (0.2601)  time: 1.0815 (1.3146)  data: 0.0094 (0.2598)  lr: 0.012000  max mem: 6540
2020-03-09 22:39:14,075 maskrcnn_benchmark INFO: eta: 10:38:38  iter: 20800  loss: 1.3942 (1.7286)  auxiliary_ctx: 0.1404 (0.1621)  auxiliary_frq: 0.1939 (0.2040)  auxiliary_vis: 0.1540 (0.1739)  loss_refine_obj: 0.7401 (0.9287)  loss_rel: 0.2240 (0.2599)  time: 1.0687 (1.3123)  data: 0.0103 (0.2574)  lr: 0.012000  max mem: 6540
2020-03-09 22:42:49,059 maskrcnn_benchmark INFO: eta: 10:33:10  iter: 21000  loss: 1.4971 (1.7264)  auxiliary_ctx: 0.1448 (0.1620)  auxiliary_frq: 0.1941 (0.2039)  auxiliary_vis: 0.1573 (0.1737)  loss_refine_obj: 0.6901 (0.9272)  loss_rel: 0.2229 (0.2596)  time: 1.0595 (1.3100)  data: 0.0114 (0.2551)  lr: 0.012000  max mem: 6540
2020-03-09 22:46:23,013 maskrcnn_benchmark INFO: eta: 10:27:42  iter: 21200  loss: 1.4766 (1.7244)  auxiliary_ctx: 0.1391 (0.1619)  auxiliary_frq: 0.1912 (0.2039)  auxiliary_vis: 0.1464 (0.1736)  loss_refine_obj: 0.7390 (0.9256)  loss_rel: 0.2168 (0.2594)  time: 1.0609 (1.3077)  data: 0.0117 (0.2528)  lr: 0.012000  max mem: 6540
2020-03-09 22:49:57,287 maskrcnn_benchmark INFO: eta: 10:22:18  iter: 21400  loss: 1.5385 (1.7221)  auxiliary_ctx: 0.1408 (0.1617)  auxiliary_frq: 0.1981 (0.2039)  auxiliary_vis: 0.1392 (0.1734)  loss_refine_obj: 0.8333 (0.9239)  loss_rel: 0.2128 (0.2592)  time: 1.0662 (1.3055)  data: 0.0114 (0.2505)  lr: 0.012000  max mem: 6540
2020-03-09 22:53:31,425 maskrcnn_benchmark INFO: eta: 10:16:55  iter: 21600  loss: 1.4099 (1.7199)  auxiliary_ctx: 0.1438 (0.1616)  auxiliary_frq: 0.1896 (0.2038)  auxiliary_vis: 0.1430 (0.1732)  loss_refine_obj: 0.7210 (0.9223)  loss_rel: 0.2136 (0.2589)  time: 1.0654 (1.3034)  data: 0.0114 (0.2483)  lr: 0.012000  max mem: 6540
2020-03-09 22:57:05,132 maskrcnn_benchmark INFO: eta: 10:11:33  iter: 21800  loss: 1.3875 (1.7179)  auxiliary_ctx: 0.1393 (0.1615)  auxiliary_frq: 0.1937 (0.2038)  auxiliary_vis: 0.1446 (0.1731)  loss_refine_obj: 0.7047 (0.9207)  loss_rel: 0.2051 (0.2587)  time: 1.0708 (1.3012)  data: 0.0114 (0.2461)  lr: 0.012000  max mem: 6540
2020-03-09 23:00:39,755 maskrcnn_benchmark INFO: eta: 10:06:15  iter: 22000  loss: 1.4784 (1.7160)  auxiliary_ctx: 0.1548 (0.1614)  auxiliary_frq: 0.1970 (0.2038)  auxiliary_vis: 0.1561 (0.1729)  loss_refine_obj: 0.7298 (0.9194)  loss_rel: 0.2239 (0.2586)  time: 1.0621 (1.2991)  data: 0.0111 (0.2440)  lr: 0.012000  max mem: 6540
2020-03-09 23:00:39,757 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgcls/model_0022000.pth
2020-03-09 23:00:41,301 maskrcnn_benchmark INFO: Start validating
2020-03-09 23:00:41,318 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 23:07:52,026 maskrcnn_benchmark INFO: Total run time: 0:07:10.707356 (0.17228294258117677 s / img per device, on 2 devices)
2020-03-09 23:07:52,026 maskrcnn_benchmark INFO: Model inference time: 0:06:33.686092 (0.15747443695068358 s / img per device, on 2 devices)
2020-03-09 23:09:11,878 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5915
====================================================================================================
SGG eval:   R @ 20: 0.3891;   R @ 50: 0.4182;   R @ 100: 0.4261;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4480; ngR @ 50: 0.5163; ngR @ 100: 0.5505;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0311;  zR @ 50: 0.0622;  zR @ 100: 0.0689;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0707;  mR @ 50: 0.0821;  mR @ 100: 0.0894;  for mode=sgcls, type=Mean Recall.
(above:0.1161) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0842) (attached to:0.0000) (behind:0.3233) (belonging to:0.0000) (between:0.0000) (carrying:0.1623) (covered in:0.0714) (covering:0.0000) (eating:0.2143) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5280) (holding:0.3054) (in:0.1917) (in front of:0.0610) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3271) (of:0.2722) (on:0.5806) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2723) (says:0.0000) (sitting on:0.1138) (standing on:0.0000) (to:0.0000) (under:0.0991) (using:0.0000) (walking in:0.0000) (walking on:0.0138) (watching:0.1176) (wearing:0.5234) (wears:0.0000) (with:0.0291) 
SGG eval:   A @ 20: 0.4511;   A @ 50: 0.4542;   A @ 100: 0.4542;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 23:09:12,535 maskrcnn_benchmark INFO: Validation Result: 0.4261
2020-03-09 23:09:12,536 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-03-09 23:12:45,440 maskrcnn_benchmark INFO: eta: 10:11:39  iter: 22200  loss: 1.4129 (1.7139)  auxiliary_ctx: 0.1417 (0.1613)  auxiliary_frq: 0.1930 (0.2038)  auxiliary_vis: 0.1477 (0.1728)  loss_refine_obj: 0.7494 (0.9178)  loss_rel: 0.2004 (0.2583)  time: 1.0757 (1.3201)  data: 0.0097 (0.2650)  lr: 0.001200  max mem: 6540
2020-03-09 23:16:20,534 maskrcnn_benchmark INFO: eta: 10:06:14  iter: 22400  loss: 1.4687 (1.7119)  auxiliary_ctx: 0.1543 (0.1612)  auxiliary_frq: 0.2000 (0.2038)  auxiliary_vis: 0.1602 (0.1726)  loss_refine_obj: 0.7461 (0.9162)  loss_rel: 0.2292 (0.2581)  time: 1.0564 (1.3179)  data: 0.0115 (0.2627)  lr: 0.001200  max mem: 6540
2020-03-09 23:19:55,842 maskrcnn_benchmark INFO: eta: 10:00:52  iter: 22600  loss: 1.5401 (1.7098)  auxiliary_ctx: 0.1408 (0.1610)  auxiliary_frq: 0.1955 (0.2037)  auxiliary_vis: 0.1493 (0.1724)  loss_refine_obj: 0.7405 (0.9148)  loss_rel: 0.2258 (0.2579)  time: 1.0643 (1.3158)  data: 0.0116 (0.2605)  lr: 0.001200  max mem: 6540
2020-03-09 23:23:30,199 maskrcnn_benchmark INFO: eta: 9:55:31  iter: 22800  loss: 1.3371 (1.7079)  auxiliary_ctx: 0.1231 (0.1609)  auxiliary_frq: 0.1793 (0.2037)  auxiliary_vis: 0.1314 (0.1723)  loss_refine_obj: 0.7090 (0.9134)  loss_rel: 0.1848 (0.2576)  time: 1.0713 (1.3136)  data: 0.0116 (0.2583)  lr: 0.001200  max mem: 6540
2020-03-09 23:27:05,158 maskrcnn_benchmark INFO: eta: 9:50:12  iter: 23000  loss: 1.4207 (1.7058)  auxiliary_ctx: 0.1301 (0.1608)  auxiliary_frq: 0.1856 (0.2036)  auxiliary_vis: 0.1427 (0.1721)  loss_refine_obj: 0.7442 (0.9119)  loss_rel: 0.2042 (0.2574)  time: 1.0834 (1.3116)  data: 0.0114 (0.2561)  lr: 0.001200  max mem: 6540
2020-03-09 23:30:38,825 maskrcnn_benchmark INFO: eta: 9:44:53  iter: 23200  loss: 1.4071 (1.7037)  auxiliary_ctx: 0.1332 (0.1606)  auxiliary_frq: 0.1906 (0.2036)  auxiliary_vis: 0.1405 (0.1719)  loss_refine_obj: 0.7371 (0.9104)  loss_rel: 0.2286 (0.2572)  time: 1.0958 (1.3095)  data: 0.0117 (0.2540)  lr: 0.001200  max mem: 6540
2020-03-09 23:34:11,967 maskrcnn_benchmark INFO: eta: 9:39:36  iter: 23400  loss: 1.4982 (1.7019)  auxiliary_ctx: 0.1440 (0.1606)  auxiliary_frq: 0.2040 (0.2036)  auxiliary_vis: 0.1500 (0.1718)  loss_refine_obj: 0.7677 (0.9089)  loss_rel: 0.2476 (0.2571)  time: 1.0640 (1.3074)  data: 0.0116 (0.2520)  lr: 0.001200  max mem: 6540
2020-03-09 23:37:44,616 maskrcnn_benchmark INFO: eta: 9:34:20  iter: 23600  loss: 1.4318 (1.6999)  auxiliary_ctx: 0.1351 (0.1604)  auxiliary_frq: 0.1935 (0.2036)  auxiliary_vis: 0.1483 (0.1716)  loss_refine_obj: 0.6833 (0.9074)  loss_rel: 0.2037 (0.2568)  time: 1.0655 (1.3053)  data: 0.0111 (0.2499)  lr: 0.001200  max mem: 6540
2020-03-09 23:41:19,010 maskrcnn_benchmark INFO: eta: 9:29:08  iter: 23800  loss: 1.3541 (1.6979)  auxiliary_ctx: 0.1285 (0.1603)  auxiliary_frq: 0.1814 (0.2035)  auxiliary_vis: 0.1338 (0.1715)  loss_refine_obj: 0.7266 (0.9059)  loss_rel: 0.1865 (0.2566)  time: 1.0827 (1.3034)  data: 0.0110 (0.2479)  lr: 0.001200  max mem: 6540
2020-03-09 23:44:53,958 maskrcnn_benchmark INFO: ---Total norm 1.60679 clip coef 3.11179-----------------
2020-03-09 23:44:53,968 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.98656, (torch.Size([4096, 4096]))
2020-03-09 23:44:53,968 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.86636, (torch.Size([4096, 12544]))
2020-03-09 23:44:53,968 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.66488, (torch.Size([3072, 5136]))
2020-03-09 23:44:53,968 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.34826, (torch.Size([4096, 12544]))
2020-03-09 23:44:53,968 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.34610, (torch.Size([151, 512]))
2020-03-09 23:44:53,968 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.17235, (torch.Size([256, 1024, 3, 3]))
2020-03-09 23:44:53,968 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.16740, (torch.Size([4096, 4096]))
2020-03-09 23:44:53,968 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.11123, (torch.Size([2048, 4808]))
2020-03-09 23:44:53,968 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.10339, (torch.Size([51, 4096]))
2020-03-09 23:44:53,968 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.10318, (torch.Size([151, 200]))
2020-03-09 23:44:53,968 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.09993, (torch.Size([4096, 1024]))
2020-03-09 23:44:53,968 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.09436, (torch.Size([2048, 4424]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.09230, (torch.Size([2560, 512]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.09143, (torch.Size([51, 4096]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.09124, (torch.Size([2048, 4808]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.09093, (torch.Size([2048, 4424]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.07476, (torch.Size([256, 128, 3, 3]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.06398, (torch.Size([4096, 512]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.05966, (torch.Size([128, 2, 7, 7]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.04942, (torch.Size([151]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.04769, (torch.Size([512, 32]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.04410, (torch.Size([3072]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.03684, (torch.Size([151, 200]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.03575, (torch.Size([512, 1024]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.03060, (torch.Size([32, 9]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.02876, (torch.Size([128, 32]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.02625, (torch.Size([512, 1024]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.02605, (torch.Size([152, 200]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.02411, (torch.Size([512]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02306, (torch.Size([1024, 512]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.02007, (torch.Size([128]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01593, (torch.Size([256]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.01568, (torch.Size([4096]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.01544, (torch.Size([2560]))
2020-03-09 23:44:53,969 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.01474, (torch.Size([2048, 512]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01404, (torch.Size([22801, 51]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.01388, (torch.Size([512]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01372, (torch.Size([2048, 512]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.01288, (torch.Size([512]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01237, (torch.Size([4096]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.01196, (torch.Size([256]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.01168, (torch.Size([128]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.01153, (torch.Size([51]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.01115, (torch.Size([128]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.01070, (torch.Size([32]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.01048, (torch.Size([32]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.01035, (torch.Size([128]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01022, (torch.Size([2048]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01022, (torch.Size([2048]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01010, (torch.Size([4096]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00943, (torch.Size([2048]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00943, (torch.Size([2048]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00917, (torch.Size([1024]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00894, (torch.Size([4096]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00887, (torch.Size([2048, 512]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00843, (torch.Size([51]))
2020-03-09 23:44:53,970 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00796, (torch.Size([2048]))
2020-03-09 23:44:53,971 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00796, (torch.Size([2048]))
2020-03-09 23:44:53,971 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00675, (torch.Size([256]))
2020-03-09 23:44:53,971 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00496, (torch.Size([4096]))
2020-03-09 23:44:53,971 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00390, (torch.Size([2048, 512]))
2020-03-09 23:44:53,971 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00387, (torch.Size([4096]))
2020-03-09 23:44:53,971 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00298, (torch.Size([2048]))
2020-03-09 23:44:53,971 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00298, (torch.Size([2048]))
2020-03-09 23:44:53,971 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00172, (torch.Size([256]))
2020-03-09 23:44:53,971 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00001, (torch.Size([32]))
2020-03-09 23:44:53,971 maskrcnn_benchmark INFO: -------------------------------
2020-03-09 23:44:53,974 maskrcnn_benchmark INFO: eta: 9:23:57  iter: 24000  loss: 1.5551 (1.6960)  auxiliary_ctx: 0.1676 (0.1602)  auxiliary_frq: 0.2124 (0.2035)  auxiliary_vis: 0.1692 (0.1713)  loss_refine_obj: 0.7115 (0.9044)  loss_rel: 0.2633 (0.2565)  time: 1.0493 (1.3015)  data: 0.0111 (0.2459)  lr: 0.001200  max mem: 6540
2020-03-09 23:44:53,975 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgcls/model_0024000.pth
2020-03-09 23:44:55,518 maskrcnn_benchmark INFO: Start validating
2020-03-09 23:44:55,535 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 23:52:06,522 maskrcnn_benchmark INFO: Total run time: 0:07:10.986917 (0.17239476690292357 s / img per device, on 2 devices)
2020-03-09 23:52:06,522 maskrcnn_benchmark INFO: Model inference time: 0:06:33.006524 (0.15720260953903198 s / img per device, on 2 devices)
2020-03-09 23:53:26,329 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5970
====================================================================================================
SGG eval:   R @ 20: 0.3974;   R @ 50: 0.4257;   R @ 100: 0.4337;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4566; ngR @ 50: 0.5237; ngR @ 100: 0.5595;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0333;  zR @ 50: 0.0622;  zR @ 100: 0.0667;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0710;  mR @ 50: 0.0821;  mR @ 100: 0.0892;  for mode=sgcls, type=Mean Recall.
(above:0.1032) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0800) (attached to:0.0000) (behind:0.3160) (belonging to:0.0000) (between:0.0000) (carrying:0.1689) (covered in:0.0714) (covering:0.0000) (eating:0.2143) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5350) (holding:0.2850) (in:0.1906) (in front of:0.0537) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3502) (of:0.2738) (on:0.5899) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2902) (says:0.0000) (sitting on:0.1086) (standing on:0.0000) (to:0.0000) (under:0.1054) (using:0.0000) (walking in:0.0000) (walking on:0.0149) (watching:0.0882) (wearing:0.5334) (wears:0.0000) (with:0.0245) 
SGG eval:   A @ 20: 0.4577;   A @ 50: 0.4610;   A @ 100: 0.4610;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 23:53:26,963 maskrcnn_benchmark INFO: Validation Result: 0.4337
2020-03-09 23:56:59,166 maskrcnn_benchmark INFO: eta: 9:27:53  iter: 24200  loss: 1.3969 (1.6940)  auxiliary_ctx: 0.1383 (0.1601)  auxiliary_frq: 0.1933 (0.2035)  auxiliary_vis: 0.1381 (0.1712)  loss_refine_obj: 0.6946 (0.9030)  loss_rel: 0.2110 (0.2562)  time: 1.0473 (1.3207)  data: 0.0114 (0.2652)  lr: 0.001200  max mem: 6540
2020-03-10 00:00:33,857 maskrcnn_benchmark INFO: eta: 9:22:37  iter: 24400  loss: 1.3506 (1.6918)  auxiliary_ctx: 0.1330 (0.1600)  auxiliary_frq: 0.1891 (0.2035)  auxiliary_vis: 0.1374 (0.1710)  loss_refine_obj: 0.7370 (0.9014)  loss_rel: 0.1776 (0.2560)  time: 1.0736 (1.3186)  data: 0.0118 (0.2631)  lr: 0.001200  max mem: 6540
2020-03-10 00:04:07,857 maskrcnn_benchmark INFO: eta: 9:17:22  iter: 24600  loss: 1.3771 (1.6896)  auxiliary_ctx: 0.1416 (0.1598)  auxiliary_frq: 0.1940 (0.2034)  auxiliary_vis: 0.1393 (0.1708)  loss_refine_obj: 0.7193 (0.8997)  loss_rel: 0.2022 (0.2558)  time: 1.0799 (1.3166)  data: 0.0113 (0.2611)  lr: 0.001200  max mem: 6540
2020-03-10 00:07:41,833 maskrcnn_benchmark INFO: eta: 9:12:08  iter: 24800  loss: 1.3626 (1.6875)  auxiliary_ctx: 0.1341 (0.1597)  auxiliary_frq: 0.1919 (0.2034)  auxiliary_vis: 0.1369 (0.1706)  loss_refine_obj: 0.7369 (0.8982)  loss_rel: 0.2096 (0.2555)  time: 1.0655 (1.3146)  data: 0.0113 (0.2591)  lr: 0.001200  max mem: 6540
2020-03-10 00:11:16,143 maskrcnn_benchmark INFO: eta: 9:06:57  iter: 25000  loss: 1.3821 (1.6852)  auxiliary_ctx: 0.1436 (0.1596)  auxiliary_frq: 0.1940 (0.2034)  auxiliary_vis: 0.1467 (0.1705)  loss_refine_obj: 0.7208 (0.8966)  loss_rel: 0.2118 (0.2553)  time: 1.0654 (1.3127)  data: 0.0098 (0.2571)  lr: 0.001200  max mem: 6540
2020-03-10 00:14:50,145 maskrcnn_benchmark INFO: eta: 9:01:46  iter: 25200  loss: 1.3494 (1.6832)  auxiliary_ctx: 0.1321 (0.1595)  auxiliary_frq: 0.1863 (0.2033)  auxiliary_vis: 0.1372 (0.1703)  loss_refine_obj: 0.6419 (0.8951)  loss_rel: 0.1991 (0.2550)  time: 1.0580 (1.3108)  data: 0.0117 (0.2551)  lr: 0.001200  max mem: 6540
2020-03-10 00:18:24,082 maskrcnn_benchmark INFO: eta: 8:56:37  iter: 25400  loss: 1.4780 (1.6811)  auxiliary_ctx: 0.1474 (0.1593)  auxiliary_frq: 0.2008 (0.2033)  auxiliary_vis: 0.1490 (0.1701)  loss_refine_obj: 0.7357 (0.8934)  loss_rel: 0.2333 (0.2548)  time: 1.0600 (1.3089)  data: 0.0118 (0.2532)  lr: 0.001200  max mem: 6540
2020-03-10 00:21:57,347 maskrcnn_benchmark INFO: eta: 8:51:29  iter: 25600  loss: 1.3772 (1.6790)  auxiliary_ctx: 0.1394 (0.1593)  auxiliary_frq: 0.1922 (0.2033)  auxiliary_vis: 0.1452 (0.1700)  loss_refine_obj: 0.6912 (0.8918)  loss_rel: 0.2085 (0.2547)  time: 1.0653 (1.3070)  data: 0.0112 (0.2513)  lr: 0.001200  max mem: 6540
2020-03-10 00:25:32,118 maskrcnn_benchmark INFO: eta: 8:46:24  iter: 25800  loss: 1.3240 (1.6772)  auxiliary_ctx: 0.1313 (0.1592)  auxiliary_frq: 0.1872 (0.2033)  auxiliary_vis: 0.1376 (0.1699)  loss_refine_obj: 0.6430 (0.8904)  loss_rel: 0.2098 (0.2545)  time: 1.0687 (1.3052)  data: 0.0109 (0.2495)  lr: 0.001200  max mem: 6540
2020-03-10 00:29:05,321 maskrcnn_benchmark INFO: eta: 8:41:19  iter: 26000  loss: 1.3355 (1.6753)  auxiliary_ctx: 0.1442 (0.1591)  auxiliary_frq: 0.2066 (0.2033)  auxiliary_vis: 0.1494 (0.1697)  loss_refine_obj: 0.6545 (0.8889)  loss_rel: 0.2169 (0.2543)  time: 1.0470 (1.3033)  data: 0.0101 (0.2476)  lr: 0.001200  max mem: 6540
2020-03-10 00:29:05,323 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgcls/model_0026000.pth
2020-03-10 00:29:06,839 maskrcnn_benchmark INFO: Start validating
2020-03-10 00:29:06,851 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-10 00:36:19,763 maskrcnn_benchmark INFO: Total run time: 0:07:12.911634 (0.17316465358734132 s / img per device, on 2 devices)
2020-03-10 00:36:19,763 maskrcnn_benchmark INFO: Model inference time: 0:06:34.495739 (0.15779829540252685 s / img per device, on 2 devices)
2020-03-10 00:37:39,982 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5979
====================================================================================================
SGG eval:   R @ 20: 0.3980;   R @ 50: 0.4261;   R @ 100: 0.4341;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4570; ngR @ 50: 0.5259; ngR @ 100: 0.5603;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0333;  zR @ 50: 0.0644;  zR @ 100: 0.0644;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0700;  mR @ 50: 0.0812;  mR @ 100: 0.0885;  for mode=sgcls, type=Mean Recall.
(above:0.1133) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0901) (attached to:0.0000) (behind:0.3151) (belonging to:0.0000) (between:0.0000) (carrying:0.1864) (covered in:0.0714) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5397) (holding:0.2850) (in:0.1905) (in front of:0.0560) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3519) (of:0.2737) (on:0.5914) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2723) (says:0.0000) (sitting on:0.1164) (standing on:0.0000) (to:0.0000) (under:0.1105) (using:0.0000) (walking in:0.0000) (walking on:0.0133) (watching:0.0882) (wearing:0.5318) (wears:0.0000) (with:0.0214) 
SGG eval:   A @ 20: 0.4584;   A @ 50: 0.4616;   A @ 100: 0.4616;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-10 00:37:40,625 maskrcnn_benchmark INFO: Validation Result: 0.4341
2020-03-10 00:41:14,005 maskrcnn_benchmark INFO: eta: 8:44:04  iter: 26200  loss: 1.3770 (1.6736)  auxiliary_ctx: 0.1332 (0.1590)  auxiliary_frq: 0.1912 (0.2032)  auxiliary_vis: 0.1395 (0.1696)  loss_refine_obj: 0.6976 (0.8876)  loss_rel: 0.2039 (0.2541)  time: 1.0698 (1.3212)  data: 0.0106 (0.2655)  lr: 0.001200  max mem: 6540
2020-03-10 00:44:47,952 maskrcnn_benchmark INFO: eta: 8:38:54  iter: 26400  loss: 1.4352 (1.6718)  auxiliary_ctx: 0.1391 (0.1589)  auxiliary_frq: 0.1976 (0.2032)  auxiliary_vis: 0.1449 (0.1695)  loss_refine_obj: 0.7173 (0.8862)  loss_rel: 0.2145 (0.2540)  time: 1.0625 (1.3193)  data: 0.0109 (0.2635)  lr: 0.001200  max mem: 6540
2020-03-10 00:48:20,449 maskrcnn_benchmark INFO: eta: 8:33:45  iter: 26600  loss: 1.4218 (1.6700)  auxiliary_ctx: 0.1347 (0.1588)  auxiliary_frq: 0.1936 (0.2032)  auxiliary_vis: 0.1409 (0.1693)  loss_refine_obj: 0.7091 (0.8849)  loss_rel: 0.2134 (0.2538)  time: 1.0598 (1.3173)  data: 0.0099 (0.2616)  lr: 0.001200  max mem: 6540
2020-03-10 00:51:54,027 maskrcnn_benchmark INFO: eta: 8:28:39  iter: 26800  loss: 1.3861 (1.6680)  auxiliary_ctx: 0.1425 (0.1587)  auxiliary_frq: 0.2027 (0.2032)  auxiliary_vis: 0.1480 (0.1692)  loss_refine_obj: 0.6758 (0.8834)  loss_rel: 0.2171 (0.2536)  time: 1.0593 (1.3155)  data: 0.0114 (0.2598)  lr: 0.001200  max mem: 6540
2020-03-10 00:55:27,771 maskrcnn_benchmark INFO: eta: 8:23:34  iter: 27000  loss: 1.3649 (1.6661)  auxiliary_ctx: 0.1435 (0.1586)  auxiliary_frq: 0.1977 (0.2031)  auxiliary_vis: 0.1437 (0.1690)  loss_refine_obj: 0.6672 (0.8820)  loss_rel: 0.2255 (0.2534)  time: 1.0511 (1.3137)  data: 0.0115 (0.2579)  lr: 0.001200  max mem: 6540
2020-03-10 00:59:00,984 maskrcnn_benchmark INFO: eta: 8:18:29  iter: 27200  loss: 1.3978 (1.6643)  auxiliary_ctx: 0.1226 (0.1585)  auxiliary_frq: 0.1901 (0.2031)  auxiliary_vis: 0.1305 (0.1689)  loss_refine_obj: 0.6808 (0.8806)  loss_rel: 0.1880 (0.2532)  time: 1.0624 (1.3118)  data: 0.0118 (0.2561)  lr: 0.001200  max mem: 6540
2020-03-10 01:02:34,660 maskrcnn_benchmark INFO: eta: 8:13:27  iter: 27400  loss: 1.3413 (1.6625)  auxiliary_ctx: 0.1416 (0.1584)  auxiliary_frq: 0.1902 (0.2031)  auxiliary_vis: 0.1435 (0.1687)  loss_refine_obj: 0.6437 (0.8792)  loss_rel: 0.2122 (0.2530)  time: 1.0557 (1.3101)  data: 0.0105 (0.2543)  lr: 0.001200  max mem: 6540
2020-03-10 01:06:07,239 maskrcnn_benchmark INFO: eta: 8:08:25  iter: 27600  loss: 1.3922 (1.6606)  auxiliary_ctx: 0.1470 (0.1583)  auxiliary_frq: 0.1977 (0.2031)  auxiliary_vis: 0.1427 (0.1686)  loss_refine_obj: 0.6440 (0.8777)  loss_rel: 0.2329 (0.2529)  time: 1.0513 (1.3083)  data: 0.0109 (0.2526)  lr: 0.001200  max mem: 6540
2020-03-10 01:09:40,377 maskrcnn_benchmark INFO: eta: 8:03:24  iter: 27800  loss: 1.4828 (1.6591)  auxiliary_ctx: 0.1518 (0.1582)  auxiliary_frq: 0.2085 (0.2031)  auxiliary_vis: 0.1556 (0.1685)  loss_refine_obj: 0.7020 (0.8766)  loss_rel: 0.2404 (0.2527)  time: 1.0533 (1.3065)  data: 0.0114 (0.2508)  lr: 0.001200  max mem: 6540
2020-03-10 01:13:12,260 maskrcnn_benchmark INFO: ---Total norm 1.26081 clip coef 3.96569-----------------
2020-03-10 01:13:12,270 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.64789, (torch.Size([4096, 4096]))
2020-03-10 01:13:12,270 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.54944, (torch.Size([4096, 12544]))
2020-03-10 01:13:12,270 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.51164, (torch.Size([4096, 12544]))
2020-03-10 01:13:12,270 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.45877, (torch.Size([3072, 5136]))
2020-03-10 01:13:12,270 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.27402, (torch.Size([151, 512]))
2020-03-10 01:13:12,270 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.26962, (torch.Size([256, 1024, 3, 3]))
2020-03-10 01:13:12,270 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.22729, (torch.Size([4096, 4096]))
2020-03-10 01:13:12,270 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.18501, (torch.Size([2048, 4808]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.16284, (torch.Size([51, 4096]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.15659, (torch.Size([51, 4096]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.15076, (torch.Size([2048, 4808]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.12707, (torch.Size([4096, 1024]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.09795, (torch.Size([256, 128, 3, 3]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.08856, (torch.Size([128, 2, 7, 7]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.08815, (torch.Size([2048, 4424]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.08113, (torch.Size([4096, 512]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.08062, (torch.Size([512, 32]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.07868, (torch.Size([2560, 512]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.07523, (torch.Size([151, 200]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.05481, (torch.Size([512, 1024]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.04747, (torch.Size([32, 9]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.04502, (torch.Size([2048, 4424]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.04086, (torch.Size([151, 200]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.03341, (torch.Size([151]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.03281, (torch.Size([512]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.03127, (torch.Size([3072]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.03106, (torch.Size([1024, 512]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.02712, (torch.Size([128]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.02709, (torch.Size([512, 1024]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.02651, (torch.Size([51]))
2020-03-10 01:13:12,271 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.02471, (torch.Size([128, 32]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.02403, (torch.Size([152, 200]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.02323, (torch.Size([51]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01956, (torch.Size([2048, 512]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01825, (torch.Size([256]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01742, (torch.Size([2048, 512]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.01719, (torch.Size([4096]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.01665, (torch.Size([512]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01662, (torch.Size([2048]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01662, (torch.Size([2048]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01604, (torch.Size([2048]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01604, (torch.Size([2048]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01567, (torch.Size([22801, 51]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.01539, (torch.Size([4096]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01403, (torch.Size([4096]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.01380, (torch.Size([512]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.01325, (torch.Size([256]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.01310, (torch.Size([128]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.01286, (torch.Size([2048, 512]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.01204, (torch.Size([2560]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.01165, (torch.Size([32]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01092, (torch.Size([1024]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00956, (torch.Size([128]))
2020-03-10 01:13:12,272 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00848, (torch.Size([4096]))
2020-03-10 01:13:12,273 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00823, (torch.Size([2048]))
2020-03-10 01:13:12,273 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00823, (torch.Size([2048]))
2020-03-10 01:13:12,273 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00816, (torch.Size([256]))
2020-03-10 01:13:12,273 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00796, (torch.Size([32]))
2020-03-10 01:13:12,273 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00688, (torch.Size([128]))
2020-03-10 01:13:12,273 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00585, (torch.Size([4096]))
2020-03-10 01:13:12,273 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00499, (torch.Size([2048, 512]))
2020-03-10 01:13:12,273 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00490, (torch.Size([2048]))
2020-03-10 01:13:12,273 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00490, (torch.Size([2048]))
2020-03-10 01:13:12,273 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00310, (torch.Size([4096]))
2020-03-10 01:13:12,273 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00258, (torch.Size([256]))
2020-03-10 01:13:12,273 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00001, (torch.Size([32]))
2020-03-10 01:13:12,273 maskrcnn_benchmark INFO: -------------------------------
2020-03-10 01:13:12,276 maskrcnn_benchmark INFO: eta: 7:58:24  iter: 28000  loss: 1.3397 (1.6575)  auxiliary_ctx: 0.1244 (0.1581)  auxiliary_frq: 0.1823 (0.2031)  auxiliary_vis: 0.1367 (0.1684)  loss_refine_obj: 0.6609 (0.8754)  loss_rel: 0.1763 (0.2526)  time: 1.0611 (1.3048)  data: 0.0114 (0.2491)  lr: 0.001200  max mem: 6540
2020-03-10 01:13:12,277 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgcls/model_0028000.pth
2020-03-10 01:13:13,820 maskrcnn_benchmark INFO: Start validating
2020-03-10 01:13:13,836 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-10 01:20:23,663 maskrcnn_benchmark INFO: Total run time: 0:07:09.827106 (0.17193084259033203 s / img per device, on 2 devices)
2020-03-10 01:20:23,664 maskrcnn_benchmark INFO: Model inference time: 0:06:32.099695 (0.15683987817764283 s / img per device, on 2 devices)
2020-03-10 01:21:43,745 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5988
====================================================================================================
SGG eval:   R @ 20: 0.4017;   R @ 50: 0.4298;   R @ 100: 0.4378;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4594; ngR @ 50: 0.5275; ngR @ 100: 0.5631;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0333;  zR @ 50: 0.0644;  zR @ 100: 0.0681;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0700;  mR @ 50: 0.0811;  mR @ 100: 0.0884;  for mode=sgcls, type=Mean Recall.
(above:0.1090) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0800) (attached to:0.0000) (behind:0.3147) (belonging to:0.0000) (between:0.0000) (carrying:0.1491) (covered in:0.0714) (covering:0.0000) (eating:0.2143) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5378) (holding:0.3054) (in:0.1939) (in front of:0.0580) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3471) (of:0.2774) (on:0.5970) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2188) (says:0.0000) (sitting on:0.1138) (standing on:0.0000) (to:0.0000) (under:0.1054) (using:0.0000) (walking in:0.0000) (walking on:0.0133) (watching:0.0784) (wearing:0.5414) (wears:0.0000) (with:0.0337) 
SGG eval:   A @ 20: 0.4591;   A @ 50: 0.4624;   A @ 100: 0.4624;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-10 01:21:44,359 maskrcnn_benchmark INFO: Validation Result: 0.4378
2020-03-10 01:25:15,618 maskrcnn_benchmark INFO: eta: 8:00:01  iter: 28200  loss: 1.4897 (1.6559)  auxiliary_ctx: 0.1555 (0.1580)  auxiliary_frq: 0.2168 (0.2030)  auxiliary_vis: 0.1621 (0.1683)  loss_refine_obj: 0.6788 (0.8742)  loss_rel: 0.2416 (0.2524)  time: 1.0451 (1.3212)  data: 0.0113 (0.2656)  lr: 0.001200  max mem: 6540
2020-03-10 01:28:47,271 maskrcnn_benchmark INFO: eta: 7:54:56  iter: 28400  loss: 1.4415 (1.6543)  auxiliary_ctx: 0.1406 (0.1580)  auxiliary_frq: 0.1983 (0.2030)  auxiliary_vis: 0.1458 (0.1682)  loss_refine_obj: 0.7369 (0.8729)  loss_rel: 0.2119 (0.2523)  time: 1.0551 (1.3193)  data: 0.0111 (0.2638)  lr: 0.001200  max mem: 6540
2020-03-10 01:32:17,594 maskrcnn_benchmark INFO: eta: 7:49:53  iter: 28600  loss: 1.3916 (1.6525)  auxiliary_ctx: 0.1364 (0.1579)  auxiliary_frq: 0.1939 (0.2030)  auxiliary_vis: 0.1496 (0.1680)  loss_refine_obj: 0.6440 (0.8715)  loss_rel: 0.1988 (0.2521)  time: 1.0398 (1.3174)  data: 0.0110 (0.2620)  lr: 0.001200  max mem: 6540
2020-03-10 01:35:50,302 maskrcnn_benchmark INFO: eta: 7:44:52  iter: 28800  loss: 1.3140 (1.6508)  auxiliary_ctx: 0.1341 (0.1578)  auxiliary_frq: 0.1929 (0.2030)  auxiliary_vis: 0.1445 (0.1679)  loss_refine_obj: 0.6571 (0.8702)  loss_rel: 0.1914 (0.2519)  time: 1.0481 (1.3157)  data: 0.0108 (0.2603)  lr: 0.001200  max mem: 6540
2020-03-10 01:39:21,549 maskrcnn_benchmark INFO: eta: 7:39:51  iter: 29000  loss: 1.3968 (1.6491)  auxiliary_ctx: 0.1416 (0.1577)  auxiliary_frq: 0.1935 (0.2030)  auxiliary_vis: 0.1504 (0.1678)  loss_refine_obj: 0.6946 (0.8690)  loss_rel: 0.2200 (0.2517)  time: 1.0531 (1.3139)  data: 0.0111 (0.2586)  lr: 0.001200  max mem: 6540
2020-03-10 01:42:51,467 maskrcnn_benchmark INFO: eta: 7:34:51  iter: 29200  loss: 1.3607 (1.6476)  auxiliary_ctx: 0.1279 (0.1576)  auxiliary_frq: 0.1893 (0.2029)  auxiliary_vis: 0.1357 (0.1677)  loss_refine_obj: 0.7103 (0.8677)  loss_rel: 0.2079 (0.2516)  time: 1.0462 (1.3121)  data: 0.0107 (0.2569)  lr: 0.001200  max mem: 6540
2020-03-10 01:46:21,066 maskrcnn_benchmark INFO: eta: 7:29:51  iter: 29400  loss: 1.4132 (1.6458)  auxiliary_ctx: 0.1457 (0.1575)  auxiliary_frq: 0.1924 (0.2029)  auxiliary_vis: 0.1507 (0.1675)  loss_refine_obj: 0.6600 (0.8664)  loss_rel: 0.2024 (0.2514)  time: 1.0406 (1.3103)  data: 0.0104 (0.2552)  lr: 0.001200  max mem: 6540
2020-03-10 01:49:50,962 maskrcnn_benchmark INFO: eta: 7:24:53  iter: 29600  loss: 1.3160 (1.6442)  auxiliary_ctx: 0.1358 (0.1574)  auxiliary_frq: 0.1928 (0.2029)  auxiliary_vis: 0.1413 (0.1674)  loss_refine_obj: 0.6749 (0.8653)  loss_rel: 0.1850 (0.2512)  time: 1.0310 (1.3085)  data: 0.0114 (0.2535)  lr: 0.001200  max mem: 6540
2020-03-10 01:53:19,013 maskrcnn_benchmark INFO: eta: 7:19:55  iter: 29800  loss: 1.4045 (1.6428)  auxiliary_ctx: 0.1451 (0.1574)  auxiliary_frq: 0.1983 (0.2029)  auxiliary_vis: 0.1398 (0.1673)  loss_refine_obj: 0.6737 (0.8641)  loss_rel: 0.2230 (0.2511)  time: 1.0445 (1.3067)  data: 0.0112 (0.2519)  lr: 0.001200  max mem: 6540
2020-03-10 01:56:47,765 maskrcnn_benchmark INFO: eta: 7:14:59  iter: 30000  loss: 1.3436 (1.6412)  auxiliary_ctx: 0.1182 (0.1573)  auxiliary_frq: 0.1910 (0.2029)  auxiliary_vis: 0.1325 (0.1672)  loss_refine_obj: 0.6800 (0.8629)  loss_rel: 0.1979 (0.2509)  time: 1.0560 (1.3050)  data: 0.0098 (0.2503)  lr: 0.001200  max mem: 6540
2020-03-10 01:56:47,767 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgcls/model_0030000.pth
2020-03-10 01:56:49,286 maskrcnn_benchmark INFO: Start validating
2020-03-10 01:56:49,303 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-10 02:03:45,291 maskrcnn_benchmark INFO: Total run time: 0:06:55.987854 (0.16639514150619505 s / img per device, on 2 devices)
2020-03-10 02:03:45,291 maskrcnn_benchmark INFO: Model inference time: 0:06:19.798251 (0.15191930027008058 s / img per device, on 2 devices)
2020-03-10 02:05:00,058 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5991
====================================================================================================
SGG eval:   R @ 20: 0.3993;   R @ 50: 0.4275;   R @ 100: 0.4353;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4563; ngR @ 50: 0.5267; ngR @ 100: 0.5610;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0289;  zR @ 50: 0.0644;  zR @ 100: 0.0696;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0706;  mR @ 50: 0.0819;  mR @ 100: 0.0893;  for mode=sgcls, type=Mean Recall.
(above:0.1133) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0800) (attached to:0.0000) (behind:0.3113) (belonging to:0.0000) (between:0.0000) (carrying:0.1557) (covered in:0.0714) (covering:0.0000) (eating:0.2143) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5394) (holding:0.3050) (in:0.1921) (in front of:0.0612) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3533) (of:0.2810) (on:0.5909) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2307) (says:0.0000) (sitting on:0.1190) (standing on:0.0000) (to:0.0000) (under:0.1156) (using:0.0000) (walking in:0.0000) (walking on:0.0112) (watching:0.0882) (wearing:0.5383) (wears:0.0000) (with:0.0331) 
SGG eval:   A @ 20: 0.4584;   A @ 50: 0.4615;   A @ 100: 0.4615;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-10 02:05:00,635 maskrcnn_benchmark INFO: Validation Result: 0.4353
2020-03-10 02:08:27,662 maskrcnn_benchmark INFO: eta: 7:15:25  iter: 30200  loss: 1.4035 (1.6396)  auxiliary_ctx: 0.1403 (0.1572)  auxiliary_frq: 0.1932 (0.2028)  auxiliary_vis: 0.1407 (0.1671)  loss_refine_obj: 0.7319 (0.8617)  loss_rel: 0.2025 (0.2508)  time: 1.0398 (1.3195)  data: 0.0109 (0.2650)  lr: 0.001200  max mem: 6540
2020-03-10 02:11:54,421 maskrcnn_benchmark INFO: eta: 7:10:25  iter: 30400  loss: 1.3056 (1.6382)  auxiliary_ctx: 0.1367 (0.1571)  auxiliary_frq: 0.1892 (0.2028)  auxiliary_vis: 0.1367 (0.1670)  loss_refine_obj: 0.6643 (0.8606)  loss_rel: 0.1944 (0.2507)  time: 1.0271 (1.3176)  data: 0.0108 (0.2634)  lr: 0.001200  max mem: 6540
2020-03-10 02:15:22,202 maskrcnn_benchmark INFO: eta: 7:05:26  iter: 30600  loss: 1.4125 (1.6366)  auxiliary_ctx: 0.1374 (0.1570)  auxiliary_frq: 0.1972 (0.2028)  auxiliary_vis: 0.1458 (0.1668)  loss_refine_obj: 0.6553 (0.8594)  loss_rel: 0.2175 (0.2505)  time: 1.0350 (1.3158)  data: 0.0096 (0.2617)  lr: 0.001200  max mem: 6540
2020-03-10 02:18:50,364 maskrcnn_benchmark INFO: eta: 7:00:28  iter: 30800  loss: 1.3120 (1.6351)  auxiliary_ctx: 0.1395 (0.1569)  auxiliary_frq: 0.1943 (0.2028)  auxiliary_vis: 0.1474 (0.1667)  loss_refine_obj: 0.6284 (0.8583)  loss_rel: 0.1924 (0.2503)  time: 1.0364 (1.3140)  data: 0.0107 (0.2601)  lr: 0.001200  max mem: 6540
2020-03-10 02:22:18,360 maskrcnn_benchmark INFO: eta: 6:55:32  iter: 31000  loss: 1.4470 (1.6338)  auxiliary_ctx: 0.1516 (0.1569)  auxiliary_frq: 0.2096 (0.2028)  auxiliary_vis: 0.1520 (0.1666)  loss_refine_obj: 0.6713 (0.8572)  loss_rel: 0.2445 (0.2502)  time: 1.0282 (1.3122)  data: 0.0098 (0.2585)  lr: 0.001200  max mem: 6540
2020-03-10 02:25:46,563 maskrcnn_benchmark INFO: eta: 6:50:37  iter: 31200  loss: 1.4220 (1.6324)  auxiliary_ctx: 0.1386 (0.1568)  auxiliary_frq: 0.1891 (0.2028)  auxiliary_vis: 0.1420 (0.1665)  loss_refine_obj: 0.7086 (0.8561)  loss_rel: 0.2110 (0.2501)  time: 1.0311 (1.3105)  data: 0.0109 (0.2569)  lr: 0.001200  max mem: 6540
2020-03-10 02:29:14,841 maskrcnn_benchmark INFO: eta: 6:45:43  iter: 31400  loss: 1.3901 (1.6309)  auxiliary_ctx: 0.1406 (0.1568)  auxiliary_frq: 0.1979 (0.2028)  auxiliary_vis: 0.1518 (0.1664)  loss_refine_obj: 0.6788 (0.8550)  loss_rel: 0.2036 (0.2499)  time: 1.0211 (1.3088)  data: 0.0109 (0.2553)  lr: 0.001200  max mem: 6540
2020-03-10 02:32:42,182 maskrcnn_benchmark INFO: eta: 6:40:49  iter: 31600  loss: 1.3049 (1.6296)  auxiliary_ctx: 0.1354 (0.1567)  auxiliary_frq: 0.1845 (0.2028)  auxiliary_vis: 0.1353 (0.1663)  loss_refine_obj: 0.5964 (0.8540)  loss_rel: 0.1976 (0.2498)  time: 1.0239 (1.3071)  data: 0.0094 (0.2538)  lr: 0.001200  max mem: 6540
2020-03-10 02:36:10,979 maskrcnn_benchmark INFO: eta: 6:35:58  iter: 31800  loss: 1.3847 (1.6282)  auxiliary_ctx: 0.1177 (0.1566)  auxiliary_frq: 0.1800 (0.2027)  auxiliary_vis: 0.1266 (0.1662)  loss_refine_obj: 0.6844 (0.8530)  loss_rel: 0.1952 (0.2496)  time: 1.0392 (1.3054)  data: 0.0109 (0.2522)  lr: 0.001200  max mem: 6540
2020-03-10 02:39:38,505 maskrcnn_benchmark INFO: ---Total norm 1.50117 clip coef 3.33073-----------------
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.89337, (torch.Size([4096, 4096]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.77505, (torch.Size([4096, 12544]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.58321, (torch.Size([3072, 5136]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.40131, (torch.Size([4096, 12544]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.33323, (torch.Size([151, 512]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.19365, (torch.Size([256, 1024, 3, 3]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.17943, (torch.Size([4096, 4096]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.14489, (torch.Size([51, 4096]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.14449, (torch.Size([2048, 4808]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.13032, (torch.Size([51, 4096]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.11890, (torch.Size([4096, 1024]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.11612, (torch.Size([2048, 4808]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.11530, (torch.Size([151, 200]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.10852, (torch.Size([2048, 4424]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.10063, (torch.Size([2560, 512]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.10015, (torch.Size([512, 32]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.09290, (torch.Size([4096, 512]))
2020-03-10 02:39:38,515 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.07489, (torch.Size([256, 128, 3, 3]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.06575, (torch.Size([128, 2, 7, 7]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.06441, (torch.Size([2048, 4424]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.05008, (torch.Size([512, 1024]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.04822, (torch.Size([151]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.04061, (torch.Size([3072]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.04033, (torch.Size([151, 200]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.03000, (torch.Size([1024, 512]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.02859, (torch.Size([512]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.02776, (torch.Size([512]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.02748, (torch.Size([152, 200]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.02545, (torch.Size([51]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.02498, (torch.Size([512, 1024]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.02225, (torch.Size([4096]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.02039, (torch.Size([256]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.01947, (torch.Size([128, 32]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.01891, (torch.Size([32, 9]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.01876, (torch.Size([51]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01727, (torch.Size([128]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01672, (torch.Size([2048, 512]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.01568, (torch.Size([512]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.01470, (torch.Size([2560]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.01461, (torch.Size([4096]))
2020-03-10 02:39:38,516 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01441, (torch.Size([2048]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01441, (torch.Size([2048]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01423, (torch.Size([22801, 51]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.01377, (torch.Size([2048, 512]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01276, (torch.Size([4096]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01262, (torch.Size([4096]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.01229, (torch.Size([128]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01184, (torch.Size([2048, 512]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.01160, (torch.Size([128]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.01146, (torch.Size([128]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01136, (torch.Size([2048]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01136, (torch.Size([2048]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01023, (torch.Size([1024]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00852, (torch.Size([256]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00785, (torch.Size([2048]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00785, (torch.Size([2048]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00769, (torch.Size([256]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00767, (torch.Size([32]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00485, (torch.Size([4096]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00479, (torch.Size([2048]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00479, (torch.Size([2048]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00449, (torch.Size([4096]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00427, (torch.Size([32]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00415, (torch.Size([2048, 512]))
2020-03-10 02:39:38,517 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00187, (torch.Size([256]))
2020-03-10 02:39:38,518 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00001, (torch.Size([32]))
2020-03-10 02:39:38,518 maskrcnn_benchmark INFO: -------------------------------
2020-03-10 02:39:38,520 maskrcnn_benchmark INFO: eta: 6:31:07  iter: 32000  loss: 1.3212 (1.6270)  auxiliary_ctx: 0.1371 (0.1565)  auxiliary_frq: 0.1909 (0.2027)  auxiliary_vis: 0.1359 (0.1661)  loss_refine_obj: 0.6807 (0.8521)  loss_rel: 0.2058 (0.2495)  time: 1.0649 (1.3037)  data: 0.0108 (0.2507)  lr: 0.001200  max mem: 6540
2020-03-10 02:39:38,522 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgcls/model_0032000.pth
2020-03-10 02:39:40,009 maskrcnn_benchmark INFO: Start validating
2020-03-10 02:39:40,024 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-10 02:46:37,860 maskrcnn_benchmark INFO: Total run time: 0:06:57.835970 (0.1671343879699707 s / img per device, on 2 devices)
2020-03-10 02:46:37,860 maskrcnn_benchmark INFO: Model inference time: 0:06:21.755362 (0.15270214490890502 s / img per device, on 2 devices)
2020-03-10 02:47:52,428 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5990
====================================================================================================
SGG eval:   R @ 20: 0.3985;   R @ 50: 0.4263;   R @ 100: 0.4341;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4573; ngR @ 50: 0.5266; ngR @ 100: 0.5609;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0267;  zR @ 50: 0.0622;  zR @ 100: 0.0637;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0696;  mR @ 50: 0.0811;  mR @ 100: 0.0881;  for mode=sgcls, type=Mean Recall.
(above:0.1133) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0665) (attached to:0.0000) (behind:0.3070) (belonging to:0.0000) (between:0.0000) (carrying:0.1820) (covered in:0.0714) (covering:0.0000) (eating:0.2143) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5364) (holding:0.2823) (in:0.1889) (in front of:0.0474) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3661) (of:0.2793) (on:0.5895) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2247) (says:0.0000) (sitting on:0.1086) (standing on:0.0000) (to:0.0000) (under:0.1156) (using:0.0000) (walking in:0.0000) (walking on:0.0128) (watching:0.0784) (wearing:0.5356) (wears:0.0000) (with:0.0251) 
SGG eval:   A @ 20: 0.4578;   A @ 50: 0.4610;   A @ 100: 0.4610;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

2020-03-10 02:47:52,998 maskrcnn_benchmark INFO: Validation Result: 0.4341
2020-03-10 02:47:52,999 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-03-10 02:47:52,999 maskrcnn_benchmark INFO: Trigger MAX_DECAY_STEP at iteration 32000.
2020-03-10 02:47:53,096 maskrcnn_benchmark INFO: Total training time: 11:43:34.070296 (0.8443 s / it)
2020-03-10 02:47:54,463 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(26446 images).
2020-03-10 03:24:59,425 maskrcnn_benchmark INFO: Total run time: 0:37:04.961633 (0.1682645113396228 s / img per device, on 2 devices)
2020-03-10 03:24:59,426 maskrcnn_benchmark INFO: Model inference time: 0:33:53.174200 (0.1537604325839812 s / img per device, on 2 devices)
2020-03-10 03:31:44,189 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.5776
====================================================================================================
SGG eval:   R @ 20: 0.3602;   R @ 50: 0.3925;   R @ 100: 0.4007;  for mode=sgcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.4113; ngR @ 50: 0.4892; ngR @ 100: 0.5250;  for mode=sgcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0106;  zR @ 50: 0.0218;  zR @ 100: 0.0307;  for mode=sgcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0650;  mR @ 50: 0.0802;  mR @ 100: 0.0851;  for mode=sgcls, type=Mean Recall.
(above:0.0929) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0059) (at:0.1512) (attached to:0.0000) (behind:0.3682) (belonging to:0.0000) (between:0.0000) (carrying:0.0394) (covered in:0.0631) (covering:0.0000) (eating:0.0585) (flying in:0.0000) (for:0.0317) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.5330) (holding:0.3813) (in:0.1908) (in front of:0.0410) (laying on:0.0000) (looking at:0.0228) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.2882) (of:0.4040) (on:0.4759) (on back of:0.0000) (over:0.0488) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1767) (says:0.0000) (sitting on:0.1121) (standing on:0.0000) (to:0.0000) (under:0.1744) (using:0.0000) (walking in:0.0000) (walking on:0.0057) (watching:0.0451) (wearing:0.5123) (wears:0.0000) (with:0.0298) 
SGG eval:   A @ 20: 0.4065;   A @ 50: 0.4076;   A @ 100: 0.4076;  for mode=sgcls, type=TopK Accuracy.
====================================================================================================

