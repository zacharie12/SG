2020-05-03 09:18:27,641 maskrcnn_benchmark INFO: Using 2 GPUs
2020-05-03 09:18:27,642 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'False', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'none', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'sum', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'SOLVER.IMS_PER_BATCH', '16', 'TEST.IMS_PER_BATCH', '2', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '50000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', '/glove', 'MODEL.PRETRAINED_DETECTOR_CKPT', '/checkpoints/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', '/checkpoints/causal-tde-sgcls'], skip_test=False)
2020-05-03 09:18:27,642 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-05-03 09:18:30,097 maskrcnn_benchmark INFO: 
PyTorch version: 1.4.0
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: GeForce GTX 1080 Ti
GPU 1: GeForce GTX 1080 Ti
GPU 2: GeForce GTX 1080 Ti
GPU 3: GeForce GTX 1080 Ti

Nvidia driver version: 440.33.01
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5

Versions of relevant libraries:
[pip] numpy==1.18.3
[pip] torch==1.4.0
[pip] torchvision==0.5.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.0                      166  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.0.15           py36ha843d7b_0  
[conda] mkl_random                1.1.0            py36hd6b4f25_0  
[conda] pytorch                   1.4.0           py3.6_cuda10.1.243_cudnn7.6.3_0    pytorch
[conda] torchvision               0.5.0                py36_cu101    pytorch
        Pillow (7.0.0)
2020-05-03 09:18:30,097 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-05-03 09:18:30,098 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-05-03 09:18:30,100 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: /glove
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: /checkpoints/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: /checkpoints/causal-tde-sgcls
PATHS_CATALOG: /Scene-Graph-Benchmark.pytorch/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /Scene-Graph-Benchmark.pytorch/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 16
  MAX_ITER: 50000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-05-03 09:18:30,100 maskrcnn_benchmark INFO: Saving config into: /checkpoints/causal-tde-sgcls/config.yml
2020-05-03 09:18:30,157 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-05-03 09:18:35,372 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-05-03 09:18:35,388 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-05-03 09:18:35,390 maskrcnn_benchmark.data.build INFO: Loading data statistics from: /checkpoints/causal-tde-sgcls/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-05-03 09:18:35,390 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
loading word vectors from /glove/glove.6B.200d.pt
loading word vectors from /glove/glove.6B.200d.pt
__background__ -> __background__ 
fail on __background__
__background__ -> __background__ 
fail on __background__
loading word vectors from /glove/glove.6B.200d.pt
loading word vectors from /glove/glove.6B.200d.pt
__background__ -> __background__ 
__background__ -> __background__ 
fail on __background__
fail on __background__
2020-05-03 09:18:37,031 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-05-03 09:18:37,624 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
2020-05-03 09:18:37,669 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-05-03 09:18:37,671 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /checkpoints/pretrained_faster_rcnn/model_final.pth
2020-05-03 09:18:38,536 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.
2020-05-03 09:18:38,536 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.
2020-05-03 09:18:38,536 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.
2020-05-03 09:18:38,536 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.
2020-05-03 09:18:38,536 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.
2020-05-03 09:18:38,536 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.
2020-05-03 09:18:38,536 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.
2020-05-03 09:18:38,536 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.
2020-05-03 09:18:38,536 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.
2020-05-03 09:18:38,536 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.
2020-05-03 09:18:38,628 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.bias                                           loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2020-05-03 09:18:38,628 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.weight                                         loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2020-05-03 09:18:38,628 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.bias                                           loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2020-05-03 09:18:38,628 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.weight                                         loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2020-05-03 09:18:38,628 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.avg_post_ctx of shape (4096,)
2020-05-03 09:18:38,628 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias of shape (3072,)
2020-05-03 09:18:38,628 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight of shape (3072, 5136)
2020-05-03 09:18:38,628 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight of shape (152, 200)
2020-05-03 09:18:38,628 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias of shape (151,)
2020-05-03 09:18:38,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight of shape (151, 512)
2020-05-03 09:18:38,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias of shape (2560,)
2020-05-03 09:18:38,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight of shape (2560, 512)
2020-05-03 09:18:38,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0 of shape (2048,)
2020-05-03 09:18:38,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2020-05-03 09:18:38,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0 of shape (2048,)
2020-05-03 09:18:38,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2020-05-03 09:18:38,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2020-05-03 09:18:38,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2020-05-03 09:18:38,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0 of shape (2048, 4808)
2020-05-03 09:18:38,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4808)
2020-05-03 09:18:38,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias of shape (512,)
2020-05-03 09:18:38,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight of shape (512, 1024)
2020-05-03 09:18:38,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias of shape (512,)
2020-05-03 09:18:38,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight of shape (512, 1024)
2020-05-03 09:18:38,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0 of shape (2048,)
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0 of shape (2048,)
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0 of shape (2048, 4424)
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4424)
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight of shape (151, 200)
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight of shape (151, 200)
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias of shape (32,)
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight of shape (32, 9)
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias of shape (32,)
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.num_batches_tracked of shape ()
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_mean of shape (32,)
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_var of shape (32,)
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight of shape (32,)
2020-05-03 09:18:38,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias of shape (128,)
2020-05-03 09:18:38,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight of shape (128, 32)
2020-05-03 09:18:38,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_dcd_feat of shape (4936,)
2020-05-03 09:18:38,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_edg_feat of shape (4296,)
2020-05-03 09:18:38,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_obj_feat of shape (4424,)
2020-05-03 09:18:38,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.bias of shape (51,)
2020-05-03 09:18:38,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.weight of shape (51, 4096)
2020-05-03 09:18:38,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight of shape (22801, 51)
2020-05-03 09:18:38,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.bias of shape (4096,)
2020-05-03 09:18:38,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.weight of shape (4096, 1024)
2020-05-03 09:18:38,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.bias of shape (1024,)
2020-05-03 09:18:38,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.weight of shape (1024, 512)
2020-05-03 09:18:38,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.bias of shape (512,)
2020-05-03 09:18:38,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.weight of shape (512, 32)
2020-05-03 09:18:38,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.bias of shape (4096,)
2020-05-03 09:18:38,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.weight of shape (4096, 512)
2020-05-03 09:18:38,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_conv_spt of shape (4096,)
2020-05-03 09:18:38,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_feat of shape (4096,)
2020-05-03 09:18:38,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_spt of shape (32,)
2020-05-03 09:18:38,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.bias of shape (51,)
2020-05-03 09:18:38,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.weight of shape (51, 4096)
2020-05-03 09:18:38,632 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                       loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2020-05-03 09:18:38,632 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                     loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2020-05-03 09:18:38,632 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                       loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2020-05-03 09:18:38,632 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                     loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2020-05-03 09:18:38,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)
2020-05-03 09:18:38,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)
2020-05-03 09:18:38,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)
2020-05-03 09:18:38,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)
2020-05-03 09:18:38,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)
2020-05-03 09:18:38,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()
2020-05-03 09:18:38,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)
2020-05-03 09:18:38,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)
2020-05-03 09:18:38,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)
2020-05-03 09:18:38,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)
2020-05-03 09:18:38,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)
2020-05-03 09:18:38,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)
2020-05-03 09:18:38,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()
2020-05-03 09:18:38,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)
2020-05-03 09:18:38,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)
2020-05-03 09:18:38,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)
2020-05-03 09:18:38,942 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-05-03 09:18:38,942 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-05-03 09:19:01,859 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into /checkpoints/causal-tde-sgcls/labels.json
2020-05-03 09:19:03,737 maskrcnn_benchmark INFO: #################### end dataloader ####################
2020-05-03 09:19:03,738 maskrcnn_benchmark INFO: Validate before training
2020-05-03 09:19:03,764 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
OBJ_DISTS:  tensor([[ 0.1401,  0.0043,  0.0523,  ..., -0.0472,  0.0382,  0.0235],
        [ 0.0352, -0.0118, -0.0157,  ..., -0.0301,  0.0391,  0.0363],
        [ 0.1228,  0.0442,  0.1417,  ...,  0.1519,  0.1215,  0.0345],
        ...,
        [-0.0551, -0.0265,  0.2285,  ...,  0.1331, -0.0365,  0.0134],
        [-0.0457,  0.0127, -0.0157,  ...,  0.0256,  0.0668, -0.0350],
        [ 0.1902,  0.0792,  0.0612,  ...,  0.1753,  0.2405, -0.0096]],
       device='cuda:1', dtype=torch.float16)
OBJ_PREDS:  tensor([ 34, 109, 132,  10, 119, 113,  58,  16,   2,  88,   6,  82, 122, 113,
        113, 136,  73, 145, 121, 113,  48,  64, 113,  88,  37, 143],
       device='cuda:1')
OBJ_CTX:  tensor([[-2.5049e-01,  6.3354e-02, -4.1901e-02,  ..., -1.1365e-01,
         -2.9282e-02, -3.9246e-02],
        [-1.1279e-01,  3.1067e-02, -3.9795e-02,  ..., -2.0569e-01,
         -1.8237e-01,  1.1420e-01],
        [-6.7566e-02, -6.6345e-02, -1.6272e-01,  ..., -1.1523e-01,
         -2.4780e-01, -7.2083e-02],
        ...,
        [-7.0129e-02, -1.2805e-01,  5.6549e-02,  ..., -8.8562e-02,
          1.2054e-01,  8.5999e-02],
        [ 4.9469e-02,  2.4462e-04, -4.2206e-02,  ..., -1.7639e-02,
         -1.7090e-02, -1.2703e-03],
        [-1.1255e-01,  5.4596e-02, -7.3853e-02,  ..., -1.2463e-01,
          4.6661e-02, -1.0529e-01]], device='cuda:1', dtype=torch.float16)
INV_PERM:  tensor([13, 15, 19,  5, 17, 14,  9, 23, 24, 11, 18, 22,  6,  3,  7,  4, 21,  8,
        20, 10, 12,  1,  2, 25,  0, 16], device='cuda:1')
ls_transposed:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1])
OBJ_DISTS:  tensor([[ 0.0200, -0.0046,  0.0209,  ..., -0.0126,  0.0161, -0.0297],
        [ 0.0133,  0.0072,  0.0137,  ..., -0.0452,  0.0301, -0.0276],
        [ 0.0472,  0.0076,  0.0495,  ..., -0.0081,  0.0341, -0.0286],
        ...,
        [ 0.0306,  0.0185,  0.0381,  ..., -0.0250,  0.0161, -0.0273],
        [ 0.0187, -0.0227,  0.0260,  ..., -0.0316,  0.0212, -0.0140],
        [ 0.0305,  0.0185,  0.0381,  ..., -0.0250,  0.0161, -0.0273]],
       device='cuda:1', dtype=torch.float16)
OBJ_PREDS:  tensor([ 53, 121, 113,  96,   2,  96,  40,  96, 121, 138,  40,  53, 121,  39,
         25,  53,  39,   2, 138, 113,  39, 113, 138,  25,  40,  25],
       device='cuda:1')
OBJ_CTX:  tensor([[-2.5049e-01,  6.3354e-02, -4.1901e-02,  ..., -1.1365e-01,
         -2.9282e-02, -3.9246e-02],
        [-1.1279e-01,  3.1067e-02, -3.9795e-02,  ..., -2.0569e-01,
         -1.8237e-01,  1.1420e-01],
        [-6.7566e-02, -6.6345e-02, -1.6272e-01,  ..., -1.1523e-01,
         -2.4780e-01, -7.2083e-02],
        ...,
        [-7.0129e-02, -1.2805e-01,  5.6549e-02,  ..., -8.8562e-02,
          1.2054e-01,  8.5999e-02],
        [ 4.9469e-02,  2.4462e-04, -4.2206e-02,  ..., -1.7639e-02,
         -1.7090e-02, -1.2703e-03],
        [-1.1255e-01,  5.4596e-02, -7.3853e-02,  ..., -1.2463e-01,
          4.6661e-02, -1.0529e-01]], device='cuda:1', dtype=torch.float16)
INV_PERM:  tensor([13, 15, 19,  5, 17, 14,  9, 23, 24, 11, 18, 22,  6,  3,  7,  4, 21,  8,
        20, 10, 12,  1,  2, 25,  0, 16], device='cuda:1')
ls_transposed:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1])
RELATION LOGITS:  (tensor([[ 0.2504, -6.3326, -6.4634,  ..., -7.1448, -6.8999, -7.0583],
        [-0.2763, -6.7549, -6.8455,  ..., -7.3201, -6.5701, -7.0436],
        [-0.7085, -3.3181, -6.5340,  ..., -6.8913, -6.5437, -6.9210],
        ...,
        [-0.2649, -6.5672, -6.1714,  ..., -7.3672, -6.6687, -6.9723],
        [ 0.2847, -6.5962, -6.7937,  ..., -7.1567, -6.7884, -6.8713],
        [-0.0431, -6.4324, -6.7398,  ..., -7.5030, -6.5694, -6.9661]],
       device='cuda:1'),)
REFINE_LOGITS:  (tensor([[ 0.1401,  0.0043,  0.0523,  ..., -0.0472,  0.0382,  0.0235],
        [ 0.0352, -0.0118, -0.0157,  ..., -0.0301,  0.0391,  0.0363],
        [ 0.1228,  0.0442,  0.1417,  ...,  0.1519,  0.1215,  0.0345],
        ...,
        [-0.0551, -0.0265,  0.2285,  ...,  0.1331, -0.0365,  0.0134],
        [-0.0457,  0.0127, -0.0157,  ...,  0.0256,  0.0668, -0.0350],
        [ 0.1902,  0.0792,  0.0612,  ...,  0.1753,  0.2405, -0.0096]],
       device='cuda:1', dtype=torch.float16),)
PROPOSALS:  [BoxList(num_boxes=26, image_width=800, image_height=600, mode=xyxy)]
REL_PAIR_IDX:  [tensor([[ 0,  1],
        [ 0,  2],
        [ 0,  3],
        ...,
        [25, 22],
        [25, 23],
        [25, 24]], device='cuda:1')]
RESULT: [BoxList(num_boxes=26, image_width=800, image_height=600, mode=xyxy)]
OBJ_DISTS:  tensor([[ 4.0527e-02, -1.6144e-02, -1.4221e-02,  ..., -1.2436e-02,
          8.5266e-02, -5.4779e-02],
        [ 4.7729e-02, -7.8979e-02, -9.9487e-03,  ..., -1.5205e-02,
          8.3984e-02, -1.0052e-01],
        [ 6.0028e-02, -3.4760e-02,  1.5588e-01,  ...,  8.4412e-02,
          1.5479e-01, -7.2975e-03],
        ...,
        [ 7.8308e-02, -4.8859e-02,  7.1411e-02,  ..., -1.9363e-02,
          5.7739e-02, -1.4400e-03],
        [ 7.3303e-02,  4.8248e-02, -8.8272e-03,  ..., -1.0394e-01,
          6.5308e-02, -1.6754e-02],
        [-8.0032e-03, -6.4148e-02, -7.9215e-05,  ...,  2.6001e-02,
          2.2797e-02, -6.7200e-02]], device='cuda:0', dtype=torch.float16)
OBJ_PREDS:  tensor([132, 142,  83, 122,  72, 103,  77, 113,  96,  96, 113,  96,  96,  77,
         77, 103,  72,  96, 132, 113,  30, 113], device='cuda:0')
OBJ_CTX:  tensor([[-0.2418, -0.0544,  0.1641,  ...,  0.0093, -0.0740,  0.0764],
        [-0.1744, -0.0869,  0.1827,  ..., -0.0616, -0.0467,  0.0091],
        [-0.2172,  0.1001,  0.1337,  ..., -0.0864,  0.0213, -0.0265],
        ...,
        [-0.2052,  0.1238, -0.0038,  ..., -0.0578, -0.0693,  0.0362],
        [-0.1289, -0.0129,  0.0334,  ..., -0.0711, -0.0782,  0.0088],
        [-0.1501, -0.0047,  0.0940,  ...,  0.0090, -0.0831,  0.1580]],
       device='cuda:0', dtype=torch.float16)
INV_PERM:  tensor([11,  9, 18,  0, 21, 19, 15, 20, 16, 17, 14, 13, 10,  5,  6,  3,  2,  1,
        12,  7,  8,  4], device='cuda:0')
ls_transposed:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
OBJ_DISTS:  tensor([[ 0.0269, -0.0038,  0.0452,  ..., -0.0168,  0.0209, -0.0233],
        [ 0.0286, -0.0107,  0.0406,  ..., -0.0188,  0.0013, -0.0227],
        [ 0.0286, -0.0107,  0.0406,  ..., -0.0188,  0.0013, -0.0228],
        ...,
        [ 0.0305,  0.0185,  0.0381,  ..., -0.0249,  0.0161, -0.0272],
        [ 0.0085, -0.0086,  0.0687,  ..., -0.0390,  0.0319, -0.0293],
        [ 0.0200, -0.0050,  0.0211,  ..., -0.0126,  0.0156, -0.0291]],
       device='cuda:0', dtype=torch.float16)
OBJ_PREDS:  tensor([138,  40,  40,  40,  39, 113, 121, 138,  25,   2,  96,  53, 113,  96,
        121,  39, 138, 113,  39,  25,   2,  53], device='cuda:0')
OBJ_CTX:  tensor([[-0.2418, -0.0544,  0.1641,  ...,  0.0093, -0.0740,  0.0764],
        [-0.1744, -0.0869,  0.1827,  ..., -0.0616, -0.0467,  0.0091],
        [-0.2172,  0.1001,  0.1337,  ..., -0.0864,  0.0213, -0.0265],
        ...,
        [-0.2052,  0.1238, -0.0038,  ..., -0.0578, -0.0693,  0.0362],
        [-0.1289, -0.0129,  0.0334,  ..., -0.0711, -0.0782,  0.0088],
        [-0.1501, -0.0047,  0.0940,  ...,  0.0090, -0.0831,  0.1580]],
       device='cuda:0', dtype=torch.float16)
INV_PERM:  tensor([11,  9, 18,  0, 21, 19, 15, 20, 16, 17, 14, 13, 10,  5,  6,  3,  2,  1,
        12,  7,  8,  4], device='cuda:0')
ls_transposed:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
RELATION LOGITS:  (tensor([[-0.3157, -6.5481, -6.5030,  ..., -7.3172, -6.2637, -6.9272],
        [-0.9012, -6.5472, -6.4722,  ..., -7.3064, -6.2754, -6.9440],
        [-0.3918, -6.5884, -6.0796,  ..., -7.1072, -6.5970, -6.6685],
        ...,
        [ 0.0187, -6.5274, -6.5550,  ..., -7.3709, -6.4214, -6.8199],
        [-0.3407, -6.7316, -6.4102,  ..., -6.9430, -6.8572, -6.3936],
        [-0.6011, -6.5574, -6.6917,  ..., -7.0489, -6.8569, -6.3194]],
       device='cuda:0'),)
REFINE_LOGITS:  (tensor([[ 4.0527e-02, -1.6144e-02, -1.4221e-02,  ..., -1.2436e-02,
          8.5266e-02, -5.4779e-02],
        [ 4.7729e-02, -7.8979e-02, -9.9487e-03,  ..., -1.5205e-02,
          8.3984e-02, -1.0052e-01],
        [ 6.0028e-02, -3.4760e-02,  1.5588e-01,  ...,  8.4412e-02,
          1.5479e-01, -7.2975e-03],
        ...,
        [ 7.8308e-02, -4.8859e-02,  7.1411e-02,  ..., -1.9363e-02,
          5.7739e-02, -1.4400e-03],
        [ 7.3303e-02,  4.8248e-02, -8.8272e-03,  ..., -1.0394e-01,
          6.5308e-02, -1.6754e-02],
        [-8.0032e-03, -6.4148e-02, -7.9215e-05,  ...,  2.6001e-02,
          2.2797e-02, -6.7200e-02]], device='cuda:0', dtype=torch.float16),)
PROPOSALS:  [BoxList(num_boxes=22, image_width=983, image_height=600, mode=xyxy)]
REL_PAIR_IDX:  [tensor([[ 0,  1],
        [ 0,  2],
        [ 0,  3],
        [ 0,  4],
        [ 0,  5],
        [ 0,  6],
        [ 0,  7],
        [ 0,  8],
        [ 0,  9],
        [ 0, 10],
        [ 0, 11],
        [ 0, 12],
        [ 0, 13],
        [ 0, 14],
        [ 0, 15],
        [ 0, 16],
        [ 0, 17],
        [ 0, 18],
        [ 0, 19],
        [ 0, 20],
        [ 0, 21],
        [ 1,  0],
        [ 1,  2],
        [ 1,  3],
        [ 1,  4],
        [ 1,  5],
        [ 1,  6],
        [ 1,  7],
        [ 1,  8],
        [ 1,  9],
        [ 1, 10],
        [ 1, 11],
        [ 1, 12],
        [ 1, 13],
        [ 1, 14],
        [ 1, 15],
        [ 1, 16],
        [ 1, 17],
        [ 1, 18],
        [ 1, 19],
        [ 1, 20],
        [ 1, 21],
        [ 2,  0],
        [ 2,  1],
        [ 2,  3],
        [ 2,  4],
        [ 2,  5],
        [ 2,  6],
        [ 2,  7],
        [ 2,  8],
        [ 2,  9],
        [ 2, 10],
        [ 2, 11],
        [ 2, 12],
        [ 2, 13],
        [ 2, 14],
        [ 2, 15],
        [ 2, 16],
        [ 2, 17],
        [ 2, 18],
        [ 2, 19],
        [ 2, 20],
        [ 2, 21],
        [ 3,  0],
        [ 3,  1],
        [ 3,  2],
        [ 3,  4],
        [ 3,  5],
        [ 3,  6],
        [ 3,  7],
        [ 3,  8],
        [ 3,  9],
        [ 3, 10],
        [ 3, 11],
        [ 3, 12],
        [ 3, 13],
        [ 3, 14],
        [ 3, 15],
        [ 3, 16],
        [ 3, 17],
        [ 3, 18],
        [ 3, 19],
        [ 3, 20],
        [ 3, 21],
        [ 4,  0],
        [ 4,  1],
        [ 4,  2],
        [ 4,  3],
        [ 4,  5],
        [ 4,  6],
        [ 4,  7],
        [ 4,  8],
        [ 4,  9],
        [ 4, 10],
        [ 4, 11],
        [ 4, 12],
        [ 4, 13],
        [ 4, 14],
        [ 4, 15],
        [ 4, 16],
        [ 4, 17],
        [ 4, 18],
        [ 4, 19],
        [ 4, 20],
        [ 4, 21],
        [ 5,  0],
        [ 5,  1],
        [ 5,  2],
        [ 5,  3],
        [ 5,  4],
        [ 5,  6],
        [ 5,  7],
        [ 5,  8],
        [ 5,  9],
        [ 5, 10],
        [ 5, 11],
        [ 5, 12],
        [ 5, 13],
        [ 5, 14],
        [ 5, 15],
        [ 5, 16],
        [ 5, 17],
        [ 5, 18],
        [ 5, 19],
        [ 5, 20],
        [ 5, 21],
        [ 6,  0],
        [ 6,  1],
        [ 6,  2],
        [ 6,  3],
        [ 6,  4],
        [ 6,  5],
        [ 6,  7],
        [ 6,  8],
        [ 6,  9],
        [ 6, 10],
        [ 6, 11],
        [ 6, 12],
        [ 6, 13],
        [ 6, 14],
        [ 6, 15],
        [ 6, 16],
        [ 6, 17],
        [ 6, 18],
        [ 6, 19],
        [ 6, 20],
        [ 6, 21],
        [ 7,  0],
        [ 7,  1],
        [ 7,  2],
        [ 7,  3],
        [ 7,  4],
        [ 7,  5],
        [ 7,  6],
        [ 7,  8],
        [ 7,  9],
        [ 7, 10],
        [ 7, 11],
        [ 7, 12],
        [ 7, 13],
        [ 7, 14],
        [ 7, 15],
        [ 7, 16],
        [ 7, 17],
        [ 7, 18],
        [ 7, 19],
        [ 7, 20],
        [ 7, 21],
        [ 8,  0],
        [ 8,  1],
        [ 8,  2],
        [ 8,  3],
        [ 8,  4],
        [ 8,  5],
        [ 8,  6],
        [ 8,  7],
        [ 8,  9],
        [ 8, 10],
        [ 8, 11],
        [ 8, 12],
        [ 8, 13],
        [ 8, 14],
        [ 8, 15],
        [ 8, 16],
        [ 8, 17],
        [ 8, 18],
        [ 8, 19],
        [ 8, 20],
        [ 8, 21],
        [ 9,  0],
        [ 9,  1],
        [ 9,  2],
        [ 9,  3],
        [ 9,  4],
        [ 9,  5],
        [ 9,  6],
        [ 9,  7],
        [ 9,  8],
        [ 9, 10],
        [ 9, 11],
        [ 9, 12],
        [ 9, 13],
        [ 9, 14],
        [ 9, 15],
        [ 9, 16],
        [ 9, 17],
        [ 9, 18],
        [ 9, 19],
        [ 9, 20],
        [ 9, 21],
        [10,  0],
        [10,  1],
        [10,  2],
        [10,  3],
        [10,  4],
        [10,  5],
        [10,  6],
        [10,  7],
        [10,  8],
        [10,  9],
        [10, 11],
        [10, 12],
        [10, 13],
        [10, 14],
        [10, 15],
        [10, 16],
        [10, 17],
        [10, 18],
        [10, 19],
        [10, 20],
        [10, 21],
        [11,  0],
        [11,  1],
        [11,  2],
        [11,  3],
        [11,  4],
        [11,  5],
        [11,  6],
        [11,  7],
        [11,  8],
        [11,  9],
        [11, 10],
        [11, 12],
        [11, 13],
        [11, 14],
        [11, 15],
        [11, 16],
        [11, 17],
        [11, 18],
        [11, 19],
        [11, 20],
        [11, 21],
        [12,  0],
        [12,  1],
        [12,  2],
        [12,  3],
        [12,  4],
        [12,  5],
        [12,  6],
        [12,  7],
        [12,  8],
        [12,  9],
        [12, 10],
        [12, 11],
        [12, 13],
        [12, 14],
        [12, 15],
        [12, 16],
        [12, 17],
        [12, 18],
        [12, 19],
        [12, 20],
        [12, 21],
        [13,  0],
        [13,  1],
        [13,  2],
        [13,  3],
        [13,  4],
        [13,  5],
        [13,  6],
        [13,  7],
        [13,  8],
        [13,  9],
        [13, 10],
        [13, 11],
        [13, 12],
        [13, 14],
        [13, 15],
        [13, 16],
        [13, 17],
        [13, 18],
        [13, 19],
        [13, 20],
        [13, 21],
        [14,  0],
        [14,  1],
        [14,  2],
        [14,  3],
        [14,  4],
        [14,  5],
        [14,  6],
        [14,  7],
        [14,  8],
        [14,  9],
        [14, 10],
        [14, 11],
        [14, 12],
        [14, 13],
        [14, 15],
        [14, 16],
        [14, 17],
        [14, 18],
        [14, 19],
        [14, 20],
        [14, 21],
        [15,  0],
        [15,  1],
        [15,  2],
        [15,  3],
        [15,  4],
        [15,  5],
        [15,  6],
        [15,  7],
        [15,  8],
        [15,  9],
        [15, 10],
        [15, 11],
        [15, 12],
        [15, 13],
        [15, 14],
        [15, 16],
        [15, 17],
        [15, 18],
        [15, 19],
        [15, 20],
        [15, 21],
        [16,  0],
        [16,  1],
        [16,  2],
        [16,  3],
        [16,  4],
        [16,  5],
        [16,  6],
        [16,  7],
        [16,  8],
        [16,  9],
        [16, 10],
        [16, 11],
        [16, 12],
        [16, 13],
        [16, 14],
        [16, 15],
        [16, 17],
        [16, 18],
        [16, 19],
        [16, 20],
        [16, 21],
        [17,  0],
        [17,  1],
        [17,  2],
        [17,  3],
        [17,  4],
        [17,  5],
        [17,  6],
        [17,  7],
        [17,  8],
        [17,  9],
        [17, 10],
        [17, 11],
        [17, 12],
        [17, 13],
        [17, 14],
        [17, 15],
        [17, 16],
        [17, 18],
        [17, 19],
        [17, 20],
        [17, 21],
        [18,  0],
        [18,  1],
        [18,  2],
        [18,  3],
        [18,  4],
        [18,  5],
        [18,  6],
        [18,  7],
        [18,  8],
        [18,  9],
        [18, 10],
        [18, 11],
        [18, 12],
        [18, 13],
        [18, 14],
        [18, 15],
        [18, 16],
        [18, 17],
        [18, 19],
        [18, 20],
        [18, 21],
        [19,  0],
        [19,  1],
        [19,  2],
        [19,  3],
        [19,  4],
        [19,  5],
        [19,  6],
        [19,  7],
        [19,  8],
        [19,  9],
        [19, 10],
        [19, 11],
        [19, 12],
        [19, 13],
        [19, 14],
        [19, 15],
        [19, 16],
        [19, 17],
        [19, 18],
        [19, 20],
        [19, 21],
        [20,  0],
        [20,  1],
        [20,  2],
        [20,  3],
        [20,  4],
        [20,  5],
        [20,  6],
        [20,  7],
        [20,  8],
        [20,  9],
        [20, 10],
        [20, 11],
        [20, 12],
        [20, 13],
        [20, 14],
        [20, 15],
        [20, 16],
        [20, 17],
        [20, 18],
        [20, 19],
        [20, 21],
        [21,  0],
        [21,  1],
        [21,  2],
        [21,  3],
        [21,  4],
        [21,  5],
        [21,  6],
        [21,  7],
        [21,  8],
        [21,  9],
        [21, 10],
        [21, 11],
        [21, 12],
        [21, 13],
        [21, 14],
        [21, 15],
        [21, 16],
        [21, 17],
        [21, 18],
        [21, 19],
        [21, 20]], device='cuda:0')]
RESULT: [BoxList(num_boxes=22, image_width=983, image_height=600, mode=xyxy)]
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
