2020-03-09 14:54:15,238 maskrcnn_benchmark INFO: Using 2 GPUs
2020-03-09 14:54:15,238 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'True', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'True', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'none', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'sum', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'SOLVER.IMS_PER_BATCH', '12', 'TEST.IMS_PER_BATCH', '2', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '50000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', '/home/kaihua/glove', 'MODEL.PRETRAINED_DETECTOR_CKPT', '/home/kaihua/checkpoints/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', '/home/kaihua/checkpoints/upload_causal_motif_predcls'], skip_test=False)
2020-03-09 14:54:15,238 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-03-09 14:54:19,920 maskrcnn_benchmark INFO: 
PyTorch version: 1.4.0
Is debug build: No
CUDA used to build PyTorch: 10.0

OS: Ubuntu 16.04.5 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: Could not collect

Python version: 3.8
Is CUDA available: Yes
CUDA runtime version: 10.0.130
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti

Nvidia driver version: 415.27
cuDNN version: Could not collect

Versions of relevant libraries:
[pip] numpy==1.18.1
[pip] torch==1.4.0
[pip] torchvision==0.5.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2019.4                      243  
[conda] mkl-service               2.3.0            py38he904b0f_0  
[conda] mkl_fft                   1.0.15           py38ha843d7b_0  
[conda] mkl_random                1.1.0            py38h962f231_0  
[conda] pytorch                   1.4.0           py3.8_cuda10.0.130_cudnn7.6.3_0    pytorch
[conda] torchvision               0.5.0                py38_cu100    pytorch
        Pillow (7.0.0)
2020-03-09 14:54:19,920 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-03-09 14:54:19,920 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-03-09 14:54:19,922 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: /home/kaihua/glove
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: /home/kaihua/checkpoints/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: /home/kaihua/checkpoints/upload_causal_motif_predcls
PATHS_CATALOG: /data1/kaihua/projects/sgg-test/scene-graph-benchmark/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /data1/kaihua/projects/sgg-test/scene-graph-benchmark/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 12
  MAX_ITER: 50000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-03-09 14:54:19,922 maskrcnn_benchmark INFO: Saving config into: /home/kaihua/checkpoints/upload_causal_motif_predcls/config.yml
2020-03-09 14:54:19,952 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-03-09 14:54:22,542 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-03-09 14:54:22,542 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-03-09 14:54:49,079 maskrcnn_benchmark.data.build INFO: finish
2020-03-09 14:54:49,079 maskrcnn_benchmark.data.build INFO: Save data statistics to: /home/kaihua/checkpoints/upload_causal_motif_predcls/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-03-09 14:54:49,079 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-03-09 14:54:49,937 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-03-09 14:54:50,370 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-03-09 14:54:50,393 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-03-09 14:54:50,393 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /home/kaihua/checkpoints/pretrained_faster_rcnn/model_final.pth
2020-03-09 14:54:56,566 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.
2020-03-09 14:54:56,567 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.
2020-03-09 14:54:56,567 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.
2020-03-09 14:54:56,567 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.
2020-03-09 14:54:56,567 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.
2020-03-09 14:54:56,567 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.
2020-03-09 14:54:56,567 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.
2020-03-09 14:54:56,567 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.
2020-03-09 14:54:56,567 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.
2020-03-09 14:54:56,567 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.
2020-03-09 14:54:56,629 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.bias                                           loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2020-03-09 14:54:56,629 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.weight                                         loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2020-03-09 14:54:56,629 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.bias                                           loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2020-03-09 14:54:56,629 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.weight                                         loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2020-03-09 14:54:56,629 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.avg_post_ctx of shape (4096,)
2020-03-09 14:54:56,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias of shape (3072,)
2020-03-09 14:54:56,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight of shape (3072, 5136)
2020-03-09 14:54:56,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight of shape (152, 200)
2020-03-09 14:54:56,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias of shape (151,)
2020-03-09 14:54:56,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight of shape (151, 512)
2020-03-09 14:54:56,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias of shape (2560,)
2020-03-09 14:54:56,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight of shape (2560, 512)
2020-03-09 14:54:56,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0 of shape (2048,)
2020-03-09 14:54:56,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2020-03-09 14:54:56,630 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0 of shape (2048,)
2020-03-09 14:54:56,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2020-03-09 14:54:56,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2020-03-09 14:54:56,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2020-03-09 14:54:56,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0 of shape (2048, 4808)
2020-03-09 14:54:56,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4808)
2020-03-09 14:54:56,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias of shape (512,)
2020-03-09 14:54:56,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight of shape (512, 1024)
2020-03-09 14:54:56,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias of shape (512,)
2020-03-09 14:54:56,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight of shape (512, 1024)
2020-03-09 14:54:56,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0 of shape (2048,)
2020-03-09 14:54:56,631 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2020-03-09 14:54:56,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0 of shape (2048,)
2020-03-09 14:54:56,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2020-03-09 14:54:56,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2020-03-09 14:54:56,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2020-03-09 14:54:56,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0 of shape (2048, 4424)
2020-03-09 14:54:56,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4424)
2020-03-09 14:54:56,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight of shape (151, 200)
2020-03-09 14:54:56,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight of shape (151, 200)
2020-03-09 14:54:56,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias of shape (32,)
2020-03-09 14:54:56,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight of shape (32, 9)
2020-03-09 14:54:56,632 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias of shape (32,)
2020-03-09 14:54:56,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.num_batches_tracked of shape ()
2020-03-09 14:54:56,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_mean of shape (32,)
2020-03-09 14:54:56,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_var of shape (32,)
2020-03-09 14:54:56,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight of shape (32,)
2020-03-09 14:54:56,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias of shape (128,)
2020-03-09 14:54:56,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight of shape (128, 32)
2020-03-09 14:54:56,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_dcd_feat of shape (4936,)
2020-03-09 14:54:56,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_edg_feat of shape (4296,)
2020-03-09 14:54:56,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_obj_feat of shape (4424,)
2020-03-09 14:54:56,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.bias of shape (51,)
2020-03-09 14:54:56,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.weight of shape (51, 4096)
2020-03-09 14:54:56,633 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight of shape (22801, 51)
2020-03-09 14:54:56,634 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.bias of shape (4096,)
2020-03-09 14:54:56,634 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.weight of shape (4096, 1024)
2020-03-09 14:54:56,634 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.bias of shape (1024,)
2020-03-09 14:54:56,634 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.weight of shape (1024, 512)
2020-03-09 14:54:56,634 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.bias of shape (512,)
2020-03-09 14:54:56,634 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.weight of shape (512, 32)
2020-03-09 14:54:56,634 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.bias of shape (4096,)
2020-03-09 14:54:56,634 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.weight of shape (4096, 512)
2020-03-09 14:54:56,634 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_conv_spt of shape (4096,)
2020-03-09 14:54:56,634 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_feat of shape (4096,)
2020-03-09 14:54:56,634 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_spt of shape (32,)
2020-03-09 14:54:56,635 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.bias of shape (51,)
2020-03-09 14:54:56,635 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.weight of shape (51, 4096)
2020-03-09 14:54:56,635 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                       loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2020-03-09 14:54:56,635 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                     loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2020-03-09 14:54:56,635 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                       loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2020-03-09 14:54:56,635 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                     loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2020-03-09 14:54:56,635 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)
2020-03-09 14:54:56,635 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)
2020-03-09 14:54:56,635 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)
2020-03-09 14:54:56,635 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)
2020-03-09 14:54:56,635 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)
2020-03-09 14:54:56,635 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()
2020-03-09 14:54:56,636 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)
2020-03-09 14:54:56,636 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)
2020-03-09 14:54:56,636 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)
2020-03-09 14:54:56,636 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)
2020-03-09 14:54:56,636 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)
2020-03-09 14:54:56,636 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)
2020-03-09 14:54:56,636 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()
2020-03-09 14:54:56,636 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)
2020-03-09 14:54:56,636 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)
2020-03-09 14:54:56,636 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)
2020-03-09 14:54:56,890 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-03-09 14:54:56,901 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-03-09 14:54:58,986 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into /home/kaihua/checkpoints/upload_causal_motif_predcls/labels.json
2020-03-09 14:54:59,808 maskrcnn_benchmark INFO: #################### end dataloader ####################
2020-03-09 14:54:59,808 maskrcnn_benchmark INFO: Validate before training
2020-03-09 14:54:59,816 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 15:00:48,733 maskrcnn_benchmark INFO: Total run time: 0:05:48.916711 (0.13956668453216553 s / img per device, on 2 devices)
2020-03-09 15:00:48,733 maskrcnn_benchmark INFO: Model inference time: 0:05:26.868845 (0.13074753799438477 s / img per device, on 2 devices)
2020-03-09 15:02:15,002 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.5004;   R @ 50: 0.5960;   R @ 100: 0.6379;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.5439; ngR @ 50: 0.6948; ngR @ 100: 0.7874;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0000;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0902;  mR @ 50: 0.1284;  mR @ 100: 0.1520;  for mode=predcls, type=Mean Recall.
(above:0.0358) (across:0.0556) (against:0.0000) (along:0.0000) (and:0.0323) (at:0.1187) (attached to:0.0000) (behind:0.3743) (belonging to:0.0000) (between:0.0000) (carrying:0.0965) (covered in:0.1786) (covering:0.0000) (eating:0.5952) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0221) (has:0.7317) (holding:0.5578) (in:0.3280) (in front of:0.1474) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3458) (of:0.4486) (on:0.8689) (on back of:0.0455) (over:0.0610) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.7098) (says:0.0000) (sitting on:0.2185) (standing on:0.0217) (to:0.0000) (under:0.1276) (using:0.3077) (walking in:0.0000) (walking on:0.0011) (watching:0.0588) (wearing:0.9760) (wears:0.0000) (with:0.0561) 
SGG eval:   A @ 20: 0.6836;   A @ 50: 0.6884;   A @ 100: 0.6884;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 15:02:15,580 maskrcnn_benchmark INFO: Start training
2020-03-09 15:02:17,593 maskrcnn_benchmark INFO: ---Total norm inf clip coef 0.00000-----------------
2020-03-09 15:02:17,602 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: inf, (torch.Size([51]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: inf, (torch.Size([51, 4096]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: inf, (torch.Size([51]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 22.77997, (torch.Size([4096, 4096]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 21.74368, (torch.Size([4096, 12544]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 4.70171, (torch.Size([256, 1024, 3, 3]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 1.89084, (torch.Size([256, 128, 3, 3]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.94588, (torch.Size([51, 4096]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.88495, (torch.Size([4096, 512]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.66347, (torch.Size([512, 1024]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.63546, (torch.Size([4096, 4096]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.61943, (torch.Size([4096, 1024]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.54833, (torch.Size([128, 2, 7, 7]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.40680, (torch.Size([4096, 12544]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.34538, (torch.Size([2048, 4808]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.34011, (torch.Size([2048, 4808]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.27015, (torch.Size([4096]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.26799, (torch.Size([512, 32]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.24992, (torch.Size([4096]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.23963, (torch.Size([512]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.15834, (torch.Size([256]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.10775, (torch.Size([4096]))
2020-03-09 15:02:17,603 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.08822, (torch.Size([128]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.08523, (torch.Size([256]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.08117, (torch.Size([512]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.07386, (torch.Size([512, 1024]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.05332, (torch.Size([2048, 512]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.05203, (torch.Size([2048, 512]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.03937, (torch.Size([2048, 4424]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.03720, (torch.Size([4096]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.03718, (torch.Size([2048, 4424]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.03433, (torch.Size([256]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.03289, (torch.Size([22801, 51]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.03252, (torch.Size([256]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.03129, (torch.Size([2048]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.03129, (torch.Size([2048]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.03086, (torch.Size([2048]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.03086, (torch.Size([2048]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.02910, (torch.Size([128]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02865, (torch.Size([1024, 512]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.02794, (torch.Size([128]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.02560, (torch.Size([512]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.02432, (torch.Size([1024]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.01456, (torch.Size([4096]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00599, (torch.Size([2048, 512]))
2020-03-09 15:02:17,604 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00580, (torch.Size([2048, 512]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00393, (torch.Size([151, 200]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00377, (torch.Size([4096]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00342, (torch.Size([2048]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00342, (torch.Size([2048]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00324, (torch.Size([2048]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00324, (torch.Size([2048]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00179, (torch.Size([128, 32]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00101, (torch.Size([32, 9]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00078, (torch.Size([128]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00055, (torch.Size([32]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00044, (torch.Size([151, 200]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00020, (torch.Size([32]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00000, (torch.Size([152, 200]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.00000, (torch.Size([3072, 5136]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.00000, (torch.Size([3072]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.00000, (torch.Size([2560, 512]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.00000, (torch.Size([2560]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.00000, (torch.Size([151, 512]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.00000, (torch.Size([151]))
2020-03-09 15:02:17,605 maskrcnn_benchmark INFO: -------------------------------
2020-03-09 15:05:32,328 maskrcnn_benchmark INFO: eta: 13:36:28  iter: 200  loss: 0.8227 (1.4058)  auxiliary_ctx: 0.1784 (0.4803)  auxiliary_frq: 0.1948 (0.2115)  auxiliary_vis: 0.1856 (0.3280)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2861 (0.3860)  time: 0.9775 (0.9837)  data: 0.0107 (0.0159)  lr: 0.054984  max mem: 6134
2020-03-09 15:08:50,071 maskrcnn_benchmark INFO: eta: 13:35:16  iter: 400  loss: 0.9032 (1.1648)  auxiliary_ctx: 0.1894 (0.3357)  auxiliary_frq: 0.2073 (0.2107)  auxiliary_vis: 0.2119 (0.2688)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.3009 (0.3497)  time: 0.9804 (0.9862)  data: 0.0110 (0.0135)  lr: 0.098184  max mem: 6134
2020-03-09 15:12:07,795 maskrcnn_benchmark INFO: eta: 13:32:39  iter: 600  loss: 0.8597 (1.0895)  auxiliary_ctx: 0.1819 (0.2874)  auxiliary_frq: 0.2058 (0.2114)  auxiliary_vis: 0.2067 (0.2512)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2742 (0.3395)  time: 0.9826 (0.9870)  data: 0.0097 (0.0125)  lr: 0.120000  max mem: 6134
2020-03-09 15:15:25,161 maskrcnn_benchmark INFO: eta: 13:29:19  iter: 800  loss: 0.8110 (1.0435)  auxiliary_ctx: 0.1658 (0.2613)  auxiliary_frq: 0.2061 (0.2117)  auxiliary_vis: 0.1962 (0.2400)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2583 (0.3304)  time: 0.9887 (0.9870)  data: 0.0099 (0.0119)  lr: 0.120000  max mem: 6134
2020-03-09 15:18:43,003 maskrcnn_benchmark INFO: eta: 13:26:23  iter: 1000  loss: 0.8764 (1.0087)  auxiliary_ctx: 0.1693 (0.2436)  auxiliary_frq: 0.2114 (0.2112)  auxiliary_vis: 0.1881 (0.2312)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.3005 (0.3226)  time: 0.9896 (0.9874)  data: 0.0111 (0.0118)  lr: 0.120000  max mem: 6134
2020-03-09 15:22:00,003 maskrcnn_benchmark INFO: eta: 13:22:46  iter: 1200  loss: 0.8043 (0.9841)  auxiliary_ctx: 0.1574 (0.2318)  auxiliary_frq: 0.2086 (0.2111)  auxiliary_vis: 0.1923 (0.2249)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2710 (0.3163)  time: 0.9794 (0.9870)  data: 0.0114 (0.0118)  lr: 0.120000  max mem: 6134
2020-03-09 15:25:17,465 maskrcnn_benchmark INFO: eta: 13:19:31  iter: 1400  loss: 0.7538 (0.9647)  auxiliary_ctx: 0.1511 (0.2228)  auxiliary_frq: 0.2003 (0.2109)  auxiliary_vis: 0.1695 (0.2199)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2360 (0.3112)  time: 0.9764 (0.9871)  data: 0.0116 (0.0117)  lr: 0.120000  max mem: 6134
2020-03-09 15:28:35,238 maskrcnn_benchmark INFO: eta: 13:16:24  iter: 1600  loss: 0.7738 (0.9515)  auxiliary_ctx: 0.1613 (0.2163)  auxiliary_frq: 0.2007 (0.2109)  auxiliary_vis: 0.1817 (0.2165)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2515 (0.3078)  time: 0.9912 (0.9873)  data: 0.0106 (0.0116)  lr: 0.120000  max mem: 6134
2020-03-09 15:31:52,941 maskrcnn_benchmark INFO: eta: 13:13:13  iter: 1800  loss: 0.7378 (0.9395)  auxiliary_ctx: 0.1485 (0.2108)  auxiliary_frq: 0.1943 (0.2106)  auxiliary_vis: 0.1561 (0.2133)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2406 (0.3047)  time: 0.9866 (0.9874)  data: 0.0110 (0.0116)  lr: 0.120000  max mem: 6134
2020-03-09 15:35:10,188 maskrcnn_benchmark INFO: eta: 13:09:50  iter: 2000  loss: 0.7790 (0.9304)  auxiliary_ctx: 0.1576 (0.2065)  auxiliary_frq: 0.1977 (0.2106)  auxiliary_vis: 0.1741 (0.2111)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2468 (0.3022)  time: 0.9755 (0.9873)  data: 0.0115 (0.0115)  lr: 0.120000  max mem: 6158
2020-03-09 15:35:10,190 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_predcls/model_0002000.pth
2020-03-09 15:35:11,886 maskrcnn_benchmark INFO: Start validating
2020-03-09 15:35:11,903 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 15:41:05,285 maskrcnn_benchmark INFO: Total run time: 0:05:53.382198 (0.14135287914276123 s / img per device, on 2 devices)
2020-03-09 15:41:05,285 maskrcnn_benchmark INFO: Model inference time: 0:05:30.003385 (0.13200135402679444 s / img per device, on 2 devices)
2020-03-09 15:42:34,497 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.5936;   R @ 50: 0.6472;   R @ 100: 0.6632;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6717; ngR @ 50: 0.7974; ngR @ 100: 0.8674;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0585;  zR @ 50: 0.1185;  zR @ 100: 0.1319;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0939;  mR @ 50: 0.1098;  mR @ 100: 0.1160;  for mode=predcls, type=Mean Recall.
(above:0.0244) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0934) (attached to:0.0000) (behind:0.5299) (belonging to:0.0000) (between:0.0000) (carrying:0.0175) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8246) (holding:0.5587) (in:0.3044) (in front of:0.0000) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4298) (of:0.3643) (on:0.9320) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.4062) (says:0.0000) (sitting on:0.2203) (standing on:0.0000) (to:0.0000) (under:0.0893) (using:0.0000) (walking in:0.0000) (walking on:0.0013) (watching:0.0000) (wearing:0.9694) (wears:0.0000) (with:0.0346) 
SGG eval:   A @ 20: 0.6891;   A @ 50: 0.6943;   A @ 100: 0.6943;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 15:42:35,055 maskrcnn_benchmark INFO: Validation Result: 0.6632
2020-03-09 15:45:51,223 maskrcnn_benchmark INFO: eta: 15:47:10  iter: 2200  loss: 0.7965 (0.9223)  auxiliary_ctx: 0.1680 (0.2029)  auxiliary_frq: 0.2082 (0.2105)  auxiliary_vis: 0.1858 (0.2090)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2612 (0.2999)  time: 0.9710 (1.1889)  data: 0.0110 (0.2137)  lr: 0.120000  max mem: 6158
2020-03-09 15:49:07,247 maskrcnn_benchmark INFO: eta: 15:29:24  iter: 2400  loss: 0.8534 (0.9142)  auxiliary_ctx: 0.1529 (0.1995)  auxiliary_frq: 0.2060 (0.2103)  auxiliary_vis: 0.1884 (0.2070)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2710 (0.2974)  time: 0.9774 (1.1715)  data: 0.0111 (0.1968)  lr: 0.120000  max mem: 6158
2020-03-09 15:52:24,754 maskrcnn_benchmark INFO: eta: 15:14:19  iter: 2600  loss: 0.8518 (0.9080)  auxiliary_ctx: 0.1721 (0.1968)  auxiliary_frq: 0.2127 (0.2103)  auxiliary_vis: 0.1988 (0.2054)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2761 (0.2956)  time: 0.9796 (1.1574)  data: 0.0110 (0.1825)  lr: 0.120000  max mem: 6158
2020-03-09 15:55:42,201 maskrcnn_benchmark INFO: eta: 15:00:54  iter: 2800  loss: 0.7436 (0.9029)  auxiliary_ctx: 0.1466 (0.1945)  auxiliary_frq: 0.2000 (0.2102)  auxiliary_vis: 0.1603 (0.2041)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2412 (0.2941)  time: 0.9895 (1.1452)  data: 0.0095 (0.1702)  lr: 0.120000  max mem: 6290
2020-03-09 15:58:58,570 maskrcnn_benchmark INFO: eta: 14:48:33  iter: 3000  loss: 0.7884 (0.8984)  auxiliary_ctx: 0.1573 (0.1925)  auxiliary_frq: 0.2057 (0.2102)  auxiliary_vis: 0.1796 (0.2029)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2482 (0.2928)  time: 0.9839 (1.1343)  data: 0.0107 (0.1595)  lr: 0.120000  max mem: 6290
2020-03-09 16:02:15,920 maskrcnn_benchmark INFO: eta: 14:37:34  iter: 3200  loss: 0.7771 (0.8939)  auxiliary_ctx: 0.1560 (0.1906)  auxiliary_frq: 0.2078 (0.2101)  auxiliary_vis: 0.1723 (0.2018)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2541 (0.2914)  time: 0.9882 (1.1251)  data: 0.0111 (0.1502)  lr: 0.120000  max mem: 6290
2020-03-09 16:05:32,867 maskrcnn_benchmark INFO: eta: 14:27:25  iter: 3400  loss: 0.8700 (0.8900)  auxiliary_ctx: 0.1738 (0.1890)  auxiliary_frq: 0.2102 (0.2102)  auxiliary_vis: 0.1926 (0.2008)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2669 (0.2901)  time: 0.9836 (1.1168)  data: 0.0109 (0.1420)  lr: 0.120000  max mem: 6290
2020-03-09 16:08:50,248 maskrcnn_benchmark INFO: eta: 14:18:06  iter: 3600  loss: 0.8757 (0.8865)  auxiliary_ctx: 0.1641 (0.1875)  auxiliary_frq: 0.2152 (0.2101)  auxiliary_vis: 0.1866 (0.1999)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2864 (0.2890)  time: 0.9759 (1.1096)  data: 0.0096 (0.1347)  lr: 0.120000  max mem: 6290
2020-03-09 16:12:07,958 maskrcnn_benchmark INFO: eta: 14:09:30  iter: 3800  loss: 0.7543 (0.8821)  auxiliary_ctx: 0.1499 (0.1860)  auxiliary_frq: 0.1987 (0.2099)  auxiliary_vis: 0.1620 (0.1988)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2381 (0.2875)  time: 0.9687 (1.1033)  data: 0.0100 (0.1282)  lr: 0.120000  max mem: 6290
2020-03-09 16:15:25,139 maskrcnn_benchmark INFO: ---Total norm 0.59360 clip coef 8.42316-----------------
2020-03-09 16:15:25,150 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.30731, (torch.Size([4096, 12544]))
2020-03-09 16:15:25,150 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.19580, (torch.Size([4096, 12544]))
2020-03-09 16:15:25,150 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.19079, (torch.Size([4096, 4096]))
2020-03-09 16:15:25,150 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.18464, (torch.Size([256, 1024, 3, 3]))
2020-03-09 16:15:25,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.17433, (torch.Size([51, 4096]))
2020-03-09 16:15:25,150 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.17095, (torch.Size([4096, 4096]))
2020-03-09 16:15:25,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.15131, (torch.Size([51, 4096]))
2020-03-09 16:15:25,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.12246, (torch.Size([4096, 1024]))
2020-03-09 16:15:25,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.10937, (torch.Size([2048, 4808]))
2020-03-09 16:15:25,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.09831, (torch.Size([2048, 4808]))
2020-03-09 16:15:25,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.09484, (torch.Size([512, 1024]))
2020-03-09 16:15:25,150 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.07106, (torch.Size([256, 128, 3, 3]))
2020-03-09 16:15:25,150 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.06984, (torch.Size([128, 2, 7, 7]))
2020-03-09 16:15:25,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.05516, (torch.Size([4096, 512]))
2020-03-09 16:15:25,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.04549, (torch.Size([512, 32]))
2020-03-09 16:15:25,150 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.03885, (torch.Size([4096]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.03482, (torch.Size([51]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.02606, (torch.Size([512]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.02290, (torch.Size([51]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01770, (torch.Size([22801, 51]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01384, (torch.Size([2048, 512]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01332, (torch.Size([2048, 512]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01316, (torch.Size([151, 200]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01315, (torch.Size([1024, 512]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.01275, (torch.Size([512]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01155, (torch.Size([256]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.01129, (torch.Size([128]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.01022, (torch.Size([4096]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.01013, (torch.Size([512, 1024]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00691, (torch.Size([256]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00570, (torch.Size([128]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00566, (torch.Size([2048]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00566, (torch.Size([2048]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00551, (torch.Size([2048]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00551, (torch.Size([2048]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00547, (torch.Size([2048, 4424]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00547, (torch.Size([2048, 4424]))
2020-03-09 16:15:25,151 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00382, (torch.Size([1024]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00347, (torch.Size([4096]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00324, (torch.Size([4096]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00323, (torch.Size([128]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00305, (torch.Size([4096]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00301, (torch.Size([512]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00252, (torch.Size([256]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00184, (torch.Size([256]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00111, (torch.Size([4096]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00080, (torch.Size([2048, 512]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00072, (torch.Size([2048, 512]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00037, (torch.Size([2048]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00037, (torch.Size([2048]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00035, (torch.Size([2048]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00035, (torch.Size([2048]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00017, (torch.Size([128, 32]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00011, (torch.Size([32, 9]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00010, (torch.Size([151, 200]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00007, (torch.Size([128]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00003, (torch.Size([32]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00002, (torch.Size([32]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00000, (torch.Size([152, 200]))
2020-03-09 16:15:25,152 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.00000, (torch.Size([3072, 5136]))
2020-03-09 16:15:25,153 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.00000, (torch.Size([3072]))
2020-03-09 16:15:25,153 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.00000, (torch.Size([2560, 512]))
2020-03-09 16:15:25,153 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.00000, (torch.Size([2560]))
2020-03-09 16:15:25,153 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.00000, (torch.Size([151, 512]))
2020-03-09 16:15:25,153 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.00000, (torch.Size([151]))
2020-03-09 16:15:25,153 maskrcnn_benchmark INFO: -------------------------------
2020-03-09 16:15:25,155 maskrcnn_benchmark INFO: eta: 14:01:20  iter: 4000  loss: 0.7340 (0.8779)  auxiliary_ctx: 0.1492 (0.1845)  auxiliary_frq: 0.1967 (0.2095)  auxiliary_vis: 0.1652 (0.1977)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2398 (0.2862)  time: 0.9851 (1.0974)  data: 0.0102 (0.1223)  lr: 0.120000  max mem: 6290
2020-03-09 16:15:25,158 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_predcls/model_0004000.pth
2020-03-09 16:15:26,698 maskrcnn_benchmark INFO: Start validating
2020-03-09 16:15:26,717 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 16:21:20,603 maskrcnn_benchmark INFO: Total run time: 0:05:53.885511 (0.14155420455932619 s / img per device, on 2 devices)
2020-03-09 16:21:20,604 maskrcnn_benchmark INFO: Model inference time: 0:05:29.974645 (0.13198985815048217 s / img per device, on 2 devices)
2020-03-09 16:22:49,612 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.5926;   R @ 50: 0.6519;   R @ 100: 0.6692;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6807; ngR @ 50: 0.8122; ngR @ 100: 0.8825;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0511;  zR @ 50: 0.1030;  zR @ 100: 0.1311;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1004;  mR @ 50: 0.1216;  mR @ 100: 0.1300;  for mode=predcls, type=Mean Recall.
(above:0.0809) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.3387) (attached to:0.0000) (behind:0.5482) (belonging to:0.0000) (between:0.0000) (carrying:0.2697) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8373) (holding:0.5410) (in:0.3107) (in front of:0.0369) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.3960) (of:0.3492) (on:0.9357) (on back of:0.0000) (over:0.0122) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.3839) (says:0.0000) (sitting on:0.2429) (standing on:0.0000) (to:0.0000) (under:0.1743) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.9782) (wears:0.0000) (with:0.0663) 
SGG eval:   A @ 20: 0.6937;   A @ 50: 0.6989;   A @ 100: 0.6989;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 16:22:50,173 maskrcnn_benchmark INFO: Validation Result: 0.6692
2020-03-09 16:26:06,008 maskrcnn_benchmark INFO: eta: 15:14:15  iter: 4200  loss: 0.8693 (0.8746)  auxiliary_ctx: 0.1715 (0.1832)  auxiliary_frq: 0.2111 (0.2094)  auxiliary_vis: 0.1953 (0.1969)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2934 (0.2851)  time: 0.9751 (1.1977)  data: 0.0110 (0.2229)  lr: 0.120000  max mem: 6290
2020-03-09 16:29:22,827 maskrcnn_benchmark INFO: eta: 15:02:53  iter: 4400  loss: 0.7386 (0.8714)  auxiliary_ctx: 0.1446 (0.1821)  auxiliary_frq: 0.1984 (0.2093)  auxiliary_vis: 0.1715 (0.1960)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2347 (0.2840)  time: 0.9667 (1.1880)  data: 0.0110 (0.2133)  lr: 0.120000  max mem: 6290
2020-03-09 16:32:39,516 maskrcnn_benchmark INFO: eta: 14:52:11  iter: 4600  loss: 0.7923 (0.8689)  auxiliary_ctx: 0.1580 (0.1811)  auxiliary_frq: 0.2095 (0.2092)  auxiliary_vis: 0.1791 (0.1953)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2521 (0.2833)  time: 0.9691 (1.1791)  data: 0.0115 (0.2045)  lr: 0.120000  max mem: 6290
2020-03-09 16:35:57,319 maskrcnn_benchmark INFO: eta: 14:42:18  iter: 4800  loss: 0.7433 (0.8675)  auxiliary_ctx: 0.1508 (0.1804)  auxiliary_frq: 0.2029 (0.2093)  auxiliary_vis: 0.1683 (0.1949)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2435 (0.2829)  time: 0.9912 (1.1712)  data: 0.0111 (0.1965)  lr: 0.120000  max mem: 6290
2020-03-09 16:39:12,927 maskrcnn_benchmark INFO: eta: 14:32:36  iter: 5000  loss: 0.7541 (0.8653)  auxiliary_ctx: 0.1475 (0.1796)  auxiliary_frq: 0.2002 (0.2092)  auxiliary_vis: 0.1639 (0.1944)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2376 (0.2821)  time: 0.9889 (1.1635)  data: 0.0118 (0.1891)  lr: 0.120000  max mem: 6290
2020-03-09 16:42:29,657 maskrcnn_benchmark INFO: eta: 14:23:33  iter: 5200  loss: 0.8080 (0.8622)  auxiliary_ctx: 0.1557 (0.1786)  auxiliary_frq: 0.2101 (0.2090)  auxiliary_vis: 0.1870 (0.1936)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2596 (0.2810)  time: 0.9737 (1.1566)  data: 0.0114 (0.1822)  lr: 0.120000  max mem: 6290
2020-03-09 16:45:46,881 maskrcnn_benchmark INFO: eta: 14:15:00  iter: 5400  loss: 0.8239 (0.8601)  auxiliary_ctx: 0.1595 (0.1778)  auxiliary_frq: 0.2122 (0.2090)  auxiliary_vis: 0.1827 (0.1930)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2726 (0.2803)  time: 0.9881 (1.1502)  data: 0.0116 (0.1759)  lr: 0.120000  max mem: 6290
2020-03-09 16:49:04,285 maskrcnn_benchmark INFO: eta: 14:06:51  iter: 5600  loss: 0.7718 (0.8578)  auxiliary_ctx: 0.1558 (0.1770)  auxiliary_frq: 0.2046 (0.2089)  auxiliary_vis: 0.1730 (0.1924)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2485 (0.2795)  time: 0.9846 (1.1444)  data: 0.0116 (0.1700)  lr: 0.120000  max mem: 6290
2020-03-09 16:52:21,643 maskrcnn_benchmark INFO: eta: 13:59:02  iter: 5800  loss: 0.8142 (0.8558)  auxiliary_ctx: 0.1662 (0.1763)  auxiliary_frq: 0.2064 (0.2088)  auxiliary_vis: 0.1845 (0.1919)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2737 (0.2788)  time: 0.9868 (1.1390)  data: 0.0114 (0.1646)  lr: 0.120000  max mem: 6290
2020-03-09 16:55:39,171 maskrcnn_benchmark INFO: eta: 13:51:32  iter: 6000  loss: 0.8118 (0.8544)  auxiliary_ctx: 0.1474 (0.1758)  auxiliary_frq: 0.2037 (0.2088)  auxiliary_vis: 0.1744 (0.1915)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2624 (0.2784)  time: 0.9844 (1.1339)  data: 0.0116 (0.1595)  lr: 0.120000  max mem: 6290
2020-03-09 16:55:39,173 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_predcls/model_0006000.pth
2020-03-09 16:55:40,711 maskrcnn_benchmark INFO: Start validating
2020-03-09 16:55:40,733 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 17:01:34,172 maskrcnn_benchmark INFO: Total run time: 0:05:53.438950 (0.14137558012008666 s / img per device, on 2 devices)
2020-03-09 17:01:34,173 maskrcnn_benchmark INFO: Model inference time: 0:05:29.460508 (0.1317842031478882 s / img per device, on 2 devices)
2020-03-09 17:03:03,955 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6032;   R @ 50: 0.6568;   R @ 100: 0.6729;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6905; ngR @ 50: 0.8176; ngR @ 100: 0.8856;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0548;  zR @ 50: 0.1185;  zR @ 100: 0.1363;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0932;  mR @ 50: 0.1124;  mR @ 100: 0.1231;  for mode=predcls, type=Mean Recall.
(above:0.1103) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0975) (attached to:0.0000) (behind:0.5076) (belonging to:0.0000) (between:0.0000) (carrying:0.0658) (covered in:0.0000) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8344) (holding:0.6050) (in:0.3469) (in front of:0.0103) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5044) (of:0.3465) (on:0.9301) (on back of:0.0000) (over:0.0610) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2009) (says:0.0000) (sitting on:0.1587) (standing on:0.0109) (to:0.0000) (under:0.1097) (using:0.0000) (walking in:0.0000) (walking on:0.0106) (watching:0.0000) (wearing:0.9765) (wears:0.0000) (with:0.0798) 
SGG eval:   A @ 20: 0.6954;   A @ 50: 0.7004;   A @ 100: 0.7004;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 17:03:04,544 maskrcnn_benchmark INFO: Validation Result: 0.6729
2020-03-09 17:06:20,829 maskrcnn_benchmark INFO: eta: 14:36:37  iter: 6200  loss: 0.6985 (0.8524)  auxiliary_ctx: 0.1472 (0.1751)  auxiliary_frq: 0.1988 (0.2086)  auxiliary_vis: 0.1601 (0.1910)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2086 (0.2777)  time: 0.9800 (1.2008)  data: 0.0118 (0.2265)  lr: 0.120000  max mem: 6327
2020-03-09 17:09:37,060 maskrcnn_benchmark INFO: eta: 14:27:37  iter: 6400  loss: 0.7625 (0.8510)  auxiliary_ctx: 0.1447 (0.1746)  auxiliary_frq: 0.1982 (0.2086)  auxiliary_vis: 0.1604 (0.1906)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2536 (0.2772)  time: 0.9914 (1.1940)  data: 0.0106 (0.2198)  lr: 0.120000  max mem: 6327
2020-03-09 17:12:54,012 maskrcnn_benchmark INFO: eta: 14:19:03  iter: 6600  loss: 0.7131 (0.8491)  auxiliary_ctx: 0.1415 (0.1740)  auxiliary_frq: 0.1950 (0.2085)  auxiliary_vis: 0.1521 (0.1901)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2290 (0.2765)  time: 0.9808 (1.1876)  data: 0.0108 (0.2135)  lr: 0.120000  max mem: 6327
2020-03-09 17:16:11,507 maskrcnn_benchmark INFO: eta: 14:10:51  iter: 6800  loss: 0.6880 (0.8469)  auxiliary_ctx: 0.1413 (0.1733)  auxiliary_frq: 0.1887 (0.2083)  auxiliary_vis: 0.1556 (0.1896)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2065 (0.2757)  time: 0.9973 (1.1818)  data: 0.0115 (0.2075)  lr: 0.120000  max mem: 6327
2020-03-09 17:19:28,876 maskrcnn_benchmark INFO: eta: 14:02:55  iter: 7000  loss: 0.7171 (0.8448)  auxiliary_ctx: 0.1415 (0.1726)  auxiliary_frq: 0.1905 (0.2082)  auxiliary_vis: 0.1683 (0.1891)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2188 (0.2750)  time: 0.9856 (1.1762)  data: 0.0116 (0.2019)  lr: 0.120000  max mem: 6327
2020-03-09 17:22:46,217 maskrcnn_benchmark INFO: eta: 13:55:15  iter: 7200  loss: 0.7902 (0.8439)  auxiliary_ctx: 0.1676 (0.1723)  auxiliary_frq: 0.2058 (0.2082)  auxiliary_vis: 0.1865 (0.1888)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2500 (0.2747)  time: 0.9783 (1.1709)  data: 0.0112 (0.1966)  lr: 0.120000  max mem: 6327
2020-03-09 17:26:04,012 maskrcnn_benchmark INFO: eta: 13:47:51  iter: 7400  loss: 0.7835 (0.8424)  auxiliary_ctx: 0.1570 (0.1718)  auxiliary_frq: 0.2107 (0.2081)  auxiliary_vis: 0.1822 (0.1884)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2402 (0.2741)  time: 0.9689 (1.1660)  data: 0.0114 (0.1916)  lr: 0.120000  max mem: 6327
2020-03-09 17:29:21,847 maskrcnn_benchmark INFO: eta: 13:40:41  iter: 7600  loss: 0.7853 (0.8407)  auxiliary_ctx: 0.1516 (0.1713)  auxiliary_frq: 0.1955 (0.2079)  auxiliary_vis: 0.1745 (0.1880)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2378 (0.2735)  time: 0.9827 (1.1614)  data: 0.0113 (0.1869)  lr: 0.120000  max mem: 6327
2020-03-09 17:32:39,875 maskrcnn_benchmark INFO: eta: 13:33:43  iter: 7800  loss: 0.7135 (0.8394)  auxiliary_ctx: 0.1342 (0.1708)  auxiliary_frq: 0.1944 (0.2078)  auxiliary_vis: 0.1583 (0.1877)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2444 (0.2731)  time: 0.9949 (1.1570)  data: 0.0110 (0.1824)  lr: 0.120000  max mem: 6327
2020-03-09 17:35:57,769 maskrcnn_benchmark INFO: ---Total norm 0.33233 clip coef 15.04539-----------------
2020-03-09 17:35:57,779 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.15783, (torch.Size([4096, 12544]))
2020-03-09 17:35:57,779 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.13422, (torch.Size([51, 4096]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.10588, (torch.Size([4096, 12544]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.09624, (torch.Size([256, 1024, 3, 3]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.08375, (torch.Size([4096, 4096]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.08348, (torch.Size([4096, 4096]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.08109, (torch.Size([512, 32]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.07107, (torch.Size([4096, 1024]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.06981, (torch.Size([51, 4096]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.06175, (torch.Size([2048, 4808]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.05249, (torch.Size([2048, 4808]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.05180, (torch.Size([512, 1024]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.03658, (torch.Size([51]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.03613, (torch.Size([4096, 512]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.03465, (torch.Size([256, 128, 3, 3]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.03108, (torch.Size([128, 2, 7, 7]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.02628, (torch.Size([4096]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.02264, (torch.Size([512]))
2020-03-09 17:35:57,780 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01854, (torch.Size([512]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01238, (torch.Size([1024, 512]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.01067, (torch.Size([51]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00988, (torch.Size([151, 200]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00960, (torch.Size([2048, 512]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.00947, (torch.Size([22801, 51]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00745, (torch.Size([256]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00725, (torch.Size([2048, 512]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00617, (torch.Size([256]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00559, (torch.Size([4096]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00547, (torch.Size([2048]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00547, (torch.Size([2048]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00517, (torch.Size([128]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00502, (torch.Size([2048]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00502, (torch.Size([2048]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00494, (torch.Size([128]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00390, (torch.Size([1024]))
2020-03-09 17:35:57,781 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00382, (torch.Size([4096]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00319, (torch.Size([512, 1024]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00232, (torch.Size([4096]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00192, (torch.Size([512]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00187, (torch.Size([2048, 4424]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00184, (torch.Size([2048, 4424]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00179, (torch.Size([4096]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00173, (torch.Size([128]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00160, (torch.Size([256]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00093, (torch.Size([256]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00075, (torch.Size([4096]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00023, (torch.Size([2048, 512]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00022, (torch.Size([2048, 512]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00020, (torch.Size([2048]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00020, (torch.Size([2048]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00020, (torch.Size([2048]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00020, (torch.Size([2048]))
2020-03-09 17:35:57,782 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00003, (torch.Size([128, 32]))
2020-03-09 17:35:57,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00003, (torch.Size([151, 200]))
2020-03-09 17:35:57,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00003, (torch.Size([128]))
2020-03-09 17:35:57,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00002, (torch.Size([32, 9]))
2020-03-09 17:35:57,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00001, (torch.Size([32]))
2020-03-09 17:35:57,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-03-09 17:35:57,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-09 17:35:57,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00000, (torch.Size([152, 200]))
2020-03-09 17:35:57,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.00000, (torch.Size([3072, 5136]))
2020-03-09 17:35:57,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.00000, (torch.Size([3072]))
2020-03-09 17:35:57,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.00000, (torch.Size([2560, 512]))
2020-03-09 17:35:57,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.00000, (torch.Size([2560]))
2020-03-09 17:35:57,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.00000, (torch.Size([151, 512]))
2020-03-09 17:35:57,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.00000, (torch.Size([151]))
2020-03-09 17:35:57,783 maskrcnn_benchmark INFO: -------------------------------
2020-03-09 17:35:57,786 maskrcnn_benchmark INFO: eta: 13:26:56  iter: 8000  loss: 0.7995 (0.8380)  auxiliary_ctx: 0.1549 (0.1704)  auxiliary_frq: 0.1940 (0.2077)  auxiliary_vis: 0.1728 (0.1873)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2576 (0.2726)  time: 0.9800 (1.1528)  data: 0.0106 (0.1781)  lr: 0.120000  max mem: 6327
2020-03-09 17:35:57,788 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_predcls/model_0008000.pth
2020-03-09 17:35:59,408 maskrcnn_benchmark INFO: Start validating
2020-03-09 17:35:59,433 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 17:41:54,109 maskrcnn_benchmark INFO: Total run time: 0:05:54.675613 (0.14187024517059327 s / img per device, on 2 devices)
2020-03-09 17:41:54,110 maskrcnn_benchmark INFO: Model inference time: 0:05:30.874494 (0.13234979772567748 s / img per device, on 2 devices)
2020-03-09 17:43:22,321 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6052;   R @ 50: 0.6574;   R @ 100: 0.6732;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6947; ngR @ 50: 0.8223; ngR @ 100: 0.8895;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0689;  zR @ 50: 0.1430;  zR @ 100: 0.1585;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0945;  mR @ 50: 0.1140;  mR @ 100: 0.1215;  for mode=predcls, type=Mean Recall.
(above:0.0783) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1993) (attached to:0.0000) (behind:0.4639) (belonging to:0.0000) (between:0.0000) (carrying:0.4211) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8310) (holding:0.5023) (in:0.3429) (in front of:0.0476) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4353) (of:0.3088) (on:0.9461) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.0759) (says:0.0000) (sitting on:0.1759) (standing on:0.0000) (to:0.0000) (under:0.1616) (using:0.0000) (walking in:0.0000) (walking on:0.0080) (watching:0.0000) (wearing:0.9675) (wears:0.0000) (with:0.0869) 
SGG eval:   A @ 20: 0.6972;   A @ 50: 0.7022;   A @ 100: 0.7022;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 17:43:22,903 maskrcnn_benchmark INFO: Validation Result: 0.6732
2020-03-09 17:46:39,747 maskrcnn_benchmark INFO: eta: 13:58:03  iter: 8200  loss: 0.8680 (0.8371)  auxiliary_ctx: 0.1659 (0.1701)  auxiliary_frq: 0.2100 (0.2076)  auxiliary_vis: 0.1962 (0.1871)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2853 (0.2723)  time: 0.9915 (1.2029)  data: 0.0117 (0.2283)  lr: 0.120000  max mem: 6327
2020-03-09 17:49:57,456 maskrcnn_benchmark INFO: eta: 13:50:30  iter: 8400  loss: 0.6988 (0.8355)  auxiliary_ctx: 0.1383 (0.1696)  auxiliary_frq: 0.1925 (0.2074)  auxiliary_vis: 0.1533 (0.1867)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2069 (0.2718)  time: 0.9838 (1.1978)  data: 0.0114 (0.2231)  lr: 0.120000  max mem: 6327
2020-03-09 17:53:15,358 maskrcnn_benchmark INFO: eta: 13:43:10  iter: 8600  loss: 0.8076 (0.8343)  auxiliary_ctx: 0.1560 (0.1692)  auxiliary_frq: 0.2092 (0.2073)  auxiliary_vis: 0.1747 (0.1864)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2584 (0.2714)  time: 0.9793 (1.1930)  data: 0.0108 (0.2182)  lr: 0.120000  max mem: 6327
2020-03-09 17:56:32,992 maskrcnn_benchmark INFO: eta: 13:35:59  iter: 8800  loss: 0.8244 (0.8332)  auxiliary_ctx: 0.1710 (0.1689)  auxiliary_frq: 0.2091 (0.2072)  auxiliary_vis: 0.1863 (0.1861)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2654 (0.2710)  time: 0.9950 (1.1883)  data: 0.0106 (0.2135)  lr: 0.120000  max mem: 6327
2020-03-09 17:59:50,972 maskrcnn_benchmark INFO: eta: 13:29:01  iter: 9000  loss: 0.7253 (0.8322)  auxiliary_ctx: 0.1357 (0.1685)  auxiliary_frq: 0.1945 (0.2071)  auxiliary_vis: 0.1642 (0.1858)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2320 (0.2707)  time: 0.9701 (1.1839)  data: 0.0097 (0.2090)  lr: 0.120000  max mem: 6327
2020-03-09 18:03:08,876 maskrcnn_benchmark INFO: eta: 13:22:11  iter: 9200  loss: 0.7434 (0.8309)  auxiliary_ctx: 0.1545 (0.1682)  auxiliary_frq: 0.1980 (0.2070)  auxiliary_vis: 0.1738 (0.1855)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2113 (0.2702)  time: 0.9917 (1.1797)  data: 0.0100 (0.2046)  lr: 0.120000  max mem: 6327
2020-03-09 18:06:26,454 maskrcnn_benchmark INFO: eta: 13:15:30  iter: 9400  loss: 0.8005 (0.8306)  auxiliary_ctx: 0.1535 (0.1680)  auxiliary_frq: 0.2070 (0.2070)  auxiliary_vis: 0.1715 (0.1854)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2466 (0.2702)  time: 0.9962 (1.1756)  data: 0.0112 (0.2005)  lr: 0.120000  max mem: 6327
2020-03-09 18:09:44,032 maskrcnn_benchmark INFO: eta: 13:08:57  iter: 9600  loss: 0.7791 (0.8303)  auxiliary_ctx: 0.1661 (0.1679)  auxiliary_frq: 0.2144 (0.2071)  auxiliary_vis: 0.1755 (0.1854)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2409 (0.2701)  time: 0.9846 (1.1717)  data: 0.0116 (0.1966)  lr: 0.120000  max mem: 6327
2020-03-09 18:13:00,641 maskrcnn_benchmark INFO: eta: 13:02:28  iter: 9800  loss: 0.7615 (0.8294)  auxiliary_ctx: 0.1529 (0.1676)  auxiliary_frq: 0.1997 (0.2070)  auxiliary_vis: 0.1730 (0.1851)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2541 (0.2697)  time: 0.9660 (1.1679)  data: 0.0113 (0.1928)  lr: 0.120000  max mem: 6327
2020-03-09 18:16:17,828 maskrcnn_benchmark INFO: eta: 12:56:08  iter: 10000  loss: 0.7215 (0.8285)  auxiliary_ctx: 0.1515 (0.1673)  auxiliary_frq: 0.1961 (0.2070)  auxiliary_vis: 0.1638 (0.1848)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2281 (0.2694)  time: 0.9856 (1.1642)  data: 0.0114 (0.1892)  lr: 0.120000  max mem: 6327
2020-03-09 18:16:17,830 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_predcls/model_0010000.pth
2020-03-09 18:16:19,396 maskrcnn_benchmark INFO: Start validating
2020-03-09 18:16:19,421 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 18:22:14,840 maskrcnn_benchmark INFO: Total run time: 0:05:55.418110 (0.14216724395751953 s / img per device, on 2 devices)
2020-03-09 18:22:14,840 maskrcnn_benchmark INFO: Model inference time: 0:05:31.735974 (0.13269438972473144 s / img per device, on 2 devices)
2020-03-09 18:23:43,199 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6092;   R @ 50: 0.6631;   R @ 100: 0.6796;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6978; ngR @ 50: 0.8254; ngR @ 100: 0.8910;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0733;  zR @ 50: 0.1370;  zR @ 100: 0.1548;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1058;  mR @ 50: 0.1275;  mR @ 100: 0.1361;  for mode=predcls, type=Mean Recall.
(above:0.1950) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0965) (attached to:0.0000) (behind:0.3719) (belonging to:0.0000) (between:0.0000) (carrying:0.0504) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8322) (holding:0.7002) (in:0.3610) (in front of:0.0412) (laying on:0.0000) (looking at:0.0435) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5826) (of:0.3573) (on:0.9192) (on back of:0.0000) (over:0.0488) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.3914) (says:0.0000) (sitting on:0.2408) (standing on:0.0109) (to:0.0000) (under:0.1403) (using:0.0000) (walking in:0.0000) (walking on:0.3445) (watching:0.0588) (wearing:0.9784) (wears:0.0000) (with:0.0382) 
SGG eval:   A @ 20: 0.7037;   A @ 50: 0.7088;   A @ 100: 0.7088;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 18:23:43,815 maskrcnn_benchmark INFO: Validation Result: 0.6796
2020-03-09 18:27:00,131 maskrcnn_benchmark INFO: eta: 13:18:53  iter: 10200  loss: 0.7707 (0.8275)  auxiliary_ctx: 0.1564 (0.1670)  auxiliary_frq: 0.1928 (0.2069)  auxiliary_vis: 0.1707 (0.1846)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2437 (0.2690)  time: 0.9868 (1.2044)  data: 0.0113 (0.2294)  lr: 0.120000  max mem: 6327
2020-03-09 18:30:17,245 maskrcnn_benchmark INFO: eta: 13:12:06  iter: 10400  loss: 0.7839 (0.8266)  auxiliary_ctx: 0.1548 (0.1667)  auxiliary_frq: 0.2018 (0.2068)  auxiliary_vis: 0.1731 (0.1843)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2239 (0.2687)  time: 0.9742 (1.2002)  data: 0.0097 (0.2252)  lr: 0.120000  max mem: 6327
2020-03-09 18:33:34,243 maskrcnn_benchmark INFO: eta: 13:05:26  iter: 10600  loss: 0.7582 (0.8260)  auxiliary_ctx: 0.1433 (0.1665)  auxiliary_frq: 0.1949 (0.2068)  auxiliary_vis: 0.1647 (0.1841)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2444 (0.2685)  time: 0.9873 (1.1961)  data: 0.0114 (0.2212)  lr: 0.120000  max mem: 6327
2020-03-09 18:36:52,339 maskrcnn_benchmark INFO: eta: 12:58:57  iter: 10800  loss: 0.7479 (0.8247)  auxiliary_ctx: 0.1484 (0.1662)  auxiliary_frq: 0.1994 (0.2066)  auxiliary_vis: 0.1631 (0.1838)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2396 (0.2681)  time: 0.9892 (1.1923)  data: 0.0111 (0.2173)  lr: 0.120000  max mem: 6440
2020-03-09 18:40:09,193 maskrcnn_benchmark INFO: eta: 12:52:31  iter: 11000  loss: 0.8013 (0.8242)  auxiliary_ctx: 0.1616 (0.1660)  auxiliary_frq: 0.2000 (0.2066)  auxiliary_vis: 0.1771 (0.1837)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2569 (0.2679)  time: 0.9714 (1.1885)  data: 0.0093 (0.2135)  lr: 0.120000  max mem: 6440
2020-03-09 18:43:26,229 maskrcnn_benchmark INFO: eta: 12:46:13  iter: 11200  loss: 0.7213 (0.8235)  auxiliary_ctx: 0.1423 (0.1658)  auxiliary_frq: 0.1968 (0.2065)  auxiliary_vis: 0.1597 (0.1835)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2351 (0.2677)  time: 0.9768 (1.1849)  data: 0.0095 (0.2099)  lr: 0.120000  max mem: 6440
2020-03-09 18:46:43,358 maskrcnn_benchmark INFO: eta: 12:40:01  iter: 11400  loss: 0.7622 (0.8225)  auxiliary_ctx: 0.1463 (0.1655)  auxiliary_frq: 0.2015 (0.2064)  auxiliary_vis: 0.1686 (0.1832)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2394 (0.2673)  time: 0.9869 (1.1814)  data: 0.0117 (0.2064)  lr: 0.120000  max mem: 6440
2020-03-09 18:50:00,685 maskrcnn_benchmark INFO: eta: 12:33:56  iter: 11600  loss: 0.8015 (0.8218)  auxiliary_ctx: 0.1581 (0.1653)  auxiliary_frq: 0.1976 (0.2063)  auxiliary_vis: 0.1647 (0.1830)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2586 (0.2671)  time: 0.9813 (1.1780)  data: 0.0115 (0.2030)  lr: 0.120000  max mem: 6440
2020-03-09 18:53:17,979 maskrcnn_benchmark INFO: eta: 12:27:56  iter: 11800  loss: 0.7961 (0.8209)  auxiliary_ctx: 0.1557 (0.1651)  auxiliary_frq: 0.2049 (0.2062)  auxiliary_vis: 0.1820 (0.1828)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2670 (0.2668)  time: 0.9851 (1.1748)  data: 0.0110 (0.1998)  lr: 0.120000  max mem: 6440
2020-03-09 18:56:36,078 maskrcnn_benchmark INFO: ---Total norm 0.35997 clip coef 13.89017-----------------
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.19406, (torch.Size([4096, 12544]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.14801, (torch.Size([4096, 12544]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.11554, (torch.Size([256, 1024, 3, 3]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.11522, (torch.Size([4096, 4096]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.08959, (torch.Size([4096, 4096]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.07820, (torch.Size([51, 4096]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.07573, (torch.Size([51, 4096]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.06915, (torch.Size([2048, 4808]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.06906, (torch.Size([4096, 1024]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.05995, (torch.Size([2048, 4808]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.04616, (torch.Size([512, 1024]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.04555, (torch.Size([256, 128, 3, 3]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.04273, (torch.Size([128, 2, 7, 7]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.03412, (torch.Size([512, 32]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.03067, (torch.Size([4096, 512]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01893, (torch.Size([1024, 512]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01504, (torch.Size([151, 200]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.01405, (torch.Size([4096]))
2020-03-09 18:56:36,088 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01350, (torch.Size([22801, 51]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.01341, (torch.Size([51]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01184, (torch.Size([512]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01170, (torch.Size([2048, 512]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.01108, (torch.Size([51]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01003, (torch.Size([128]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.00969, (torch.Size([256]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00933, (torch.Size([2048, 512]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00844, (torch.Size([512]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00761, (torch.Size([128]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00741, (torch.Size([4096]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00634, (torch.Size([256]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00555, (torch.Size([2048]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00555, (torch.Size([2048]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00435, (torch.Size([128]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00434, (torch.Size([2048]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00434, (torch.Size([2048]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00385, (torch.Size([1024]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00347, (torch.Size([4096]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00318, (torch.Size([256]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00274, (torch.Size([4096]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00272, (torch.Size([4096]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00162, (torch.Size([512, 1024]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00114, (torch.Size([512]))
2020-03-09 18:56:36,089 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00102, (torch.Size([256]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00098, (torch.Size([2048, 4424]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00096, (torch.Size([2048, 4424]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00092, (torch.Size([4096]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00011, (torch.Size([2048]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00011, (torch.Size([2048]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00010, (torch.Size([2048, 512]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00010, (torch.Size([2048]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00010, (torch.Size([2048]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00010, (torch.Size([2048, 512]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00001, (torch.Size([151, 200]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00001, (torch.Size([128]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00001, (torch.Size([128, 32]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00001, (torch.Size([32, 9]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00000, (torch.Size([152, 200]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.00000, (torch.Size([3072, 5136]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.00000, (torch.Size([3072]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.00000, (torch.Size([2560, 512]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.00000, (torch.Size([2560]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.00000, (torch.Size([151, 512]))
2020-03-09 18:56:36,090 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.00000, (torch.Size([151]))
2020-03-09 18:56:36,091 maskrcnn_benchmark INFO: -------------------------------
2020-03-09 18:56:36,093 maskrcnn_benchmark INFO: eta: 12:22:04  iter: 12000  loss: 0.6913 (0.8199)  auxiliary_ctx: 0.1333 (0.1648)  auxiliary_frq: 0.1851 (0.2061)  auxiliary_vis: 0.1523 (0.1826)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2110 (0.2664)  time: 0.9948 (1.1717)  data: 0.0116 (0.1966)  lr: 0.120000  max mem: 6440
2020-03-09 18:56:36,095 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_predcls/model_0012000.pth
2020-03-09 18:56:37,614 maskrcnn_benchmark INFO: Start validating
2020-03-09 18:56:37,637 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 19:02:31,978 maskrcnn_benchmark INFO: Total run time: 0:05:54.340553 (0.14173622121810914 s / img per device, on 2 devices)
2020-03-09 19:02:31,978 maskrcnn_benchmark INFO: Model inference time: 0:05:31.033997 (0.1324135989189148 s / img per device, on 2 devices)
2020-03-09 19:03:59,501 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6038;   R @ 50: 0.6569;   R @ 100: 0.6728;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6932; ngR @ 50: 0.8211; ngR @ 100: 0.8885;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0667;  zR @ 50: 0.1215;  zR @ 100: 0.1452;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1057;  mR @ 50: 0.1270;  mR @ 100: 0.1387;  for mode=predcls, type=Mean Recall.
(above:0.0883) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1215) (attached to:0.0000) (behind:0.4320) (belonging to:0.0000) (between:0.0000) (carrying:0.1184) (covered in:0.0714) (covering:0.0000) (eating:0.1429) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8188) (holding:0.5936) (in:0.3295) (in front of:0.0030) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4680) (of:0.4414) (on:0.9293) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.6295) (says:0.0000) (sitting on:0.2618) (standing on:0.0000) (to:0.0000) (under:0.1514) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.2843) (wearing:0.9822) (wears:0.0000) (with:0.0408) 
SGG eval:   A @ 20: 0.6986;   A @ 50: 0.7036;   A @ 100: 0.7036;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 19:04:00,076 maskrcnn_benchmark INFO: Validation Result: 0.6728
2020-03-09 19:07:16,736 maskrcnn_benchmark INFO: eta: 12:39:09  iter: 12200  loss: 0.7959 (0.8194)  auxiliary_ctx: 0.1478 (0.1646)  auxiliary_frq: 0.2039 (0.2061)  auxiliary_vis: 0.1693 (0.1824)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2523 (0.2662)  time: 0.9810 (1.2050)  data: 0.0113 (0.2300)  lr: 0.120000  max mem: 6440
2020-03-09 19:10:34,795 maskrcnn_benchmark INFO: eta: 12:32:58  iter: 12400  loss: 0.7172 (0.8187)  auxiliary_ctx: 0.1486 (0.1644)  auxiliary_frq: 0.1919 (0.2060)  auxiliary_vis: 0.1567 (0.1823)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2310 (0.2660)  time: 0.9805 (1.2015)  data: 0.0104 (0.2265)  lr: 0.120000  max mem: 6440
2020-03-09 19:13:52,251 maskrcnn_benchmark INFO: eta: 12:26:50  iter: 12600  loss: 0.7077 (0.8184)  auxiliary_ctx: 0.1366 (0.1643)  auxiliary_frq: 0.1900 (0.2060)  auxiliary_vis: 0.1514 (0.1822)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2262 (0.2659)  time: 0.9842 (1.1981)  data: 0.0118 (0.2231)  lr: 0.120000  max mem: 6440
2020-03-09 19:17:10,152 maskrcnn_benchmark INFO: eta: 12:20:49  iter: 12800  loss: 0.6976 (0.8176)  auxiliary_ctx: 0.1359 (0.1641)  auxiliary_frq: 0.1840 (0.2059)  auxiliary_vis: 0.1512 (0.1820)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2122 (0.2656)  time: 0.9899 (1.1949)  data: 0.0109 (0.2197)  lr: 0.120000  max mem: 6440
2020-03-09 19:20:28,055 maskrcnn_benchmark INFO: eta: 12:14:53  iter: 13000  loss: 0.7219 (0.8168)  auxiliary_ctx: 0.1414 (0.1639)  auxiliary_frq: 0.1938 (0.2058)  auxiliary_vis: 0.1527 (0.1818)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2249 (0.2653)  time: 0.9901 (1.1917)  data: 0.0107 (0.2165)  lr: 0.120000  max mem: 6440
2020-03-09 19:23:45,041 maskrcnn_benchmark INFO: eta: 12:09:00  iter: 13200  loss: 0.7701 (0.8159)  auxiliary_ctx: 0.1495 (0.1637)  auxiliary_frq: 0.1951 (0.2057)  auxiliary_vis: 0.1783 (0.1816)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2423 (0.2650)  time: 0.9816 (1.1886)  data: 0.0109 (0.2134)  lr: 0.120000  max mem: 6440
2020-03-09 19:27:02,792 maskrcnn_benchmark INFO: eta: 12:03:13  iter: 13400  loss: 0.7418 (0.8154)  auxiliary_ctx: 0.1560 (0.1635)  auxiliary_frq: 0.1992 (0.2056)  auxiliary_vis: 0.1692 (0.1814)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2436 (0.2649)  time: 0.9782 (1.1856)  data: 0.0110 (0.2104)  lr: 0.120000  max mem: 6440
2020-03-09 19:30:20,843 maskrcnn_benchmark INFO: eta: 11:57:31  iter: 13600  loss: 0.7282 (0.8147)  auxiliary_ctx: 0.1420 (0.1633)  auxiliary_frq: 0.1927 (0.2055)  auxiliary_vis: 0.1647 (0.1813)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2169 (0.2646)  time: 0.9876 (1.1827)  data: 0.0112 (0.2075)  lr: 0.120000  max mem: 6440
2020-03-09 19:33:38,038 maskrcnn_benchmark INFO: eta: 11:51:51  iter: 13800  loss: 0.7357 (0.8144)  auxiliary_ctx: 0.1489 (0.1632)  auxiliary_frq: 0.1994 (0.2055)  auxiliary_vis: 0.1762 (0.1812)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2322 (0.2645)  time: 0.9793 (1.1799)  data: 0.0117 (0.2046)  lr: 0.120000  max mem: 6440
2020-03-09 19:36:55,425 maskrcnn_benchmark INFO: eta: 11:46:16  iter: 14000  loss: 0.7967 (0.8142)  auxiliary_ctx: 0.1528 (0.1631)  auxiliary_frq: 0.2014 (0.2054)  auxiliary_vis: 0.1659 (0.1811)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2394 (0.2645)  time: 0.9930 (1.1771)  data: 0.0117 (0.2019)  lr: 0.120000  max mem: 6440
2020-03-09 19:36:55,427 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_predcls/model_0014000.pth
2020-03-09 19:36:56,971 maskrcnn_benchmark INFO: Start validating
2020-03-09 19:36:56,987 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 19:42:51,363 maskrcnn_benchmark INFO: Total run time: 0:05:54.375337 (0.14175013494491578 s / img per device, on 2 devices)
2020-03-09 19:42:51,363 maskrcnn_benchmark INFO: Model inference time: 0:05:30.541871 (0.13221674852371215 s / img per device, on 2 devices)
2020-03-09 19:44:19,400 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6025;   R @ 50: 0.6573;   R @ 100: 0.6743;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6932; ngR @ 50: 0.8202; ngR @ 100: 0.8877;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0600;  zR @ 50: 0.1385;  zR @ 100: 0.1496;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1007;  mR @ 50: 0.1185;  mR @ 100: 0.1297;  for mode=predcls, type=Mean Recall.
(above:0.0702) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1086) (attached to:0.0000) (behind:0.4926) (belonging to:0.0000) (between:0.0000) (carrying:0.1096) (covered in:0.0000) (covering:0.0000) (eating:0.2857) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8429) (holding:0.6554) (in:0.3210) (in front of:0.0213) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4549) (of:0.3437) (on:0.9436) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.3884) (says:0.0000) (sitting on:0.2047) (standing on:0.0109) (to:0.0000) (under:0.1173) (using:0.0000) (walking in:0.0000) (walking on:0.0738) (watching:0.0000) (wearing:0.9679) (wears:0.0000) (with:0.0490) 
SGG eval:   A @ 20: 0.6986;   A @ 50: 0.7036;   A @ 100: 0.7036;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 19:44:19,990 maskrcnn_benchmark INFO: Validation Result: 0.6743
2020-03-09 19:44:19,990 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-03-09 19:47:36,758 maskrcnn_benchmark INFO: eta: 11:59:24  iter: 14200  loss: 0.7422 (0.8134)  auxiliary_ctx: 0.1491 (0.1629)  auxiliary_frq: 0.1948 (0.2054)  auxiliary_vis: 0.1634 (0.1809)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2322 (0.2642)  time: 0.9808 (1.2057)  data: 0.0119 (0.2305)  lr: 0.012000  max mem: 6440
2020-03-09 19:50:54,651 maskrcnn_benchmark INFO: eta: 11:53:36  iter: 14400  loss: 0.7111 (0.8124)  auxiliary_ctx: 0.1345 (0.1627)  auxiliary_frq: 0.1901 (0.2053)  auxiliary_vis: 0.1589 (0.1807)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2175 (0.2638)  time: 0.9949 (1.2027)  data: 0.0117 (0.2274)  lr: 0.012000  max mem: 6440
2020-03-09 19:54:11,746 maskrcnn_benchmark INFO: eta: 11:47:50  iter: 14600  loss: 0.6814 (0.8117)  auxiliary_ctx: 0.1357 (0.1624)  auxiliary_frq: 0.1916 (0.2052)  auxiliary_vis: 0.1492 (0.1805)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2027 (0.2635)  time: 0.9822 (1.1997)  data: 0.0114 (0.2245)  lr: 0.012000  max mem: 6440
2020-03-09 19:57:29,512 maskrcnn_benchmark INFO: eta: 11:42:10  iter: 14800  loss: 0.7298 (0.8105)  auxiliary_ctx: 0.1407 (0.1621)  auxiliary_frq: 0.1981 (0.2051)  auxiliary_vis: 0.1582 (0.1802)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2408 (0.2631)  time: 0.9827 (1.1969)  data: 0.0098 (0.2216)  lr: 0.012000  max mem: 6440
2020-03-09 20:00:47,138 maskrcnn_benchmark INFO: eta: 11:36:33  iter: 15000  loss: 0.7418 (0.8096)  auxiliary_ctx: 0.1429 (0.1619)  auxiliary_frq: 0.1986 (0.2051)  auxiliary_vis: 0.1632 (0.1799)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2300 (0.2627)  time: 0.9870 (1.1941)  data: 0.0103 (0.2188)  lr: 0.012000  max mem: 6440
2020-03-09 20:04:05,774 maskrcnn_benchmark INFO: eta: 11:31:02  iter: 15200  loss: 0.7027 (0.8085)  auxiliary_ctx: 0.1355 (0.1616)  auxiliary_frq: 0.1891 (0.2050)  auxiliary_vis: 0.1531 (0.1796)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2203 (0.2623)  time: 0.9936 (1.1915)  data: 0.0111 (0.2160)  lr: 0.012000  max mem: 6440
2020-03-09 20:07:24,052 maskrcnn_benchmark INFO: eta: 11:25:34  iter: 15400  loss: 0.6544 (0.8073)  auxiliary_ctx: 0.1309 (0.1613)  auxiliary_frq: 0.1873 (0.2049)  auxiliary_vis: 0.1396 (0.1793)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2043 (0.2618)  time: 0.9863 (1.1889)  data: 0.0111 (0.2134)  lr: 0.012000  max mem: 6440
2020-03-09 20:10:41,373 maskrcnn_benchmark INFO: eta: 11:20:07  iter: 15600  loss: 0.7144 (0.8066)  auxiliary_ctx: 0.1405 (0.1611)  auxiliary_frq: 0.1884 (0.2049)  auxiliary_vis: 0.1537 (0.1791)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2191 (0.2615)  time: 0.9772 (1.1863)  data: 0.0111 (0.2108)  lr: 0.012000  max mem: 6440
2020-03-09 20:13:58,699 maskrcnn_benchmark INFO: eta: 11:14:43  iter: 15800  loss: 0.6915 (0.8056)  auxiliary_ctx: 0.1334 (0.1609)  auxiliary_frq: 0.1920 (0.2048)  auxiliary_vis: 0.1536 (0.1788)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2150 (0.2611)  time: 0.9944 (1.1837)  data: 0.0112 (0.2082)  lr: 0.012000  max mem: 6440
2020-03-09 20:17:16,183 maskrcnn_benchmark INFO: ---Total norm 0.91257 clip coef 5.47903-----------------
2020-03-09 20:17:16,194 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.46941, (torch.Size([4096, 12544]))
2020-03-09 20:17:16,194 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.40779, (torch.Size([4096, 12544]))
2020-03-09 20:17:16,194 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.28948, (torch.Size([256, 1024, 3, 3]))
2020-03-09 20:17:16,194 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.28399, (torch.Size([4096, 4096]))
2020-03-09 20:17:16,194 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.23368, (torch.Size([4096, 4096]))
2020-03-09 20:17:16,194 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.19935, (torch.Size([51, 4096]))
2020-03-09 20:17:16,194 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.19744, (torch.Size([4096, 1024]))
2020-03-09 20:17:16,194 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.19534, (torch.Size([51, 4096]))
2020-03-09 20:17:16,194 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.15634, (torch.Size([2048, 4808]))
2020-03-09 20:17:16,194 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.13455, (torch.Size([2048, 4808]))
2020-03-09 20:17:16,194 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.12679, (torch.Size([512, 1024]))
2020-03-09 20:17:16,194 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.10070, (torch.Size([256, 128, 3, 3]))
2020-03-09 20:17:16,194 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.09705, (torch.Size([128, 2, 7, 7]))
2020-03-09 20:17:16,194 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.09489, (torch.Size([512, 32]))
2020-03-09 20:17:16,194 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.09060, (torch.Size([4096, 512]))
2020-03-09 20:17:16,194 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.06166, (torch.Size([1024, 512]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.03752, (torch.Size([51]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.03744, (torch.Size([512]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.03470, (torch.Size([151, 200]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.03332, (torch.Size([51]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.03089, (torch.Size([4096]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.02703, (torch.Size([512]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.02526, (torch.Size([22801, 51]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.02237, (torch.Size([128]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.02185, (torch.Size([256]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.02089, (torch.Size([2048, 512]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01969, (torch.Size([2048, 512]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.01520, (torch.Size([4096]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01391, (torch.Size([2048]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01391, (torch.Size([2048]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.01345, (torch.Size([128]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01335, (torch.Size([4096]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.01320, (torch.Size([256]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01247, (torch.Size([1024]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01105, (torch.Size([2048]))
2020-03-09 20:17:16,195 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01105, (torch.Size([2048]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00727, (torch.Size([256]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00698, (torch.Size([4096]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00594, (torch.Size([128]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00541, (torch.Size([4096]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00319, (torch.Size([512, 1024]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00292, (torch.Size([512]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00259, (torch.Size([256]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00234, (torch.Size([4096]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00211, (torch.Size([2048, 4424]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00144, (torch.Size([2048, 4424]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00029, (torch.Size([2048]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00029, (torch.Size([2048]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00024, (torch.Size([2048, 512]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00016, (torch.Size([2048]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00016, (torch.Size([2048]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00007, (torch.Size([2048, 512]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00003, (torch.Size([128]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00002, (torch.Size([151, 200]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00001, (torch.Size([128, 32]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00001, (torch.Size([32, 9]))
2020-03-09 20:17:16,196 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-03-09 20:17:16,197 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-03-09 20:17:16,197 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-09 20:17:16,197 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00000, (torch.Size([152, 200]))
2020-03-09 20:17:16,197 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.00000, (torch.Size([3072, 5136]))
2020-03-09 20:17:16,197 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.00000, (torch.Size([3072]))
2020-03-09 20:17:16,197 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.00000, (torch.Size([2560, 512]))
2020-03-09 20:17:16,197 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.00000, (torch.Size([2560]))
2020-03-09 20:17:16,197 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.00000, (torch.Size([151, 512]))
2020-03-09 20:17:16,197 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.00000, (torch.Size([151]))
2020-03-09 20:17:16,197 maskrcnn_benchmark INFO: -------------------------------
2020-03-09 20:17:16,200 maskrcnn_benchmark INFO: eta: 11:09:23  iter: 16000  loss: 0.6603 (0.8049)  auxiliary_ctx: 0.1274 (0.1607)  auxiliary_frq: 0.1898 (0.2048)  auxiliary_vis: 0.1427 (0.1786)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2048 (0.2608)  time: 0.9913 (1.1813)  data: 0.0116 (0.2058)  lr: 0.012000  max mem: 6440
2020-03-09 20:17:16,202 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_predcls/model_0016000.pth
2020-03-09 20:17:17,849 maskrcnn_benchmark INFO: Start validating
2020-03-09 20:17:17,871 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 20:23:12,693 maskrcnn_benchmark INFO: Total run time: 0:05:54.821745 (0.14192869787216186 s / img per device, on 2 devices)
2020-03-09 20:23:12,693 maskrcnn_benchmark INFO: Model inference time: 0:05:30.053660 (0.1320214641571045 s / img per device, on 2 devices)
2020-03-09 20:24:40,501 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6116;   R @ 50: 0.6651;   R @ 100: 0.6807;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.7071; ngR @ 50: 0.8313; ngR @ 100: 0.8971;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0704;  zR @ 50: 0.1519;  zR @ 100: 0.1652;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1207;  mR @ 50: 0.1465;  mR @ 100: 0.1569;  for mode=predcls, type=Mean Recall.
(above:0.1225) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2286) (attached to:0.0000) (behind:0.4971) (belonging to:0.0000) (between:0.0000) (carrying:0.2412) (covered in:0.0714) (covering:0.0000) (eating:0.6190) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8300) (holding:0.5973) (in:0.3528) (in front of:0.0732) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5056) (of:0.3768) (on:0.9304) (on back of:0.0000) (over:0.0813) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.3497) (says:0.0000) (sitting on:0.2395) (standing on:0.0109) (to:0.0000) (under:0.1964) (using:0.0000) (walking in:0.0000) (walking on:0.0927) (watching:0.3824) (wearing:0.9766) (wears:0.0000) (with:0.0687) 
SGG eval:   A @ 20: 0.7033;   A @ 50: 0.7084;   A @ 100: 0.7084;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 20:24:41,102 maskrcnn_benchmark INFO: Validation Result: 0.6807
2020-03-09 20:27:58,437 maskrcnn_benchmark INFO: eta: 11:19:34  iter: 16200  loss: 0.6764 (0.8044)  auxiliary_ctx: 0.1378 (0.1605)  auxiliary_frq: 0.1933 (0.2048)  auxiliary_vis: 0.1436 (0.1784)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2046 (0.2606)  time: 0.9898 (1.2063)  data: 0.0117 (0.2308)  lr: 0.012000  max mem: 6440
2020-03-09 20:31:15,371 maskrcnn_benchmark INFO: eta: 11:14:02  iter: 16400  loss: 0.7306 (0.8037)  auxiliary_ctx: 0.1397 (0.1603)  auxiliary_frq: 0.2028 (0.2048)  auxiliary_vis: 0.1563 (0.1782)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2243 (0.2604)  time: 0.9761 (1.2036)  data: 0.0118 (0.2282)  lr: 0.012000  max mem: 6440
2020-03-09 20:34:33,968 maskrcnn_benchmark INFO: eta: 11:08:36  iter: 16600  loss: 0.7418 (0.8029)  auxiliary_ctx: 0.1465 (0.1601)  auxiliary_frq: 0.2023 (0.2048)  auxiliary_vis: 0.1585 (0.1780)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2178 (0.2600)  time: 0.9899 (1.2011)  data: 0.0115 (0.2256)  lr: 0.012000  max mem: 6440
2020-03-09 20:37:51,819 maskrcnn_benchmark INFO: eta: 11:03:13  iter: 16800  loss: 0.7396 (0.8020)  auxiliary_ctx: 0.1451 (0.1599)  auxiliary_frq: 0.2060 (0.2047)  auxiliary_vis: 0.1618 (0.1778)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2272 (0.2596)  time: 0.9963 (1.1986)  data: 0.0119 (0.2230)  lr: 0.012000  max mem: 6440
2020-03-09 20:41:10,122 maskrcnn_benchmark INFO: eta: 10:57:52  iter: 17000  loss: 0.6733 (0.8011)  auxiliary_ctx: 0.1310 (0.1596)  auxiliary_frq: 0.1981 (0.2047)  auxiliary_vis: 0.1487 (0.1775)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2012 (0.2593)  time: 0.9883 (1.1961)  data: 0.0110 (0.2205)  lr: 0.012000  max mem: 6440
2020-03-09 20:44:29,106 maskrcnn_benchmark INFO: eta: 10:52:36  iter: 17200  loss: 0.7271 (0.8003)  auxiliary_ctx: 0.1419 (0.1594)  auxiliary_frq: 0.1941 (0.2046)  auxiliary_vis: 0.1580 (0.1773)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2243 (0.2590)  time: 0.9859 (1.1938)  data: 0.0117 (0.2181)  lr: 0.012000  max mem: 6440
2020-03-09 20:47:48,575 maskrcnn_benchmark INFO: eta: 10:47:24  iter: 17400  loss: 0.6960 (0.7994)  auxiliary_ctx: 0.1381 (0.1592)  auxiliary_frq: 0.1892 (0.2046)  auxiliary_vis: 0.1590 (0.1770)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2047 (0.2586)  time: 0.9873 (1.1916)  data: 0.0113 (0.2157)  lr: 0.012000  max mem: 6440
2020-03-09 20:51:07,095 maskrcnn_benchmark INFO: eta: 10:42:12  iter: 17600  loss: 0.7453 (0.7985)  auxiliary_ctx: 0.1488 (0.1590)  auxiliary_frq: 0.2018 (0.2045)  auxiliary_vis: 0.1571 (0.1768)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2208 (0.2582)  time: 0.9874 (1.1893)  data: 0.0110 (0.2134)  lr: 0.012000  max mem: 6440
2020-03-09 20:54:25,197 maskrcnn_benchmark INFO: eta: 10:37:03  iter: 17800  loss: 0.7220 (0.7976)  auxiliary_ctx: 0.1421 (0.1587)  auxiliary_frq: 0.2006 (0.2044)  auxiliary_vis: 0.1603 (0.1765)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2229 (0.2579)  time: 0.9842 (1.1871)  data: 0.0108 (0.2111)  lr: 0.012000  max mem: 6440
2020-03-09 20:57:42,758 maskrcnn_benchmark INFO: eta: 10:31:54  iter: 18000  loss: 0.7090 (0.7968)  auxiliary_ctx: 0.1342 (0.1585)  auxiliary_frq: 0.1983 (0.2044)  auxiliary_vis: 0.1512 (0.1763)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2228 (0.2576)  time: 0.9861 (1.1848)  data: 0.0113 (0.2089)  lr: 0.012000  max mem: 6440
2020-03-09 20:57:42,760 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_predcls/model_0018000.pth
2020-03-09 20:57:44,300 maskrcnn_benchmark INFO: Start validating
2020-03-09 20:57:44,321 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 21:03:40,334 maskrcnn_benchmark INFO: Total run time: 0:05:56.013025 (0.1424052098274231 s / img per device, on 2 devices)
2020-03-09 21:03:40,335 maskrcnn_benchmark INFO: Model inference time: 0:05:31.281106 (0.13251244249343871 s / img per device, on 2 devices)
2020-03-09 21:05:08,646 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6135;   R @ 50: 0.6668;   R @ 100: 0.6821;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.7085; ngR @ 50: 0.8333; ngR @ 100: 0.8989;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0800;  zR @ 50: 0.1563;  zR @ 100: 0.1696;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1237;  mR @ 50: 0.1501;  mR @ 100: 0.1586;  for mode=predcls, type=Mean Recall.
(above:0.1153) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1532) (attached to:0.0000) (behind:0.4686) (belonging to:0.0000) (between:0.0000) (carrying:0.4320) (covered in:0.0714) (covering:0.0000) (eating:0.6190) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8292) (holding:0.5847) (in:0.3681) (in front of:0.0488) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5420) (of:0.4420) (on:0.9195) (on back of:0.0000) (over:0.0732) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.3943) (says:0.0000) (sitting on:0.2709) (standing on:0.0109) (to:0.0000) (under:0.1616) (using:0.0000) (walking in:0.0000) (walking on:0.0530) (watching:0.3235) (wearing:0.9754) (wears:0.0000) (with:0.0727) 
SGG eval:   A @ 20: 0.7032;   A @ 50: 0.7085;   A @ 100: 0.7085;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 21:05:09,203 maskrcnn_benchmark INFO: Validation Result: 0.6821
2020-03-09 21:08:26,253 maskrcnn_benchmark INFO: eta: 10:39:48  iter: 18200  loss: 0.6954 (0.7962)  auxiliary_ctx: 0.1364 (0.1584)  auxiliary_frq: 0.1893 (0.2043)  auxiliary_vis: 0.1586 (0.1761)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2127 (0.2573)  time: 0.9834 (1.2072)  data: 0.0113 (0.2313)  lr: 0.012000  max mem: 6440
2020-03-09 21:11:44,753 maskrcnn_benchmark INFO: eta: 10:34:33  iter: 18400  loss: 0.6904 (0.7954)  auxiliary_ctx: 0.1363 (0.1582)  auxiliary_frq: 0.1938 (0.2043)  auxiliary_vis: 0.1459 (0.1759)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2131 (0.2570)  time: 0.9976 (1.2048)  data: 0.0102 (0.2289)  lr: 0.012000  max mem: 6440
2020-03-09 21:15:04,206 maskrcnn_benchmark INFO: eta: 10:29:22  iter: 18600  loss: 0.6641 (0.7945)  auxiliary_ctx: 0.1249 (0.1580)  auxiliary_frq: 0.1926 (0.2042)  auxiliary_vis: 0.1472 (0.1757)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2044 (0.2567)  time: 0.9848 (1.2026)  data: 0.0097 (0.2265)  lr: 0.012000  max mem: 6440
2020-03-09 21:18:22,405 maskrcnn_benchmark INFO: eta: 10:24:11  iter: 18800  loss: 0.7721 (0.7940)  auxiliary_ctx: 0.1416 (0.1578)  auxiliary_frq: 0.2095 (0.2042)  auxiliary_vis: 0.1547 (0.1755)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2434 (0.2565)  time: 0.9987 (1.2004)  data: 0.0112 (0.2242)  lr: 0.012000  max mem: 6440
2020-03-09 21:21:40,502 maskrcnn_benchmark INFO: eta: 10:19:02  iter: 19000  loss: 0.6848 (0.7934)  auxiliary_ctx: 0.1271 (0.1577)  auxiliary_frq: 0.1903 (0.2042)  auxiliary_vis: 0.1441 (0.1754)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2053 (0.2562)  time: 0.9920 (1.1982)  data: 0.0100 (0.2220)  lr: 0.012000  max mem: 6440
2020-03-09 21:24:58,794 maskrcnn_benchmark INFO: eta: 10:13:56  iter: 19200  loss: 0.6756 (0.7928)  auxiliary_ctx: 0.1273 (0.1575)  auxiliary_frq: 0.1959 (0.2041)  auxiliary_vis: 0.1419 (0.1752)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2187 (0.2560)  time: 0.9947 (1.1960)  data: 0.0113 (0.2198)  lr: 0.012000  max mem: 6440
2020-03-09 21:28:15,655 maskrcnn_benchmark INFO: eta: 10:08:50  iter: 19400  loss: 0.7364 (0.7919)  auxiliary_ctx: 0.1402 (0.1573)  auxiliary_frq: 0.1987 (0.2041)  auxiliary_vis: 0.1551 (0.1749)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2369 (0.2556)  time: 0.9892 (1.1938)  data: 0.0112 (0.2176)  lr: 0.012000  max mem: 6440
2020-03-09 21:31:34,049 maskrcnn_benchmark INFO: eta: 10:03:49  iter: 19600  loss: 0.7047 (0.7910)  auxiliary_ctx: 0.1392 (0.1571)  auxiliary_frq: 0.2031 (0.2040)  auxiliary_vis: 0.1537 (0.1747)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2159 (0.2552)  time: 0.9814 (1.1918)  data: 0.0111 (0.2155)  lr: 0.012000  max mem: 6440
2020-03-09 21:34:52,635 maskrcnn_benchmark INFO: eta: 9:58:50  iter: 19800  loss: 0.6309 (0.7902)  auxiliary_ctx: 0.1212 (0.1569)  auxiliary_frq: 0.1915 (0.2040)  auxiliary_vis: 0.1334 (0.1744)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1955 (0.2549)  time: 0.9876 (1.1897)  data: 0.0111 (0.2135)  lr: 0.012000  max mem: 6440
2020-03-09 21:38:09,924 maskrcnn_benchmark INFO: ---Total norm 0.39083 clip coef 12.79327-----------------
2020-03-09 21:38:09,934 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.23337, (torch.Size([4096, 12544]))
2020-03-09 21:38:09,934 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.14247, (torch.Size([4096, 12544]))
2020-03-09 21:38:09,934 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.11889, (torch.Size([256, 1024, 3, 3]))
2020-03-09 21:38:09,934 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.11484, (torch.Size([4096, 4096]))
2020-03-09 21:38:09,934 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.09683, (torch.Size([51, 4096]))
2020-03-09 21:38:09,934 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.09584, (torch.Size([51, 4096]))
2020-03-09 21:38:09,934 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.09533, (torch.Size([4096, 4096]))
2020-03-09 21:38:09,934 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.08101, (torch.Size([4096, 1024]))
2020-03-09 21:38:09,934 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.05290, (torch.Size([2048, 4808]))
2020-03-09 21:38:09,934 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.05071, (torch.Size([2048, 4808]))
2020-03-09 21:38:09,934 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.04970, (torch.Size([256, 128, 3, 3]))
2020-03-09 21:38:09,934 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.04315, (torch.Size([128, 2, 7, 7]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.04216, (torch.Size([512, 1024]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.04173, (torch.Size([4096, 512]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.02759, (torch.Size([512, 32]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02320, (torch.Size([1024, 512]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01448, (torch.Size([22801, 51]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.01396, (torch.Size([51]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01350, (torch.Size([512]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.01342, (torch.Size([51]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01328, (torch.Size([256]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01229, (torch.Size([128]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01188, (torch.Size([151, 200]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.01035, (torch.Size([4096]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00927, (torch.Size([2048, 512]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00843, (torch.Size([256]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00826, (torch.Size([4096]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00764, (torch.Size([2048, 512]))
2020-03-09 21:38:09,935 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00720, (torch.Size([128]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00684, (torch.Size([4096]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00625, (torch.Size([1024]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.00608, (torch.Size([512]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00490, (torch.Size([128]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00450, (torch.Size([2048]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00450, (torch.Size([2048]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00408, (torch.Size([2048]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00408, (torch.Size([2048]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00387, (torch.Size([256]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00307, (torch.Size([4096]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00245, (torch.Size([4096]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00119, (torch.Size([256]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00115, (torch.Size([512, 1024]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00083, (torch.Size([512]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00079, (torch.Size([4096]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00079, (torch.Size([2048, 4424]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00076, (torch.Size([2048, 4424]))
2020-03-09 21:38:09,936 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00008, (torch.Size([2048]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00008, (torch.Size([2048]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00008, (torch.Size([2048, 512]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00006, (torch.Size([2048]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00006, (torch.Size([2048]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00005, (torch.Size([2048, 512]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00001, (torch.Size([128]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00001, (torch.Size([128, 32]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00001, (torch.Size([151, 200]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00000, (torch.Size([32, 9]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00000, (torch.Size([152, 200]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.00000, (torch.Size([3072, 5136]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.00000, (torch.Size([3072]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.00000, (torch.Size([2560, 512]))
2020-03-09 21:38:09,937 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.00000, (torch.Size([2560]))
2020-03-09 21:38:09,938 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.00000, (torch.Size([151, 512]))
2020-03-09 21:38:09,938 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.00000, (torch.Size([151]))
2020-03-09 21:38:09,938 maskrcnn_benchmark INFO: -------------------------------
2020-03-09 21:38:09,940 maskrcnn_benchmark INFO: eta: 9:53:51  iter: 20000  loss: 0.6244 (0.7896)  auxiliary_ctx: 0.1191 (0.1567)  auxiliary_frq: 0.1832 (0.2039)  auxiliary_vis: 0.1270 (0.1743)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1938 (0.2546)  time: 0.9899 (1.1877)  data: 0.0107 (0.2114)  lr: 0.012000  max mem: 6440
2020-03-09 21:38:09,942 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_predcls/model_0020000.pth
2020-03-09 21:38:11,485 maskrcnn_benchmark INFO: Start validating
2020-03-09 21:38:11,514 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 21:44:06,768 maskrcnn_benchmark INFO: Total run time: 0:05:55.253474 (0.1421013897895813 s / img per device, on 2 devices)
2020-03-09 21:44:06,769 maskrcnn_benchmark INFO: Model inference time: 0:05:30.149041 (0.13205961656570434 s / img per device, on 2 devices)
2020-03-09 21:45:35,528 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6137;   R @ 50: 0.6666;   R @ 100: 0.6823;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.7114; ngR @ 50: 0.8344; ngR @ 100: 0.8989;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0800;  zR @ 50: 0.1519;  zR @ 100: 0.1674;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1228;  mR @ 50: 0.1469;  mR @ 100: 0.1634;  for mode=predcls, type=Mean Recall.
(above:0.1345) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1919) (attached to:0.0000) (behind:0.4660) (belonging to:0.0000) (between:0.0000) (carrying:0.3728) (covered in:0.1429) (covering:0.0000) (eating:0.7143) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8254) (holding:0.5936) (in:0.3653) (in front of:0.1110) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5220) (of:0.4015) (on:0.9261) (on back of:0.0000) (over:0.0935) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2902) (says:0.0000) (sitting on:0.2317) (standing on:0.0109) (to:0.0000) (under:0.1947) (using:0.0769) (walking in:0.0000) (walking on:0.0423) (watching:0.3824) (wearing:0.9764) (wears:0.0000) (with:0.0675) 
SGG eval:   A @ 20: 0.7039;   A @ 50: 0.7092;   A @ 100: 0.7092;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 21:45:36,119 maskrcnn_benchmark INFO: Validation Result: 0.6823
2020-03-09 21:48:53,450 maskrcnn_benchmark INFO: eta: 9:59:52  iter: 20200  loss: 0.6973 (0.7888)  auxiliary_ctx: 0.1339 (0.1565)  auxiliary_frq: 0.2018 (0.2039)  auxiliary_vis: 0.1482 (0.1740)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2195 (0.2543)  time: 0.9935 (1.2078)  data: 0.0114 (0.2315)  lr: 0.012000  max mem: 6440
2020-03-09 21:52:11,768 maskrcnn_benchmark INFO: eta: 9:54:48  iter: 20400  loss: 0.6628 (0.7882)  auxiliary_ctx: 0.1269 (0.1564)  auxiliary_frq: 0.1857 (0.2039)  auxiliary_vis: 0.1434 (0.1739)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2076 (0.2541)  time: 0.9895 (1.2057)  data: 0.0114 (0.2294)  lr: 0.012000  max mem: 6440
2020-03-09 21:55:30,311 maskrcnn_benchmark INFO: eta: 9:49:46  iter: 20600  loss: 0.6374 (0.7875)  auxiliary_ctx: 0.1179 (0.1562)  auxiliary_frq: 0.1881 (0.2038)  auxiliary_vis: 0.1334 (0.1737)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1963 (0.2538)  time: 0.9979 (1.2036)  data: 0.0114 (0.2273)  lr: 0.012000  max mem: 6440
2020-03-09 21:58:48,319 maskrcnn_benchmark INFO: eta: 9:44:45  iter: 20800  loss: 0.6958 (0.7868)  auxiliary_ctx: 0.1333 (0.1561)  auxiliary_frq: 0.1938 (0.2038)  auxiliary_vis: 0.1541 (0.1735)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2190 (0.2535)  time: 0.9907 (1.2016)  data: 0.0113 (0.2252)  lr: 0.012000  max mem: 6440
2020-03-09 22:02:07,112 maskrcnn_benchmark INFO: eta: 9:39:48  iter: 21000  loss: 0.6763 (0.7861)  auxiliary_ctx: 0.1371 (0.1559)  auxiliary_frq: 0.1919 (0.2038)  auxiliary_vis: 0.1499 (0.1733)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2152 (0.2532)  time: 0.9763 (1.1996)  data: 0.0118 (0.2232)  lr: 0.012000  max mem: 6440
2020-03-09 22:05:24,767 maskrcnn_benchmark INFO: eta: 9:34:50  iter: 21200  loss: 0.6919 (0.7856)  auxiliary_ctx: 0.1358 (0.1557)  auxiliary_frq: 0.1897 (0.2037)  auxiliary_vis: 0.1504 (0.1731)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2055 (0.2530)  time: 0.9978 (1.1976)  data: 0.0116 (0.2212)  lr: 0.012000  max mem: 6440
2020-03-09 22:08:42,379 maskrcnn_benchmark INFO: eta: 9:29:55  iter: 21400  loss: 0.6900 (0.7850)  auxiliary_ctx: 0.1335 (0.1556)  auxiliary_frq: 0.1992 (0.2037)  auxiliary_vis: 0.1388 (0.1730)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2143 (0.2527)  time: 0.9822 (1.1956)  data: 0.0115 (0.2192)  lr: 0.012000  max mem: 6440
2020-03-09 22:12:00,499 maskrcnn_benchmark INFO: eta: 9:25:02  iter: 21600  loss: 0.6730 (0.7843)  auxiliary_ctx: 0.1278 (0.1554)  auxiliary_frq: 0.1897 (0.2037)  auxiliary_vis: 0.1474 (0.1728)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1979 (0.2525)  time: 0.9910 (1.1937)  data: 0.0117 (0.2173)  lr: 0.012000  max mem: 6440
2020-03-09 22:15:19,086 maskrcnn_benchmark INFO: eta: 9:20:11  iter: 21800  loss: 0.6654 (0.7838)  auxiliary_ctx: 0.1322 (0.1553)  auxiliary_frq: 0.1933 (0.2036)  auxiliary_vis: 0.1457 (0.1726)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1969 (0.2523)  time: 0.9973 (1.1919)  data: 0.0115 (0.2154)  lr: 0.012000  max mem: 6440
2020-03-09 22:18:37,384 maskrcnn_benchmark INFO: eta: 9:15:22  iter: 22000  loss: 0.7068 (0.7833)  auxiliary_ctx: 0.1416 (0.1552)  auxiliary_frq: 0.1946 (0.2036)  auxiliary_vis: 0.1550 (0.1725)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2123 (0.2520)  time: 0.9830 (1.1901)  data: 0.0107 (0.2135)  lr: 0.012000  max mem: 6440
2020-03-09 22:18:37,386 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_predcls/model_0022000.pth
2020-03-09 22:18:39,043 maskrcnn_benchmark INFO: Start validating
2020-03-09 22:18:39,063 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 22:24:32,985 maskrcnn_benchmark INFO: Total run time: 0:05:53.922428 (0.14156897134780883 s / img per device, on 2 devices)
2020-03-09 22:24:32,986 maskrcnn_benchmark INFO: Model inference time: 0:05:29.667198 (0.1318668791770935 s / img per device, on 2 devices)
2020-03-09 22:25:59,791 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6145;   R @ 50: 0.6678;   R @ 100: 0.6842;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.7109; ngR @ 50: 0.8345; ngR @ 100: 0.9003;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0867;  zR @ 50: 0.1593;  zR @ 100: 0.1830;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1232;  mR @ 50: 0.1480;  mR @ 100: 0.1661;  for mode=predcls, type=Mean Recall.
(above:0.1489) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.2040) (attached to:0.0000) (behind:0.5153) (belonging to:0.0000) (between:0.0000) (carrying:0.3838) (covered in:0.1429) (covering:0.0000) (eating:0.5714) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8227) (holding:0.5936) (in:0.3701) (in front of:0.1178) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5168) (of:0.4134) (on:0.9245) (on back of:0.0000) (over:0.0813) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.3795) (says:0.0000) (sitting on:0.2448) (standing on:0.0130) (to:0.0000) (under:0.2228) (using:0.1538) (walking in:0.0000) (walking on:0.0643) (watching:0.3627) (wearing:0.9779) (wears:0.0000) (with:0.0782) 
SGG eval:   A @ 20: 0.7061;   A @ 50: 0.7114;   A @ 100: 0.7114;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 22:26:00,337 maskrcnn_benchmark INFO: Validation Result: 0.6842
2020-03-09 22:29:17,111 maskrcnn_benchmark INFO: eta: 9:19:47  iter: 22200  loss: 0.6689 (0.7828)  auxiliary_ctx: 0.1324 (0.1550)  auxiliary_frq: 0.1927 (0.2036)  auxiliary_vis: 0.1458 (0.1723)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1879 (0.2518)  time: 0.9908 (1.2082)  data: 0.0116 (0.2317)  lr: 0.012000  max mem: 6440
2020-03-09 22:32:35,310 maskrcnn_benchmark INFO: eta: 9:14:52  iter: 22400  loss: 0.7256 (0.7822)  auxiliary_ctx: 0.1487 (0.1549)  auxiliary_frq: 0.1982 (0.2036)  auxiliary_vis: 0.1607 (0.1722)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2162 (0.2516)  time: 0.9840 (1.2062)  data: 0.0111 (0.2297)  lr: 0.012000  max mem: 6440
2020-03-09 22:35:54,651 maskrcnn_benchmark INFO: eta: 9:10:00  iter: 22600  loss: 0.7070 (0.7815)  auxiliary_ctx: 0.1362 (0.1547)  auxiliary_frq: 0.1952 (0.2035)  auxiliary_vis: 0.1501 (0.1720)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2094 (0.2513)  time: 0.9829 (1.2044)  data: 0.0099 (0.2278)  lr: 0.012000  max mem: 6440
2020-03-09 22:39:13,690 maskrcnn_benchmark INFO: eta: 9:05:09  iter: 22800  loss: 0.6049 (0.7810)  auxiliary_ctx: 0.1180 (0.1546)  auxiliary_frq: 0.1802 (0.2035)  auxiliary_vis: 0.1281 (0.1718)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1837 (0.2511)  time: 0.9800 (1.2025)  data: 0.0114 (0.2259)  lr: 0.012000  max mem: 6440
2020-03-09 22:42:32,607 maskrcnn_benchmark INFO: eta: 9:00:19  iter: 23000  loss: 0.6450 (0.7804)  auxiliary_ctx: 0.1211 (0.1545)  auxiliary_frq: 0.1851 (0.2034)  auxiliary_vis: 0.1409 (0.1716)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1946 (0.2509)  time: 0.9964 (1.2007)  data: 0.0100 (0.2240)  lr: 0.012000  max mem: 6440
2020-03-09 22:45:51,009 maskrcnn_benchmark INFO: eta: 8:55:31  iter: 23200  loss: 0.6714 (0.7799)  auxiliary_ctx: 0.1292 (0.1543)  auxiliary_frq: 0.1946 (0.2034)  auxiliary_vis: 0.1396 (0.1715)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2127 (0.2506)  time: 1.0022 (1.1989)  data: 0.0115 (0.2222)  lr: 0.012000  max mem: 6440
2020-03-09 22:49:09,747 maskrcnn_benchmark INFO: eta: 8:50:45  iter: 23400  loss: 0.7074 (0.7795)  auxiliary_ctx: 0.1370 (0.1542)  auxiliary_frq: 0.2029 (0.2034)  auxiliary_vis: 0.1467 (0.1714)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2287 (0.2505)  time: 0.9873 (1.1972)  data: 0.0117 (0.2204)  lr: 0.012000  max mem: 6440
2020-03-09 22:52:28,553 maskrcnn_benchmark INFO: eta: 8:46:00  iter: 23600  loss: 0.6659 (0.7789)  auxiliary_ctx: 0.1327 (0.1541)  auxiliary_frq: 0.1913 (0.2034)  auxiliary_vis: 0.1476 (0.1712)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1941 (0.2502)  time: 0.9970 (1.1955)  data: 0.0114 (0.2186)  lr: 0.012000  max mem: 6440
2020-03-09 22:55:47,502 maskrcnn_benchmark INFO: eta: 8:41:16  iter: 23800  loss: 0.6218 (0.7784)  auxiliary_ctx: 0.1194 (0.1540)  auxiliary_frq: 0.1830 (0.2033)  auxiliary_vis: 0.1305 (0.1711)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1887 (0.2500)  time: 1.0028 (1.1938)  data: 0.0115 (0.2168)  lr: 0.012000  max mem: 6440
2020-03-09 22:59:06,515 maskrcnn_benchmark INFO: ---Total norm 0.55758 clip coef 8.96724-----------------
2020-03-09 22:59:06,524 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.30874, (torch.Size([4096, 12544]))
2020-03-09 22:59:06,524 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.21265, (torch.Size([4096, 12544]))
2020-03-09 22:59:06,524 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.15516, (torch.Size([256, 1024, 3, 3]))
2020-03-09 22:59:06,524 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.15175, (torch.Size([4096, 4096]))
2020-03-09 22:59:06,524 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.14766, (torch.Size([4096, 4096]))
2020-03-09 22:59:06,524 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.13490, (torch.Size([51, 4096]))
2020-03-09 22:59:06,524 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.13267, (torch.Size([51, 4096]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.11259, (torch.Size([4096, 1024]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.10236, (torch.Size([2048, 4808]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.09672, (torch.Size([4096, 512]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.08977, (torch.Size([2048, 4808]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.07702, (torch.Size([512, 32]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.07166, (torch.Size([256, 128, 3, 3]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.06624, (torch.Size([512, 1024]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.05132, (torch.Size([128, 2, 7, 7]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.03616, (torch.Size([1024, 512]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.03091, (torch.Size([512]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.02285, (torch.Size([51]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.02155, (torch.Size([512]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.02121, (torch.Size([4096]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.02064, (torch.Size([51]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.02033, (torch.Size([256]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01940, (torch.Size([151, 200]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01607, (torch.Size([128]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01567, (torch.Size([2048, 512]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01369, (torch.Size([22801, 51]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01337, (torch.Size([2048, 512]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01308, (torch.Size([1024]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.01269, (torch.Size([256]))
2020-03-09 22:59:06,525 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01235, (torch.Size([4096]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.01208, (torch.Size([4096]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01045, (torch.Size([2048]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01045, (torch.Size([2048]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00992, (torch.Size([2048]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00992, (torch.Size([2048]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00798, (torch.Size([128]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00531, (torch.Size([256]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00522, (torch.Size([128]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00463, (torch.Size([4096]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00381, (torch.Size([4096]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00220, (torch.Size([512, 1024]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00176, (torch.Size([512]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00147, (torch.Size([256]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00137, (torch.Size([2048, 4424]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00132, (torch.Size([2048, 4424]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00128, (torch.Size([4096]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00014, (torch.Size([2048]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00014, (torch.Size([2048]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00013, (torch.Size([2048]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00013, (torch.Size([2048]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00011, (torch.Size([2048, 512]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00010, (torch.Size([2048, 512]))
2020-03-09 22:59:06,526 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00001, (torch.Size([128]))
2020-03-09 22:59:06,527 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00001, (torch.Size([151, 200]))
2020-03-09 22:59:06,527 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00001, (torch.Size([128, 32]))
2020-03-09 22:59:06,527 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00001, (torch.Size([32, 9]))
2020-03-09 22:59:06,527 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-03-09 22:59:06,527 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-03-09 22:59:06,527 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-09 22:59:06,527 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00000, (torch.Size([152, 200]))
2020-03-09 22:59:06,527 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.00000, (torch.Size([3072, 5136]))
2020-03-09 22:59:06,527 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.00000, (torch.Size([3072]))
2020-03-09 22:59:06,527 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.00000, (torch.Size([2560, 512]))
2020-03-09 22:59:06,527 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.00000, (torch.Size([2560]))
2020-03-09 22:59:06,527 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.00000, (torch.Size([151, 512]))
2020-03-09 22:59:06,527 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.00000, (torch.Size([151]))
2020-03-09 22:59:06,527 maskrcnn_benchmark INFO: -------------------------------
2020-03-09 22:59:06,530 maskrcnn_benchmark INFO: eta: 8:36:35  iter: 24000  loss: 0.7915 (0.7780)  auxiliary_ctx: 0.1576 (0.1539)  auxiliary_frq: 0.2129 (0.2033)  auxiliary_vis: 0.1689 (0.1709)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2547 (0.2499)  time: 0.9914 (1.1921)  data: 0.0114 (0.2151)  lr: 0.012000  max mem: 6440
2020-03-09 22:59:06,531 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_predcls/model_0024000.pth
2020-03-09 22:59:08,110 maskrcnn_benchmark INFO: Start validating
2020-03-09 22:59:08,136 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 23:05:02,774 maskrcnn_benchmark INFO: Total run time: 0:05:54.637360 (0.14185494384765626 s / img per device, on 2 devices)
2020-03-09 23:05:02,774 maskrcnn_benchmark INFO: Model inference time: 0:05:29.616183 (0.13184647321701048 s / img per device, on 2 devices)
2020-03-09 23:06:31,623 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6136;   R @ 50: 0.6676;   R @ 100: 0.6830;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.7089; ngR @ 50: 0.8351; ngR @ 100: 0.9007;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0859;  zR @ 50: 0.1630;  zR @ 100: 0.1852;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1245;  mR @ 50: 0.1544;  mR @ 100: 0.1651;  for mode=predcls, type=Mean Recall.
(above:0.1431) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1833) (attached to:0.0000) (behind:0.4570) (belonging to:0.0000) (between:0.0000) (carrying:0.4232) (covered in:0.0714) (covering:0.0000) (eating:0.5714) (flying in:0.0000) (for:0.0370) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8277) (holding:0.5930) (in:0.3564) (in front of:0.0426) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5649) (of:0.4137) (on:0.9225) (on back of:0.0000) (over:0.1057) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.3824) (says:0.0000) (sitting on:0.2605) (standing on:0.0109) (to:0.0000) (under:0.2568) (using:0.1538) (walking in:0.0000) (walking on:0.0438) (watching:0.3824) (wearing:0.9781) (wears:0.0000) (with:0.0710) 
SGG eval:   A @ 20: 0.7050;   A @ 50: 0.7104;   A @ 100: 0.7104;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 23:06:32,188 maskrcnn_benchmark INFO: Validation Result: 0.6830
2020-03-09 23:09:48,886 maskrcnn_benchmark INFO: eta: 8:39:47  iter: 24200  loss: 0.6790 (0.7774)  auxiliary_ctx: 0.1330 (0.1537)  auxiliary_frq: 0.1953 (0.2033)  auxiliary_vis: 0.1411 (0.1708)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1975 (0.2496)  time: 0.9825 (1.2088)  data: 0.0121 (0.2319)  lr: 0.012000  max mem: 6440
2020-03-09 23:13:06,926 maskrcnn_benchmark INFO: eta: 8:34:59  iter: 24400  loss: 0.6001 (0.7768)  auxiliary_ctx: 0.1179 (0.1536)  auxiliary_frq: 0.1883 (0.2033)  auxiliary_vis: 0.1318 (0.1706)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1714 (0.2493)  time: 0.9923 (1.2070)  data: 0.0116 (0.2301)  lr: 0.012000  max mem: 6440
2020-03-09 23:16:25,177 maskrcnn_benchmark INFO: eta: 8:30:13  iter: 24600  loss: 0.6517 (0.7762)  auxiliary_ctx: 0.1237 (0.1534)  auxiliary_frq: 0.1937 (0.2032)  auxiliary_vis: 0.1395 (0.1704)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2030 (0.2491)  time: 1.0028 (1.2053)  data: 0.0119 (0.2283)  lr: 0.012000  max mem: 6440
2020-03-09 23:19:43,455 maskrcnn_benchmark INFO: eta: 8:25:29  iter: 24800  loss: 0.6550 (0.7755)  auxiliary_ctx: 0.1274 (0.1533)  auxiliary_frq: 0.1912 (0.2032)  auxiliary_vis: 0.1352 (0.1702)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1972 (0.2488)  time: 0.9923 (1.2035)  data: 0.0115 (0.2265)  lr: 0.012000  max mem: 6440
2020-03-09 23:23:01,941 maskrcnn_benchmark INFO: eta: 8:20:46  iter: 25000  loss: 0.6573 (0.7749)  auxiliary_ctx: 0.1273 (0.1531)  auxiliary_frq: 0.1934 (0.2032)  auxiliary_vis: 0.1451 (0.1700)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2022 (0.2485)  time: 0.9863 (1.2019)  data: 0.0114 (0.2248)  lr: 0.012000  max mem: 6440
2020-03-09 23:26:19,863 maskrcnn_benchmark INFO: eta: 8:16:04  iter: 25200  loss: 0.6397 (0.7743)  auxiliary_ctx: 0.1247 (0.1530)  auxiliary_frq: 0.1873 (0.2031)  auxiliary_vis: 0.1367 (0.1699)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1966 (0.2483)  time: 0.9784 (1.2002)  data: 0.0112 (0.2231)  lr: 0.012000  max mem: 6440
2020-03-09 23:29:37,836 maskrcnn_benchmark INFO: eta: 8:11:23  iter: 25400  loss: 0.7268 (0.7738)  auxiliary_ctx: 0.1405 (0.1529)  auxiliary_frq: 0.1999 (0.2031)  auxiliary_vis: 0.1564 (0.1697)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2257 (0.2481)  time: 0.9834 (1.1985)  data: 0.0114 (0.2214)  lr: 0.012000  max mem: 6440
2020-03-09 23:32:55,386 maskrcnn_benchmark INFO: eta: 8:06:43  iter: 25600  loss: 0.6581 (0.7734)  auxiliary_ctx: 0.1298 (0.1528)  auxiliary_frq: 0.1931 (0.2031)  auxiliary_vis: 0.1418 (0.1696)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1934 (0.2479)  time: 0.9876 (1.1969)  data: 0.0098 (0.2198)  lr: 0.012000  max mem: 6440
2020-03-09 23:36:13,649 maskrcnn_benchmark INFO: eta: 8:02:05  iter: 25800  loss: 0.6422 (0.7729)  auxiliary_ctx: 0.1210 (0.1527)  auxiliary_frq: 0.1885 (0.2031)  auxiliary_vis: 0.1346 (0.1694)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2067 (0.2477)  time: 0.9907 (1.1953)  data: 0.0113 (0.2182)  lr: 0.012000  max mem: 6440
2020-03-09 23:39:31,344 maskrcnn_benchmark INFO: eta: 7:57:28  iter: 26000  loss: 0.7228 (0.7725)  auxiliary_ctx: 0.1407 (0.1526)  auxiliary_frq: 0.2090 (0.2030)  auxiliary_vis: 0.1521 (0.1693)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2092 (0.2476)  time: 0.9782 (1.1937)  data: 0.0116 (0.2166)  lr: 0.012000  max mem: 6440
2020-03-09 23:39:31,347 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_predcls/model_0026000.pth
2020-03-09 23:39:32,953 maskrcnn_benchmark INFO: Start validating
2020-03-09 23:39:32,979 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-09 23:45:29,863 maskrcnn_benchmark INFO: Total run time: 0:05:56.883621 (0.14275344858169556 s / img per device, on 2 devices)
2020-03-09 23:45:29,863 maskrcnn_benchmark INFO: Model inference time: 0:05:31.595897 (0.13263835897445678 s / img per device, on 2 devices)
2020-03-09 23:46:58,187 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6164;   R @ 50: 0.6691;   R @ 100: 0.6839;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.7115; ngR @ 50: 0.8356; ngR @ 100: 0.9001;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0844;  zR @ 50: 0.1504;  zR @ 100: 0.1652;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1259;  mR @ 50: 0.1573;  mR @ 100: 0.1692;  for mode=predcls, type=Mean Recall.
(above:0.1436) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1557) (attached to:0.0000) (behind:0.4838) (belonging to:0.0000) (between:0.0000) (carrying:0.4759) (covered in:0.1429) (covering:0.0000) (eating:0.4286) (flying in:0.0000) (for:0.0741) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8301) (holding:0.6002) (in:0.3793) (in front of:0.0575) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5334) (of:0.4319) (on:0.9155) (on back of:0.0000) (over:0.0610) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.4420) (says:0.0000) (sitting on:0.2771) (standing on:0.0130) (to:0.0000) (under:0.2151) (using:0.1923) (walking in:0.0000) (walking on:0.1830) (watching:0.3922) (wearing:0.9764) (wears:0.0000) (with:0.0548) 
SGG eval:   A @ 20: 0.7045;   A @ 50: 0.7095;   A @ 100: 0.7095;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-03-09 23:46:58,752 maskrcnn_benchmark INFO: Validation Result: 0.6839
2020-03-09 23:46:58,752 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-03-09 23:50:16,255 maskrcnn_benchmark INFO: eta: 7:59:38  iter: 26200  loss: 0.6429 (0.7720)  auxiliary_ctx: 0.1260 (0.1524)  auxiliary_frq: 0.1908 (0.2030)  auxiliary_vis: 0.1352 (0.1692)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1939 (0.2473)  time: 0.9931 (1.2092)  data: 0.0116 (0.2321)  lr: 0.001200  max mem: 6440
2020-03-09 23:53:34,412 maskrcnn_benchmark INFO: eta: 7:54:57  iter: 26400  loss: 0.6787 (0.7715)  auxiliary_ctx: 0.1297 (0.1523)  auxiliary_frq: 0.1954 (0.2030)  auxiliary_vis: 0.1430 (0.1690)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2029 (0.2472)  time: 0.9822 (1.2075)  data: 0.0114 (0.2304)  lr: 0.001200  max mem: 6440
2020-03-09 23:56:51,193 maskrcnn_benchmark INFO: eta: 7:50:16  iter: 26600  loss: 0.6633 (0.7711)  auxiliary_ctx: 0.1258 (0.1522)  auxiliary_frq: 0.1942 (0.2030)  auxiliary_vis: 0.1434 (0.1689)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2055 (0.2469)  time: 0.9719 (1.2058)  data: 0.0116 (0.2288)  lr: 0.001200  max mem: 6440
2020-03-10 00:00:09,191 maskrcnn_benchmark INFO: eta: 7:45:38  iter: 26800  loss: 0.6796 (0.7705)  auxiliary_ctx: 0.1290 (0.1521)  auxiliary_frq: 0.2024 (0.2030)  auxiliary_vis: 0.1454 (0.1687)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2043 (0.2467)  time: 0.9947 (1.2042)  data: 0.0115 (0.2272)  lr: 0.001200  max mem: 6440
2020-03-10 00:03:27,155 maskrcnn_benchmark INFO: eta: 7:41:00  iter: 27000  loss: 0.6912 (0.7700)  auxiliary_ctx: 0.1296 (0.1520)  auxiliary_frq: 0.1980 (0.2029)  auxiliary_vis: 0.1451 (0.1686)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2144 (0.2465)  time: 0.9751 (1.2027)  data: 0.0113 (0.2256)  lr: 0.001200  max mem: 6440
2020-03-10 00:06:45,626 maskrcnn_benchmark INFO: eta: 7:36:25  iter: 27200  loss: 0.6294 (0.7695)  auxiliary_ctx: 0.1235 (0.1518)  auxiliary_frq: 0.1899 (0.2029)  auxiliary_vis: 0.1272 (0.1684)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1886 (0.2463)  time: 0.9830 (1.2011)  data: 0.0113 (0.2240)  lr: 0.001200  max mem: 6440
2020-03-10 00:10:03,511 maskrcnn_benchmark INFO: eta: 7:31:50  iter: 27400  loss: 0.6857 (0.7690)  auxiliary_ctx: 0.1380 (0.1517)  auxiliary_frq: 0.1893 (0.2029)  auxiliary_vis: 0.1355 (0.1683)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2017 (0.2461)  time: 0.9926 (1.1996)  data: 0.0108 (0.2224)  lr: 0.001200  max mem: 6440
2020-03-10 00:13:21,423 maskrcnn_benchmark INFO: eta: 7:27:16  iter: 27600  loss: 0.7022 (0.7686)  auxiliary_ctx: 0.1345 (0.1516)  auxiliary_frq: 0.1991 (0.2029)  auxiliary_vis: 0.1476 (0.1682)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2198 (0.2459)  time: 0.9770 (1.1980)  data: 0.0102 (0.2209)  lr: 0.001200  max mem: 6440
2020-03-10 00:16:40,028 maskrcnn_benchmark INFO: eta: 7:22:43  iter: 27800  loss: 0.7381 (0.7681)  auxiliary_ctx: 0.1485 (0.1515)  auxiliary_frq: 0.2085 (0.2028)  auxiliary_vis: 0.1567 (0.1681)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2184 (0.2457)  time: 0.9813 (1.1966)  data: 0.0110 (0.2194)  lr: 0.001200  max mem: 6440
2020-03-10 00:19:57,755 maskrcnn_benchmark INFO: ---Total norm 0.93278 clip coef 5.36034-----------------
2020-03-10 00:19:57,764 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.59438, (torch.Size([4096, 12544]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.35700, (torch.Size([4096, 12544]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.31413, (torch.Size([256, 1024, 3, 3]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.26199, (torch.Size([4096, 4096]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.23272, (torch.Size([4096, 4096]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.16801, (torch.Size([51, 4096]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.15728, (torch.Size([51, 4096]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.15459, (torch.Size([2048, 4808]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.14878, (torch.Size([4096, 1024]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.14067, (torch.Size([2048, 4808]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.10503, (torch.Size([256, 128, 3, 3]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.09172, (torch.Size([4096, 512]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.08975, (torch.Size([128, 2, 7, 7]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.08453, (torch.Size([512, 1024]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.07222, (torch.Size([512, 32]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.04215, (torch.Size([1024, 512]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.03112, (torch.Size([512]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.02808, (torch.Size([128]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.02741, (torch.Size([151, 200]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.02489, (torch.Size([51]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.02124, (torch.Size([256]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.02093, (torch.Size([51]))
2020-03-10 00:19:57,765 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.02086, (torch.Size([2048, 512]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01969, (torch.Size([2048, 512]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.01726, (torch.Size([512]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.01667, (torch.Size([4096]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.01608, (torch.Size([4096]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01537, (torch.Size([22801, 51]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01464, (torch.Size([4096]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01263, (torch.Size([1024]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.01239, (torch.Size([256]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01184, (torch.Size([2048]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01184, (torch.Size([2048]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.01149, (torch.Size([128]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01106, (torch.Size([2048]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01106, (torch.Size([2048]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.01064, (torch.Size([128]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00941, (torch.Size([256]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00706, (torch.Size([4096]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00676, (torch.Size([4096]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00339, (torch.Size([512, 1024]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00327, (torch.Size([256]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00265, (torch.Size([512]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00249, (torch.Size([2048, 4424]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00219, (torch.Size([4096]))
2020-03-10 00:19:57,766 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00207, (torch.Size([2048, 4424]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00029, (torch.Size([2048]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00029, (torch.Size([2048]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00026, (torch.Size([2048, 512]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00023, (torch.Size([2048]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00023, (torch.Size([2048]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00014, (torch.Size([2048, 512]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00003, (torch.Size([128]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00002, (torch.Size([151, 200]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00001, (torch.Size([128, 32]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00001, (torch.Size([32, 9]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00000, (torch.Size([32]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00000, (torch.Size([32]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00000, (torch.Size([152, 200]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.00000, (torch.Size([3072, 5136]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.00000, (torch.Size([3072]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.00000, (torch.Size([2560, 512]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.00000, (torch.Size([2560]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.00000, (torch.Size([151, 512]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.00000, (torch.Size([151]))
2020-03-10 00:19:57,767 maskrcnn_benchmark INFO: -------------------------------
2020-03-10 00:19:57,770 maskrcnn_benchmark INFO: eta: 7:18:11  iter: 28000  loss: 0.5909 (0.7677)  auxiliary_ctx: 0.1128 (0.1514)  auxiliary_frq: 0.1835 (0.2028)  auxiliary_vis: 0.1323 (0.1679)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1649 (0.2455)  time: 0.9919 (1.1951)  data: 0.0115 (0.2179)  lr: 0.001200  max mem: 6440
2020-03-10 00:19:57,772 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_predcls/model_0028000.pth
2020-03-10 00:19:59,350 maskrcnn_benchmark INFO: Start validating
2020-03-10 00:19:59,374 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-10 00:25:55,227 maskrcnn_benchmark INFO: Total run time: 0:05:55.852393 (0.14234095726013182 s / img per device, on 2 devices)
2020-03-10 00:25:55,227 maskrcnn_benchmark INFO: Model inference time: 0:05:30.151852 (0.1320607406616211 s / img per device, on 2 devices)
2020-03-10 00:27:23,714 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6148;   R @ 50: 0.6686;   R @ 100: 0.6842;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.7115; ngR @ 50: 0.8359; ngR @ 100: 0.9009;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0733;  zR @ 50: 0.1630;  zR @ 100: 0.1852;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1206;  mR @ 50: 0.1529;  mR @ 100: 0.1654;  for mode=predcls, type=Mean Recall.
(above:0.1393) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1662) (attached to:0.0000) (behind:0.4928) (belonging to:0.0000) (between:0.0000) (carrying:0.4057) (covered in:0.1429) (covering:0.0000) (eating:0.4286) (flying in:0.0000) (for:0.0741) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8250) (holding:0.6047) (in:0.3699) (in front of:0.0818) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5372) (of:0.4169) (on:0.9211) (on back of:0.0000) (over:0.0813) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.3438) (says:0.0000) (sitting on:0.2657) (standing on:0.0130) (to:0.0000) (under:0.2321) (using:0.1923) (walking in:0.0000) (walking on:0.0960) (watching:0.3824) (wearing:0.9768) (wears:0.0000) (with:0.0796) 
SGG eval:   A @ 20: 0.7048;   A @ 50: 0.7101;   A @ 100: 0.7101;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-03-10 00:27:24,301 maskrcnn_benchmark INFO: Validation Result: 0.6842
2020-03-10 00:30:41,916 maskrcnn_benchmark INFO: eta: 7:19:25  iter: 28200  loss: 0.7563 (0.7672)  auxiliary_ctx: 0.1500 (0.1513)  auxiliary_frq: 0.2151 (0.2028)  auxiliary_vis: 0.1595 (0.1678)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2305 (0.2453)  time: 0.9751 (1.2094)  data: 0.0105 (0.2323)  lr: 0.001200  max mem: 6440
2020-03-10 00:34:00,045 maskrcnn_benchmark INFO: eta: 7:14:50  iter: 28400  loss: 0.6741 (0.7669)  auxiliary_ctx: 0.1318 (0.1512)  auxiliary_frq: 0.1972 (0.2028)  auxiliary_vis: 0.1452 (0.1677)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2046 (0.2452)  time: 0.9850 (1.2079)  data: 0.0097 (0.2307)  lr: 0.001200  max mem: 6440
2020-03-10 00:37:17,474 maskrcnn_benchmark INFO: eta: 7:10:16  iter: 28600  loss: 0.6509 (0.7664)  auxiliary_ctx: 0.1278 (0.1511)  auxiliary_frq: 0.1954 (0.2028)  auxiliary_vis: 0.1438 (0.1676)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1911 (0.2450)  time: 0.9744 (1.2064)  data: 0.0112 (0.2292)  lr: 0.001200  max mem: 6440
2020-03-10 00:40:35,946 maskrcnn_benchmark INFO: eta: 7:05:43  iter: 28800  loss: 0.6386 (0.7659)  auxiliary_ctx: 0.1339 (0.1510)  auxiliary_frq: 0.1927 (0.2028)  auxiliary_vis: 0.1435 (0.1674)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1890 (0.2448)  time: 0.9939 (1.2049)  data: 0.0105 (0.2277)  lr: 0.001200  max mem: 6440
2020-03-10 00:43:54,294 maskrcnn_benchmark INFO: eta: 7:01:11  iter: 29000  loss: 0.6999 (0.7654)  auxiliary_ctx: 0.1312 (0.1509)  auxiliary_frq: 0.1943 (0.2027)  auxiliary_vis: 0.1385 (0.1673)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2058 (0.2445)  time: 0.9808 (1.2034)  data: 0.0116 (0.2262)  lr: 0.001200  max mem: 6440
2020-03-10 00:47:11,710 maskrcnn_benchmark INFO: eta: 6:56:39  iter: 29200  loss: 0.6192 (0.7650)  auxiliary_ctx: 0.1221 (0.1508)  auxiliary_frq: 0.1873 (0.2027)  auxiliary_vis: 0.1333 (0.1671)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1848 (0.2443)  time: 0.9941 (1.2019)  data: 0.0114 (0.2247)  lr: 0.001200  max mem: 6440
2020-03-10 00:50:29,110 maskrcnn_benchmark INFO: eta: 6:52:09  iter: 29400  loss: 0.6501 (0.7644)  auxiliary_ctx: 0.1367 (0.1506)  auxiliary_frq: 0.1902 (0.2027)  auxiliary_vis: 0.1479 (0.1670)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1911 (0.2441)  time: 0.9866 (1.2005)  data: 0.0114 (0.2232)  lr: 0.001200  max mem: 6440
2020-03-10 00:53:47,522 maskrcnn_benchmark INFO: eta: 6:47:40  iter: 29600  loss: 0.6511 (0.7639)  auxiliary_ctx: 0.1248 (0.1505)  auxiliary_frq: 0.1944 (0.2027)  auxiliary_vis: 0.1370 (0.1668)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1822 (0.2439)  time: 0.9898 (1.1991)  data: 0.0115 (0.2218)  lr: 0.001200  max mem: 6440
2020-03-10 00:57:05,628 maskrcnn_benchmark INFO: eta: 6:43:12  iter: 29800  loss: 0.6402 (0.7635)  auxiliary_ctx: 0.1293 (0.1504)  auxiliary_frq: 0.1973 (0.2027)  auxiliary_vis: 0.1368 (0.1667)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.2074 (0.2437)  time: 0.9906 (1.1977)  data: 0.0116 (0.2204)  lr: 0.001200  max mem: 6440
2020-03-10 01:00:24,234 maskrcnn_benchmark INFO: eta: 6:38:45  iter: 30000  loss: 0.6043 (0.7630)  auxiliary_ctx: 0.1149 (0.1503)  auxiliary_frq: 0.1908 (0.2026)  auxiliary_vis: 0.1308 (0.1666)  loss_refine_obj: 0.0000 (0.0000)  loss_rel: 0.1860 (0.2435)  time: 0.9976 (1.1963)  data: 0.0116 (0.2190)  lr: 0.001200  max mem: 6440
2020-03-10 01:00:24,236 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_predcls/model_0030000.pth
2020-03-10 01:00:25,796 maskrcnn_benchmark INFO: Start validating
2020-03-10 01:00:25,819 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-10 01:06:21,518 maskrcnn_benchmark INFO: Total run time: 0:05:55.699015 (0.14227960586547853 s / img per device, on 2 devices)
2020-03-10 01:06:21,519 maskrcnn_benchmark INFO: Model inference time: 0:05:30.753793 (0.1323015172958374 s / img per device, on 2 devices)
2020-03-10 01:07:50,305 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9999
====================================================================================================
SGG eval:   R @ 20: 0.6152;   R @ 50: 0.6687;   R @ 100: 0.6847;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.7112; ngR @ 50: 0.8370; ngR @ 100: 0.9012;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0793;  zR @ 50: 0.1585;  zR @ 100: 0.1852;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1216;  mR @ 50: 0.1534;  mR @ 100: 0.1659;  for mode=predcls, type=Mean Recall.
(above:0.1436) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1909) (attached to:0.0000) (behind:0.4838) (belonging to:0.0000) (between:0.0000) (carrying:0.4320) (covered in:0.1429) (covering:0.0000) (eating:0.4286) (flying in:0.0000) (for:0.0741) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.8242) (holding:0.5980) (in:0.3744) (in front of:0.0735) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.5493) (of:0.4222) (on:0.9200) (on back of:0.0000) (over:0.0935) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.3497) (says:0.0000) (sitting on:0.2709) (standing on:0.0130) (to:0.0000) (under:0.2474) (using:0.1923) (walking in:0.0000) (walking on:0.0744) (watching:0.3431) (wearing:0.9768) (wears:0.0000) (with:0.0750) 
SGG eval:   A @ 20: 0.7057;   A @ 50: 0.7108;   A @ 100: 0.7108;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

2020-03-10 01:07:50,909 maskrcnn_benchmark INFO: Validation Result: 0.6847
2020-03-10 01:07:50,909 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-03-10 01:07:50,909 maskrcnn_benchmark INFO: Trigger MAX_DECAY_STEP at iteration 30000.
2020-03-10 01:07:51,002 maskrcnn_benchmark INFO: Total training time: 10:05:35.422045 (0.7267 s / it)
2020-03-10 01:07:52,458 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(26446 images).
2020-03-10 01:39:39,929 maskrcnn_benchmark INFO: Total run time: 0:31:47.470518 (0.14425399063088426 s / img per device, on 2 devices)
2020-03-10 01:39:39,929 maskrcnn_benchmark INFO: Model inference time: 0:29:34.368147 (0.1341880168747471 s / img per device, on 2 devices)
2020-03-10 01:47:50,850 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.9995
====================================================================================================
SGG eval:   R @ 20: 0.5964;   R @ 50: 0.6611;   R @ 100: 0.6796;  for mode=predcls, type=Recall(Main).
SGG eval: ngR @ 20: 0.6798; ngR @ 50: 0.8249; ngR @ 100: 0.8968;  for mode=predcls, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0579;  zR @ 50: 0.1102;  zR @ 100: 0.1474;  for mode=predcls, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.1146;  mR @ 50: 0.1460;  mR @ 100: 0.1584;  for mode=predcls, type=Mean Recall.
(above:0.1386) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0059) (at:0.2865) (attached to:0.0000) (behind:0.6247) (belonging to:0.0000) (between:0.0000) (carrying:0.1460) (covered in:0.1940) (covering:0.0000) (eating:0.1784) (flying in:0.0000) (for:0.0276) (from:0.0000) (growing on:0.0000) (hanging from:0.0120) (has:0.8242) (holding:0.7351) (in:0.3863) (in front of:0.0739) (laying on:0.0045) (looking at:0.0745) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.4634) (of:0.6271) (on:0.8294) (on back of:0.0000) (over:0.0806) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.3027) (says:0.0000) (sitting on:0.2503) (standing on:0.0019) (to:0.0000) (under:0.3328) (using:0.0356) (walking in:0.0000) (walking on:0.0365) (watching:0.2158) (wearing:0.9657) (wears:0.0000) (with:0.0683) 
SGG eval:   A @ 20: 0.6959;   A @ 50: 0.6987;   A @ 100: 0.6987;  for mode=predcls, type=TopK Accuracy.
====================================================================================================

