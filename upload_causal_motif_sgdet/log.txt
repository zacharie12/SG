2020-03-10 18:36:40,759 maskrcnn_benchmark INFO: Using 2 GPUs
2020-03-10 18:36:40,759 maskrcnn_benchmark INFO: Namespace(config_file='configs/e2e_relation_X_101_32_8_FPN_1x.yaml', distributed=True, local_rank=0, opts=['MODEL.ROI_RELATION_HEAD.USE_GT_BOX', 'False', 'MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL', 'False', 'MODEL.ROI_RELATION_HEAD.PREDICTOR', 'CausalAnalysisPredictor', 'MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE', 'none', 'MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE', 'sum', 'MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER', 'motifs', 'SOLVER.IMS_PER_BATCH', '12', 'TEST.IMS_PER_BATCH', '2', 'DTYPE', 'float16', 'SOLVER.MAX_ITER', '50000', 'SOLVER.VAL_PERIOD', '2000', 'SOLVER.CHECKPOINT_PERIOD', '2000', 'GLOVE_DIR', '/home/kaihua/glove', 'MODEL.PRETRAINED_DETECTOR_CKPT', '/home/kaihua/checkpoints/pretrained_faster_rcnn/model_final.pth', 'OUTPUT_DIR', '/home/kaihua/checkpoints/upload_causal_motif_sgdet'], skip_test=False)
2020-03-10 18:36:40,759 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-03-10 18:36:42,295 maskrcnn_benchmark INFO: 
PyTorch version: 1.4.0
Is debug build: No
CUDA used to build PyTorch: 10.0

OS: Ubuntu 16.04.5 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: Could not collect

Python version: 3.8
Is CUDA available: Yes
CUDA runtime version: 10.0.130
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti

Nvidia driver version: 415.27
cuDNN version: Could not collect

Versions of relevant libraries:
[pip] numpy==1.18.1
[pip] torch==1.4.0
[pip] torchvision==0.5.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2019.4                      243  
[conda] mkl-service               2.3.0            py38he904b0f_0  
[conda] mkl_fft                   1.0.15           py38ha843d7b_0  
[conda] mkl_random                1.1.0            py38h962f231_0  
[conda] pytorch                   1.4.0           py3.8_cuda10.0.130_cudnn7.6.3_0    pytorch
[conda] torchvision               0.5.0                py38_cu100    pytorch
        Pillow (7.0.0)
2020-03-10 18:36:42,296 maskrcnn_benchmark INFO: Loaded configuration file configs/e2e_relation_X_101_32_8_FPN_1x.yaml
2020-03-10 18:36:42,296 maskrcnn_benchmark INFO: 
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN" # VGG-16
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 151                # 151 for VG, 1201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: True
    USE_GT_OBJECT_LABEL: True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 51                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048 
DATASETS:
  TRAIN: ("VG_stanford_filtered_with_attribute_train",)
  VAL: ("VG_stanford_filtered_with_attribute_val",)
  TEST: ("VG_stanford_filtered_with_attribute_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.1
  WEIGHT_DECAY: 0.0001
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (10000, 16000)
  MAX_ITER: 40000
  VAL_PERIOD: 2000
  CHECKPOINT_PERIOD: 2000
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: "WarmupReduceLROnPlateau"    # WarmupMultiStepLR, WarmupReduceLROnPlateau
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5

2020-03-10 18:36:42,297 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VG_stanford_filtered_with_attribute_test',)
  TRAIN: ('VG_stanford_filtered_with_attribute_train',)
  VAL: ('VG_stanford_filtered_with_attribute_val',)
DTYPE: float16
GLOVE_DIR: /home/kaihua/glove
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: /home/kaihua/checkpoints/pretrained_faster_rcnn/model_final.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 151
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 80
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: none
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 51
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: False
    USE_GT_OBJECT_LABEL: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: /home/kaihua/checkpoints/upload_causal_motif_sgdet
PATHS_CATALOG: /data1/kaihua/projects/sgg-test/scene-graph-benchmark/maskrcnn_benchmark/config/paths_catalog.py
PATHS_DATA: /data1/kaihua/projects/sgg-test/scene-graph-benchmark/maskrcnn_benchmark/config/../data/datasets
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 2000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 12
  MAX_ITER: 50000
  MOMENTUM: 0.9
  PRE_VAL: True
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False
2020-03-10 18:36:42,298 maskrcnn_benchmark INFO: Saving config into: /home/kaihua/checkpoints/upload_causal_motif_sgdet/config.yml
2020-03-10 18:36:42,326 maskrcnn_benchmark INFO: #################### prepare training ####################
2020-03-10 18:36:44,965 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-03-10 18:36:44,965 maskrcnn_benchmark.data.build INFO: get dataset statistics...
2020-03-10 18:37:09,974 maskrcnn_benchmark.data.build INFO: finish
2020-03-10 18:37:09,974 maskrcnn_benchmark.data.build INFO: Save data statistics to: /home/kaihua/checkpoints/upload_causal_motif_sgdet/VG_stanford_filtered_with_attribute_train_statistics.cache
2020-03-10 18:37:09,974 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------
2020-03-10 18:37:10,806 maskrcnn_benchmark INFO: #################### end model construction ####################
2020-03-10 18:37:11,170 maskrcnn_benchmark INFO: #################### end optimizer and shcedule ####################
2020-03-10 18:37:11,192 maskrcnn_benchmark INFO: #################### end distributed ####################
2020-03-10 18:37:11,193 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /home/kaihua/checkpoints/pretrained_faster_rcnn/model_final.pth
2020-03-10 18:37:11,606 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.
2020-03-10 18:37:11,606 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.
2020-03-10 18:37:11,606 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.
2020-03-10 18:37:11,606 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.box_feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.
2020-03-10 18:37:11,606 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias in current model to module.roi_heads.box.feature_extractor.fc6.bias in loaded model.
2020-03-10 18:37:11,606 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight in current model to module.roi_heads.box.feature_extractor.fc6.weight in loaded model.
2020-03-10 18:37:11,606 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias in current model to module.roi_heads.box.feature_extractor.fc7.bias in loaded model.
2020-03-10 18:37:11,606 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight in current model to module.roi_heads.box.feature_extractor.fc7.weight in loaded model.
2020-03-10 18:37:11,606 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.bias in loaded model.
2020-03-10 18:37:11,606 maskrcnn_benchmark.utils.model_serialization INFO: MAPPING module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight in current model to module.roi_heads.box.feature_extractor.pooler.reduce_channel.0.weight in loaded model.
2020-03-10 18:37:11,644 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.bias                                           loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2020-03-10 18:37:11,644 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc6.weight                                         loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2020-03-10 18:37:11,644 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.bias                                           loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2020-03-10 18:37:11,644 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.box_feature_extractor.fc7.weight                                         loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.avg_post_ctx of shape (4096,)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias of shape (3072,)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight of shape (3072, 5136)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight of shape (152, 200)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias of shape (151,)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight of shape (151, 512)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias of shape (2560,)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight of shape (2560, 512)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0 of shape (2048,)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0 of shape (2048,)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0 of shape (2048, 4808)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4808)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias of shape (512,)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight of shape (512, 1024)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias of shape (512,)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight of shape (512, 1024)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0 of shape (2048,)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse of shape (2048,)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0 of shape (2048,)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse of shape (2048,)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0 of shape (2048, 512)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse of shape (2048, 512)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0 of shape (2048, 4424)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse of shape (2048, 4424)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight of shape (151, 200)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight of shape (151, 200)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias of shape (32,)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight of shape (32, 9)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias of shape (32,)
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.num_batches_tracked of shape ()
2020-03-10 18:37:11,645 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_mean of shape (32,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.running_var of shape (32,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight of shape (32,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias of shape (128,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight of shape (128, 32)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_dcd_feat of shape (4936,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_edg_feat of shape (4296,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.context_layer.untreated_obj_feat of shape (4424,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.bias of shape (51,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.ctx_compress.weight of shape (51, 4096)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight of shape (22801, 51)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.bias of shape (4096,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_cat.0.weight of shape (4096, 1024)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.bias of shape (1024,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.post_emb.weight of shape (1024, 512)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.bias of shape (512,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.0.weight of shape (512, 32)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.bias of shape (4096,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.spt_emb.2.weight of shape (4096, 512)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_conv_spt of shape (4096,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_feat of shape (4096,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.untreated_spt of shape (32,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.bias of shape (51,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.predictor.vis_compress.weight of shape (51, 4096)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias                       loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (4096,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight                     loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (4096, 12544)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias                       loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (4096,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: REMATCHING! module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight                     loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (4096, 4096)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias of shape (256,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight of shape (256, 1024, 3, 3)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias of shape (128,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight of shape (128, 2, 7, 7)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias of shape (128,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.num_batches_tracked of shape ()
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_mean of shape (128,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.running_var of shape (128,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight of shape (128,)
2020-03-10 18:37:11,646 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias of shape (256,)
2020-03-10 18:37:11,647 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight of shape (256, 128, 3, 3)
2020-03-10 18:37:11,647 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias of shape (256,)
2020-03-10 18:37:11,647 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.num_batches_tracked of shape ()
2020-03-10 18:37:11,647 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_mean of shape (256,)
2020-03-10 18:37:11,647 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.running_var of shape (256,)
2020-03-10 18:37:11,647 maskrcnn_benchmark.utils.model_serialization INFO: NO-MATCHING of current module: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight of shape (256,)
2020-03-10 18:37:12,282 maskrcnn_benchmark INFO: #################### end load checkpointer ####################
2020-03-10 18:37:12,282 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-03-10 18:37:14,327 maskrcnn_benchmark.utils.miscellaneous INFO: Saving labels mapping into /home/kaihua/checkpoints/upload_causal_motif_sgdet/labels.json
2020-03-10 18:37:15,158 maskrcnn_benchmark INFO: #################### end dataloader ####################
2020-03-10 18:37:15,158 maskrcnn_benchmark INFO: Validate before training
2020-03-10 18:37:15,167 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-10 18:57:51,805 maskrcnn_benchmark INFO: Total run time: 0:20:36.638085 (0.4946552339553833 s / img per device, on 2 devices)
2020-03-10 18:57:51,805 maskrcnn_benchmark INFO: Model inference time: 0:19:36.990993 (0.4707963970184326 s / img per device, on 2 devices)
2020-03-10 19:02:06,153 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.0002
====================================================================================================
SGG eval:   R @ 20: 0.0000;   R @ 50: 0.0001;   R @ 100: 0.0001;  for mode=sgdet, type=Recall(Main).
SGG eval: ngR @ 20: 0.0000; ngR @ 50: 0.0001; ngR @ 100: 0.0001;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0000;  for mode=sgdet, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0000;  mR @ 50: 0.0000;  mR @ 100: 0.0000;  for mode=sgdet, type=Mean Recall.
(above:0.0000) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0000) (attached to:0.0000) (behind:0.0000) (belonging to:0.0000) (between:0.0000) (carrying:0.0000) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.0000) (holding:0.0000) (in:0.0000) (in front of:0.0000) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0000) (of:0.0005) (on:0.0000) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.0000) (says:0.0000) (sitting on:0.0000) (standing on:0.0000) (to:0.0000) (under:0.0000) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.0000) (wears:0.0000) (with:0.0000) 
====================================================================================================

2020-03-10 19:02:07,975 maskrcnn_benchmark INFO: Start training
2020-03-10 19:02:10,361 maskrcnn_benchmark INFO: ---Total norm inf clip coef 0.00000-----------------
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: inf, (torch.Size([51, 4096]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 22.94290, (torch.Size([4096, 4096]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 22.83815, (torch.Size([4096, 12544]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 5.20101, (torch.Size([256, 1024, 3, 3]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 3.68879, (torch.Size([3072, 5136]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 2.27910, (torch.Size([256, 128, 3, 3]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 1.22142, (torch.Size([4096, 4096]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 1.12133, (torch.Size([151, 512]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 1.04296, (torch.Size([51, 4096]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.99549, (torch.Size([4096, 512]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.94599, (torch.Size([51]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.93175, (torch.Size([51]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.84323, (torch.Size([151]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.70296, (torch.Size([512, 1024]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.68482, (torch.Size([4096, 1024]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.63057, (torch.Size([128, 2, 7, 7]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.61937, (torch.Size([4096, 12544]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.38569, (torch.Size([2048, 4808]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.35650, (torch.Size([2048, 4808]))
2020-03-10 19:02:10,371 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.29229, (torch.Size([3072]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.28763, (torch.Size([4096]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.28325, (torch.Size([512, 32]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.24023, (torch.Size([512]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.23190, (torch.Size([4096]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.19285, (torch.Size([512, 1024]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.18914, (torch.Size([256]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.15646, (torch.Size([2560, 512]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.13887, (torch.Size([128]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.12194, (torch.Size([2560]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.10901, (torch.Size([4096]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.10272, (torch.Size([256]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.09426, (torch.Size([2048, 4424]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.09410, (torch.Size([2048, 4424]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.08299, (torch.Size([512]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.07500, (torch.Size([2048, 512]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.06788, (torch.Size([2048, 512]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.05917, (torch.Size([512]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.03783, (torch.Size([4096]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.03709, (torch.Size([256]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.03707, (torch.Size([256]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.03701, (torch.Size([2048]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.03701, (torch.Size([2048]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.03695, (torch.Size([128]))
2020-03-10 19:02:10,372 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.03420, (torch.Size([2048]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.03420, (torch.Size([2048]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.03190, (torch.Size([128]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.03131, (torch.Size([4096]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.03099, (torch.Size([1024, 512]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.03026, (torch.Size([128, 32]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.02958, (torch.Size([22801, 51]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.02420, (torch.Size([1024]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.01876, (torch.Size([2048, 512]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.01838, (torch.Size([151, 200]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.01693, (torch.Size([2048, 512]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.01666, (torch.Size([32, 9]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.01235, (torch.Size([128]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00789, (torch.Size([2048]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00789, (torch.Size([2048]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00786, (torch.Size([4096]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00786, (torch.Size([2048]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00786, (torch.Size([2048]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00650, (torch.Size([32]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00522, (torch.Size([152, 200]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00325, (torch.Size([32]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00278, (torch.Size([151, 200]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-10 19:02:10,373 maskrcnn_benchmark INFO: -------------------------------
2020-03-10 19:07:13,003 maskrcnn_benchmark INFO: eta: 21:05:51  iter: 200  loss: 1.6704 (2.5405)  auxiliary_ctx: 0.1934 (0.4641)  auxiliary_frq: 0.1978 (0.2121)  auxiliary_vis: 0.2077 (0.3304)  loss_refine_obj: 0.7216 (1.1279)  loss_rel: 0.3330 (0.4061)  time: 1.5153 (1.5251)  data: 0.0102 (0.0157)  lr: 0.054984  max mem: 6391
2020-03-10 19:12:18,863 maskrcnn_benchmark INFO: eta: 21:02:29  iter: 400  loss: 1.5960 (2.0872)  auxiliary_ctx: 0.1907 (0.3322)  auxiliary_frq: 0.2075 (0.2110)  auxiliary_vis: 0.2314 (0.2775)  loss_refine_obj: 0.6432 (0.8979)  loss_rel: 0.3387 (0.3687)  time: 1.5182 (1.5272)  data: 0.0108 (0.0134)  lr: 0.098184  max mem: 6391
2020-03-10 19:17:23,407 maskrcnn_benchmark INFO: eta: 20:56:10  iter: 600  loss: 1.4464 (1.9272)  auxiliary_ctx: 0.1729 (0.2888)  auxiliary_frq: 0.2027 (0.2119)  auxiliary_vis: 0.2012 (0.2617)  loss_refine_obj: 0.6031 (0.8059)  loss_rel: 0.2760 (0.3589)  time: 1.5041 (1.5257)  data: 0.0112 (0.0126)  lr: 0.120000  max mem: 6391
2020-03-10 19:22:28,376 maskrcnn_benchmark INFO: eta: 20:50:54  iter: 800  loss: 1.4714 (1.8320)  auxiliary_ctx: 0.1850 (0.2651)  auxiliary_frq: 0.2076 (0.2125)  auxiliary_vis: 0.2034 (0.2520)  loss_refine_obj: 0.5255 (0.7517)  loss_rel: 0.3142 (0.3505)  time: 1.5244 (1.5255)  data: 0.0102 (0.0121)  lr: 0.120000  max mem: 6391
2020-03-10 19:27:33,124 maskrcnn_benchmark INFO: eta: 20:45:32  iter: 1000  loss: 1.5479 (1.7663)  auxiliary_ctx: 0.1936 (0.2493)  auxiliary_frq: 0.2139 (0.2123)  auxiliary_vis: 0.2184 (0.2442)  loss_refine_obj: 0.5685 (0.7171)  loss_rel: 0.3411 (0.3433)  time: 1.5139 (1.5251)  data: 0.0114 (0.0119)  lr: 0.120000  max mem: 6391
2020-03-10 19:32:38,482 maskrcnn_benchmark INFO: eta: 20:40:40  iter: 1200  loss: 1.4357 (1.7150)  auxiliary_ctx: 0.1679 (0.2373)  auxiliary_frq: 0.2153 (0.2118)  auxiliary_vis: 0.2020 (0.2376)  loss_refine_obj: 0.5652 (0.6922)  loss_rel: 0.2792 (0.3361)  time: 1.5204 (1.5254)  data: 0.0113 (0.0119)  lr: 0.120000  max mem: 6391
2020-03-10 19:37:42,992 maskrcnn_benchmark INFO: eta: 20:35:15  iter: 1400  loss: 1.3589 (1.6760)  auxiliary_ctx: 0.1489 (0.2286)  auxiliary_frq: 0.2094 (0.2115)  auxiliary_vis: 0.1823 (0.2327)  loss_refine_obj: 0.5186 (0.6724)  loss_rel: 0.2763 (0.3308)  time: 1.4949 (1.5250)  data: 0.0115 (0.0118)  lr: 0.120000  max mem: 6391
2020-03-10 19:42:48,455 maskrcnn_benchmark INFO: eta: 20:30:24  iter: 1600  loss: 1.4041 (1.6472)  auxiliary_ctx: 0.1651 (0.2223)  auxiliary_frq: 0.2156 (0.2114)  auxiliary_vis: 0.1922 (0.2293)  loss_refine_obj: 0.5290 (0.6574)  loss_rel: 0.2840 (0.3268)  time: 1.5361 (1.5253)  data: 0.0114 (0.0118)  lr: 0.120000  max mem: 6391
2020-03-10 19:47:53,680 maskrcnn_benchmark INFO: eta: 20:25:23  iter: 1800  loss: 1.3728 (1.6230)  auxiliary_ctx: 0.1628 (0.2170)  auxiliary_frq: 0.1968 (0.2112)  auxiliary_vis: 0.1708 (0.2264)  loss_refine_obj: 0.5730 (0.6449)  loss_rel: 0.2436 (0.3235)  time: 1.5280 (1.5254)  data: 0.0092 (0.0116)  lr: 0.120000  max mem: 6391
2020-03-10 19:52:58,245 maskrcnn_benchmark INFO: eta: 20:20:06  iter: 2000  loss: 1.3840 (1.6031)  auxiliary_ctx: 0.1733 (0.2128)  auxiliary_frq: 0.2045 (0.2110)  auxiliary_vis: 0.1898 (0.2241)  loss_refine_obj: 0.5496 (0.6348)  loss_rel: 0.2774 (0.3205)  time: 1.5175 (1.5251)  data: 0.0113 (0.0116)  lr: 0.120000  max mem: 6545
2020-03-10 19:52:58,247 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgdet/model_0002000.pth
2020-03-10 19:52:59,659 maskrcnn_benchmark INFO: Start validating
2020-03-10 19:52:59,678 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-10 20:13:40,448 maskrcnn_benchmark INFO: Total run time: 0:20:40.769551 (0.4963078203201294 s / img per device, on 2 devices)
2020-03-10 20:13:40,448 maskrcnn_benchmark INFO: Model inference time: 0:19:35.964693 (0.4703858770370483 s / img per device, on 2 devices)
2020-03-10 20:18:15,680 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.2754
====================================================================================================
SGG eval:   R @ 20: 0.2278;   R @ 50: 0.2892;   R @ 100: 0.3355;  for mode=sgdet, type=Recall(Main).
SGG eval: ngR @ 20: 0.2313; ngR @ 50: 0.2993; ngR @ 100: 0.3626;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0044;  for mode=sgdet, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0326;  mR @ 50: 0.0441;  mR @ 100: 0.0527;  for mode=sgdet, type=Mean Recall.
(above:0.0029) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0000) (attached to:0.0000) (behind:0.1031) (belonging to:0.0000) (between:0.0000) (carrying:0.0000) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.3664) (holding:0.2413) (in:0.1102) (in front of:0.0000) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1053) (of:0.2468) (on:0.4716) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2173) (says:0.0000) (sitting on:0.1065) (standing on:0.0000) (to:0.0000) (under:0.0077) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.6579) (wears:0.0000) (with:0.0000) 
====================================================================================================

2020-03-10 20:18:17,149 maskrcnn_benchmark INFO: Validation Result: 0.3355
2020-03-10 20:23:19,129 maskrcnn_benchmark INFO: eta: 1 day, 5:23:56  iter: 2200  loss: 1.3391 (1.5862)  auxiliary_ctx: 0.1776 (0.2094)  auxiliary_frq: 0.1992 (0.2109)  auxiliary_vis: 0.1992 (0.2221)  loss_refine_obj: 0.5066 (0.6258)  loss_rel: 0.2797 (0.3181)  time: 1.5048 (2.2142)  data: 0.0107 (0.7019)  lr: 0.120000  max mem: 6545
2020-03-10 20:28:22,372 maskrcnn_benchmark INFO: eta: 1 day, 4:30:25  iter: 2400  loss: 1.4653 (1.5711)  auxiliary_ctx: 0.1929 (0.2063)  auxiliary_frq: 0.2149 (0.2109)  auxiliary_vis: 0.2166 (0.2202)  loss_refine_obj: 0.5204 (0.6179)  loss_rel: 0.3054 (0.3158)  time: 1.5045 (2.1560)  data: 0.0105 (0.6443)  lr: 0.120000  max mem: 6545
2020-03-10 20:33:27,376 maskrcnn_benchmark INFO: eta: 1 day, 3:44:53  iter: 2600  loss: 1.5159 (1.5578)  auxiliary_ctx: 0.1842 (0.2036)  auxiliary_frq: 0.2190 (0.2109)  auxiliary_vis: 0.2155 (0.2186)  loss_refine_obj: 0.5450 (0.6112)  loss_rel: 0.3025 (0.3136)  time: 1.5227 (2.1075)  data: 0.0106 (0.5955)  lr: 0.120000  max mem: 6545
2020-03-10 20:38:32,682 maskrcnn_benchmark INFO: eta: 1 day, 3:05:13  iter: 2800  loss: 1.3757 (1.5474)  auxiliary_ctx: 0.1571 (0.2014)  auxiliary_frq: 0.2024 (0.2109)  auxiliary_vis: 0.1885 (0.2172)  loss_refine_obj: 0.5776 (0.6056)  loss_rel: 0.2430 (0.3122)  time: 1.5218 (2.0660)  data: 0.0084 (0.5537)  lr: 0.120000  max mem: 6545
2020-03-10 20:43:38,619 maskrcnn_benchmark INFO: eta: 1 day, 2:30:20  iter: 3000  loss: 1.4396 (1.5367)  auxiliary_ctx: 0.1742 (0.1993)  auxiliary_frq: 0.2153 (0.2108)  auxiliary_vis: 0.1979 (0.2157)  loss_refine_obj: 0.5267 (0.6006)  loss_rel: 0.2774 (0.3102)  time: 1.5354 (2.0302)  data: 0.0111 (0.5175)  lr: 0.120000  max mem: 6545
2020-03-10 20:48:42,316 maskrcnn_benchmark INFO: eta: 1 day, 1:58:37  iter: 3200  loss: 1.3241 (1.5263)  auxiliary_ctx: 0.1535 (0.1973)  auxiliary_frq: 0.2046 (0.2106)  auxiliary_vis: 0.1749 (0.2143)  loss_refine_obj: 0.4977 (0.5956)  loss_rel: 0.2592 (0.3084)  time: 1.5125 (1.9982)  data: 0.0113 (0.4859)  lr: 0.120000  max mem: 6545
2020-03-10 20:53:42,657 maskrcnn_benchmark INFO: eta: 1 day, 1:29:16  iter: 3400  loss: 1.3347 (1.5181)  auxiliary_ctx: 0.1544 (0.1958)  auxiliary_frq: 0.1973 (0.2107)  auxiliary_vis: 0.1823 (0.2132)  loss_refine_obj: 0.5002 (0.5913)  loss_rel: 0.2602 (0.3070)  time: 1.5103 (1.9690)  data: 0.0114 (0.4580)  lr: 0.120000  max mem: 6545
2020-03-10 20:58:43,150 maskrcnn_benchmark INFO: eta: 1 day, 1:02:39  iter: 3600  loss: 1.2788 (1.5109)  auxiliary_ctx: 0.1620 (0.1945)  auxiliary_frq: 0.2023 (0.2106)  auxiliary_vis: 0.1780 (0.2124)  loss_refine_obj: 0.5197 (0.5874)  loss_rel: 0.2798 (0.3060)  time: 1.5033 (1.9431)  data: 0.0115 (0.4332)  lr: 0.120000  max mem: 6545
2020-03-10 21:03:43,601 maskrcnn_benchmark INFO: eta: 1 day, 0:38:19  iter: 3800  loss: 1.3549 (1.5034)  auxiliary_ctx: 0.1599 (0.1930)  auxiliary_frq: 0.2085 (0.2104)  auxiliary_vis: 0.1861 (0.2113)  loss_refine_obj: 0.5226 (0.5842)  loss_rel: 0.2796 (0.3045)  time: 1.4851 (1.9199)  data: 0.0115 (0.4110)  lr: 0.120000  max mem: 6545
2020-03-10 21:08:43,931 maskrcnn_benchmark INFO: ---Total norm 0.78651 clip coef 6.35718-----------------
2020-03-10 21:08:43,940 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.36486, (torch.Size([4096, 12544]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.33750, (torch.Size([4096, 12544]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.31785, (torch.Size([4096, 4096]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.24208, (torch.Size([3072, 5136]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.20800, (torch.Size([151, 512]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.19281, (torch.Size([256, 1024, 3, 3]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.17998, (torch.Size([4096, 4096]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.12003, (torch.Size([4096, 1024]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.11951, (torch.Size([51, 4096]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.11737, (torch.Size([51, 4096]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.11111, (torch.Size([2048, 4808]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.10217, (torch.Size([2048, 4808]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.09628, (torch.Size([512, 1024]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.07528, (torch.Size([128, 2, 7, 7]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.07295, (torch.Size([256, 128, 3, 3]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.05232, (torch.Size([2560, 512]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.05167, (torch.Size([4096, 512]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.04137, (torch.Size([4096]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.03499, (torch.Size([512, 32]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.03010, (torch.Size([512]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.02108, (torch.Size([51]))
2020-03-10 21:08:43,941 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.02033, (torch.Size([51]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01849, (torch.Size([22801, 51]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01797, (torch.Size([2048, 512]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01717, (torch.Size([2048, 512]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01638, (torch.Size([256]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01595, (torch.Size([151, 200]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01524, (torch.Size([1024, 512]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.01404, (torch.Size([128]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.01382, (torch.Size([151]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.01316, (torch.Size([512, 1024]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.01109, (torch.Size([4096]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.01004, (torch.Size([512]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.00972, (torch.Size([3072]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00912, (torch.Size([151, 200]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00849, (torch.Size([128]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00840, (torch.Size([128, 32]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00840, (torch.Size([2048, 4424]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00826, (torch.Size([256]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00772, (torch.Size([2048, 4424]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00760, (torch.Size([2048]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00760, (torch.Size([2048]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00759, (torch.Size([2048]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00759, (torch.Size([2048]))
2020-03-10 21:08:43,942 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00704, (torch.Size([32, 9]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.00643, (torch.Size([2560]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00527, (torch.Size([4096]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00521, (torch.Size([128]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00429, (torch.Size([152, 200]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00411, (torch.Size([4096]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00389, (torch.Size([512]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00385, (torch.Size([1024]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00293, (torch.Size([256]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00278, (torch.Size([4096]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00194, (torch.Size([4096]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00188, (torch.Size([256]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00185, (torch.Size([128]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00138, (torch.Size([2048, 512]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00122, (torch.Size([2048, 512]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00119, (torch.Size([32]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00109, (torch.Size([32]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00055, (torch.Size([2048]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00055, (torch.Size([2048]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00051, (torch.Size([2048]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00051, (torch.Size([2048]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-10 21:08:43,943 maskrcnn_benchmark INFO: -------------------------------
2020-03-10 21:08:43,946 maskrcnn_benchmark INFO: eta: 1 day, 0:15:53  iter: 4000  loss: 1.3258 (1.4968)  auxiliary_ctx: 0.1567 (0.1917)  auxiliary_frq: 0.1947 (0.2102)  auxiliary_vis: 0.1809 (0.2104)  loss_refine_obj: 0.5391 (0.5813)  loss_rel: 0.2493 (0.3032)  time: 1.5043 (1.8990)  data: 0.0114 (0.3910)  lr: 0.120000  max mem: 6545
2020-03-10 21:08:43,948 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgdet/model_0004000.pth
2020-03-10 21:08:45,048 maskrcnn_benchmark INFO: Start validating
2020-03-10 21:08:45,067 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-10 21:29:00,746 maskrcnn_benchmark INFO: Total run time: 0:20:15.678434 (0.486271373462677 s / img per device, on 2 devices)
2020-03-10 21:29:00,746 maskrcnn_benchmark INFO: Model inference time: 0:19:13.819143 (0.46152765703201293 s / img per device, on 2 devices)
2020-03-10 21:33:22,258 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.2832
====================================================================================================
SGG eval:   R @ 20: 0.2193;   R @ 50: 0.2835;   R @ 100: 0.3308;  for mode=sgdet, type=Recall(Main).
SGG eval: ngR @ 20: 0.2229; ngR @ 50: 0.2962; ngR @ 100: 0.3582;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0000;  for mode=sgdet, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0341;  mR @ 50: 0.0441;  mR @ 100: 0.0541;  for mode=sgdet, type=Mean Recall.
(above:0.0057) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1398) (attached to:0.0000) (behind:0.1325) (belonging to:0.0000) (between:0.0000) (carrying:0.0175) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.3816) (holding:0.2213) (in:0.1105) (in front of:0.0010) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.0803) (of:0.1384) (on:0.4647) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2440) (says:0.0000) (sitting on:0.0575) (standing on:0.0000) (to:0.0000) (under:0.0128) (using:0.0000) (walking in:0.0000) (walking on:0.0040) (watching:0.0000) (wearing:0.6816) (wears:0.0000) (with:0.0116) 
====================================================================================================

2020-03-10 21:33:23,720 maskrcnn_benchmark INFO: Validation Result: 0.3308
2020-03-10 21:38:22,696 maskrcnn_benchmark INFO: eta: 1 day, 4:23:49  iter: 4200  loss: 1.4108 (1.4911)  auxiliary_ctx: 0.1848 (0.1906)  auxiliary_frq: 0.2137 (0.2101)  auxiliary_vis: 0.2257 (0.2097)  loss_refine_obj: 0.5110 (0.5784)  loss_rel: 0.2755 (0.3023)  time: 1.4801 (2.2321)  data: 0.0116 (0.7253)  lr: 0.120000  max mem: 6545
2020-03-10 21:43:23,899 maskrcnn_benchmark INFO: eta: 1 day, 3:51:17  iter: 4400  loss: 1.3445 (1.4859)  auxiliary_ctx: 0.1553 (0.1895)  auxiliary_frq: 0.1977 (0.2100)  auxiliary_vis: 0.1808 (0.2089)  loss_refine_obj: 0.5413 (0.5762)  loss_rel: 0.2667 (0.3013)  time: 1.5017 (2.1991)  data: 0.0116 (0.6928)  lr: 0.120000  max mem: 6545
2020-03-10 21:48:23,824 maskrcnn_benchmark INFO: eta: 1 day, 3:20:57  iter: 4600  loss: 1.3695 (1.4803)  auxiliary_ctx: 0.1732 (0.1885)  auxiliary_frq: 0.2216 (0.2099)  auxiliary_vis: 0.1962 (0.2081)  loss_refine_obj: 0.5171 (0.5735)  loss_rel: 0.2736 (0.3003)  time: 1.4862 (2.1687)  data: 0.0116 (0.6632)  lr: 0.120000  max mem: 6545
2020-03-10 21:53:22,979 maskrcnn_benchmark INFO: eta: 1 day, 2:52:36  iter: 4800  loss: 1.3244 (1.4769)  auxiliary_ctx: 0.1780 (0.1880)  auxiliary_frq: 0.2094 (0.2100)  auxiliary_vis: 0.1945 (0.2078)  loss_refine_obj: 0.4846 (0.5710)  loss_rel: 0.2768 (0.3001)  time: 1.4923 (2.1406)  data: 0.0114 (0.6361)  lr: 0.120000  max mem: 6545
2020-03-10 21:58:20,504 maskrcnn_benchmark INFO: eta: 1 day, 2:25:52  iter: 5000  loss: 1.3294 (1.4717)  auxiliary_ctx: 0.1631 (0.1870)  auxiliary_frq: 0.2001 (0.2099)  auxiliary_vis: 0.1909 (0.2071)  loss_refine_obj: 0.5229 (0.5687)  loss_rel: 0.2643 (0.2990)  time: 1.4942 (2.1145)  data: 0.0116 (0.6111)  lr: 0.120000  max mem: 6545
2020-03-10 22:03:19,202 maskrcnn_benchmark INFO: eta: 1 day, 2:00:59  iter: 5200  loss: 1.3066 (1.4671)  auxiliary_ctx: 0.1699 (0.1862)  auxiliary_frq: 0.2101 (0.2098)  auxiliary_vis: 0.2005 (0.2064)  loss_refine_obj: 0.4689 (0.5665)  loss_rel: 0.2594 (0.2981)  time: 1.4794 (2.0906)  data: 0.0117 (0.5880)  lr: 0.120000  max mem: 6545
2020-03-10 22:08:18,007 maskrcnn_benchmark INFO: eta: 1 day, 1:37:36  iter: 5400  loss: 1.3202 (1.4627)  auxiliary_ctx: 0.1645 (0.1855)  auxiliary_frq: 0.2088 (0.2097)  auxiliary_vis: 0.1913 (0.2059)  loss_refine_obj: 0.4926 (0.5644)  loss_rel: 0.2787 (0.2972)  time: 1.4836 (2.0685)  data: 0.0113 (0.5667)  lr: 0.120000  max mem: 6545
2020-03-10 22:13:16,583 maskrcnn_benchmark INFO: eta: 1 day, 1:15:29  iter: 5600  loss: 1.3203 (1.4582)  auxiliary_ctx: 0.1738 (0.1847)  auxiliary_frq: 0.2081 (0.2097)  auxiliary_vis: 0.1823 (0.2053)  loss_refine_obj: 0.4883 (0.5621)  loss_rel: 0.2532 (0.2964)  time: 1.4893 (2.0480)  data: 0.0114 (0.5468)  lr: 0.120000  max mem: 6545
2020-03-10 22:18:14,558 maskrcnn_benchmark INFO: eta: 1 day, 0:54:29  iter: 5800  loss: 1.3184 (1.4541)  auxiliary_ctx: 0.1571 (0.1841)  auxiliary_frq: 0.1953 (0.2096)  auxiliary_vis: 0.1882 (0.2048)  loss_refine_obj: 0.5201 (0.5599)  loss_rel: 0.2714 (0.2958)  time: 1.4855 (2.0287)  data: 0.0113 (0.5284)  lr: 0.120000  max mem: 6545
2020-03-10 22:23:13,591 maskrcnn_benchmark INFO: eta: 1 day, 0:34:41  iter: 6000  loss: 1.3374 (1.4513)  auxiliary_ctx: 0.1648 (0.1836)  auxiliary_frq: 0.2075 (0.2096)  auxiliary_vis: 0.1916 (0.2045)  loss_refine_obj: 0.4889 (0.5583)  loss_rel: 0.2751 (0.2953)  time: 1.4906 (2.0109)  data: 0.0108 (0.5111)  lr: 0.120000  max mem: 6719
2020-03-10 22:23:13,593 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgdet/model_0006000.pth
2020-03-10 22:23:14,701 maskrcnn_benchmark INFO: Start validating
2020-03-10 22:23:14,724 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-10 22:43:29,452 maskrcnn_benchmark INFO: Total run time: 0:20:14.727146 (0.4858908582687378 s / img per device, on 2 devices)
2020-03-10 22:43:29,452 maskrcnn_benchmark INFO: Model inference time: 0:19:17.262672 (0.46290506896972655 s / img per device, on 2 devices)
2020-03-10 22:47:56,319 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.2854
====================================================================================================
SGG eval:   R @ 20: 0.2371;   R @ 50: 0.3003;   R @ 100: 0.3433;  for mode=sgdet, type=Recall(Main).
SGG eval: ngR @ 20: 0.2428; ngR @ 50: 0.3168; ngR @ 100: 0.3766;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0044;  for mode=sgdet, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0345;  mR @ 50: 0.0457;  mR @ 100: 0.0553;  for mode=sgdet, type=Mean Recall.
(above:0.0100) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0348) (attached to:0.0000) (behind:0.1254) (belonging to:0.0000) (between:0.0000) (carrying:0.0307) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.4124) (holding:0.2085) (in:0.1157) (in front of:0.0000) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1536) (of:0.1588) (on:0.4761) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2396) (says:0.0000) (sitting on:0.0728) (standing on:0.0000) (to:0.0000) (under:0.0344) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.6767) (wears:0.0000) (with:0.0135) 
====================================================================================================

2020-03-10 22:47:57,772 maskrcnn_benchmark INFO: Validation Result: 0.3433
2020-03-10 22:52:55,672 maskrcnn_benchmark INFO: eta: 1 day, 3:10:27  iter: 6200  loss: 1.1972 (1.4473)  auxiliary_ctx: 0.1440 (0.1829)  auxiliary_frq: 0.1964 (0.2094)  auxiliary_vis: 0.1593 (0.2039)  loss_refine_obj: 0.4999 (0.5566)  loss_rel: 0.2166 (0.2945)  time: 1.4941 (2.2335)  data: 0.0105 (0.7344)  lr: 0.120000  max mem: 6719
2020-03-10 22:57:55,810 maskrcnn_benchmark INFO: eta: 1 day, 2:46:22  iter: 6400  loss: 1.3011 (1.4449)  auxiliary_ctx: 0.1477 (0.1824)  auxiliary_frq: 0.1906 (0.2094)  auxiliary_vis: 0.1615 (0.2036)  loss_refine_obj: 0.5189 (0.5554)  loss_rel: 0.2270 (0.2942)  time: 1.5039 (2.2106)  data: 0.0116 (0.7118)  lr: 0.120000  max mem: 6719
2020-03-10 23:02:56,395 maskrcnn_benchmark INFO: eta: 1 day, 2:23:29  iter: 6600  loss: 1.2737 (1.4417)  auxiliary_ctx: 0.1556 (0.1818)  auxiliary_frq: 0.1954 (0.2092)  auxiliary_vis: 0.1710 (0.2031)  loss_refine_obj: 0.4956 (0.5540)  loss_rel: 0.2357 (0.2935)  time: 1.4810 (2.1892)  data: 0.0116 (0.6906)  lr: 0.120000  max mem: 6719
2020-03-10 23:07:57,490 maskrcnn_benchmark INFO: eta: 1 day, 2:01:42  iter: 6800  loss: 1.3548 (1.4390)  auxiliary_ctx: 0.1577 (0.1813)  auxiliary_frq: 0.2109 (0.2092)  auxiliary_vis: 0.1878 (0.2027)  loss_refine_obj: 0.5035 (0.5530)  loss_rel: 0.2623 (0.2928)  time: 1.4982 (2.1690)  data: 0.0114 (0.6706)  lr: 0.120000  max mem: 6719
2020-03-10 23:12:57,604 maskrcnn_benchmark INFO: eta: 1 day, 1:40:47  iter: 7000  loss: 1.2975 (1.4358)  auxiliary_ctx: 0.1490 (0.1806)  auxiliary_frq: 0.1965 (0.2090)  auxiliary_vis: 0.1697 (0.2021)  loss_refine_obj: 0.5081 (0.5520)  loss_rel: 0.2460 (0.2920)  time: 1.5011 (2.1499)  data: 0.0116 (0.6517)  lr: 0.120000  max mem: 6719
2020-03-10 23:17:57,927 maskrcnn_benchmark INFO: eta: 1 day, 1:20:46  iter: 7200  loss: 1.3058 (1.4340)  auxiliary_ctx: 0.1665 (0.1803)  auxiliary_frq: 0.2060 (0.2090)  auxiliary_vis: 0.1793 (0.2019)  loss_refine_obj: 0.4952 (0.5510)  loss_rel: 0.2749 (0.2918)  time: 1.4771 (2.1319)  data: 0.0114 (0.6340)  lr: 0.120000  max mem: 6719
2020-03-10 23:22:58,028 maskrcnn_benchmark INFO: eta: 1 day, 1:01:33  iter: 7400  loss: 1.3565 (1.4320)  auxiliary_ctx: 0.1591 (0.1799)  auxiliary_frq: 0.1987 (0.2091)  auxiliary_vis: 0.1801 (0.2017)  loss_refine_obj: 0.5353 (0.5499)  loss_rel: 0.2457 (0.2914)  time: 1.4935 (2.1149)  data: 0.0115 (0.6171)  lr: 0.120000  max mem: 6719
2020-03-10 23:27:58,609 maskrcnn_benchmark INFO: eta: 1 day, 0:43:07  iter: 7600  loss: 1.3386 (1.4292)  auxiliary_ctx: 0.1664 (0.1794)  auxiliary_frq: 0.1974 (0.2089)  auxiliary_vis: 0.1956 (0.2012)  loss_refine_obj: 0.4982 (0.5490)  loss_rel: 0.2747 (0.2907)  time: 1.4932 (2.0988)  data: 0.0116 (0.6012)  lr: 0.120000  max mem: 6719
2020-03-10 23:32:58,915 maskrcnn_benchmark INFO: eta: 1 day, 0:25:21  iter: 7800  loss: 1.2795 (1.4267)  auxiliary_ctx: 0.1541 (0.1789)  auxiliary_frq: 0.1949 (0.2087)  auxiliary_vis: 0.1788 (0.2008)  loss_refine_obj: 0.4852 (0.5482)  loss_rel: 0.2454 (0.2901)  time: 1.4922 (2.0835)  data: 0.0114 (0.5861)  lr: 0.120000  max mem: 6719
2020-03-10 23:37:59,133 maskrcnn_benchmark INFO: ---Total norm 0.57402 clip coef 8.71052-----------------
2020-03-10 23:37:59,143 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.26613, (torch.Size([4096, 12544]))
2020-03-10 23:37:59,143 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.23610, (torch.Size([3072, 5136]))
2020-03-10 23:37:59,143 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.23019, (torch.Size([4096, 4096]))
2020-03-10 23:37:59,143 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.21304, (torch.Size([151, 512]))
2020-03-10 23:37:59,143 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.18579, (torch.Size([4096, 12544]))
2020-03-10 23:37:59,143 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.12165, (torch.Size([4096, 4096]))
2020-03-10 23:37:59,143 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.11708, (torch.Size([256, 1024, 3, 3]))
2020-03-10 23:37:59,143 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.10111, (torch.Size([51, 4096]))
2020-03-10 23:37:59,143 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.08656, (torch.Size([51, 4096]))
2020-03-10 23:37:59,143 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.06600, (torch.Size([4096, 1024]))
2020-03-10 23:37:59,143 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.06251, (torch.Size([2048, 4808]))
2020-03-10 23:37:59,143 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.06140, (torch.Size([2048, 4808]))
2020-03-10 23:37:59,143 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.05183, (torch.Size([2560, 512]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.04150, (torch.Size([512, 1024]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.03649, (torch.Size([256, 128, 3, 3]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.03406, (torch.Size([512, 32]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.03297, (torch.Size([128, 2, 7, 7]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.02997, (torch.Size([4096, 512]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.02214, (torch.Size([4096]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.01975, (torch.Size([151]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01589, (torch.Size([22801, 51]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.01367, (torch.Size([3072]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.01253, (torch.Size([151, 200]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.01229, (torch.Size([51]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.01187, (torch.Size([51]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.01062, (torch.Size([512]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01061, (torch.Size([1024, 512]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01049, (torch.Size([256]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.00991, (torch.Size([512]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.00855, (torch.Size([2048, 512]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.00802, (torch.Size([151, 200]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00792, (torch.Size([256]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00741, (torch.Size([152, 200]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.00711, (torch.Size([2560]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00700, (torch.Size([2048, 512]))
2020-03-10 23:37:59,144 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00694, (torch.Size([4096]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00612, (torch.Size([32, 9]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00563, (torch.Size([128]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00556, (torch.Size([128, 32]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00540, (torch.Size([128]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00501, (torch.Size([512, 1024]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00454, (torch.Size([2048, 4424]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00423, (torch.Size([4096]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00388, (torch.Size([128]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00381, (torch.Size([2048, 4424]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00274, (torch.Size([2048]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00274, (torch.Size([2048]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00267, (torch.Size([1024]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00248, (torch.Size([2048]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00248, (torch.Size([2048]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00236, (torch.Size([4096]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00230, (torch.Size([4096]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00214, (torch.Size([512]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00198, (torch.Size([128]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00185, (torch.Size([256]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00158, (torch.Size([32]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00147, (torch.Size([4096]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00129, (torch.Size([256]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00069, (torch.Size([32]))
2020-03-10 23:37:59,145 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00053, (torch.Size([2048, 512]))
2020-03-10 23:37:59,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00040, (torch.Size([2048, 512]))
2020-03-10 23:37:59,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00034, (torch.Size([2048]))
2020-03-10 23:37:59,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00034, (torch.Size([2048]))
2020-03-10 23:37:59,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00026, (torch.Size([2048]))
2020-03-10 23:37:59,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00026, (torch.Size([2048]))
2020-03-10 23:37:59,146 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-10 23:37:59,146 maskrcnn_benchmark INFO: -------------------------------
2020-03-10 23:37:59,148 maskrcnn_benchmark INFO: eta: 1 day, 0:08:13  iter: 8000  loss: 1.2772 (1.4245)  auxiliary_ctx: 0.1590 (0.1785)  auxiliary_frq: 0.1932 (0.2086)  auxiliary_vis: 0.1878 (0.2004)  loss_refine_obj: 0.4899 (0.5473)  loss_rel: 0.2569 (0.2896)  time: 1.5010 (2.0689)  data: 0.0115 (0.5717)  lr: 0.120000  max mem: 6719
2020-03-10 23:37:59,150 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgdet/model_0008000.pth
2020-03-10 23:38:00,277 maskrcnn_benchmark INFO: Start validating
2020-03-10 23:38:00,297 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-10 23:58:21,505 maskrcnn_benchmark INFO: Total run time: 0:20:21.208397 (0.488483358669281 s / img per device, on 2 devices)
2020-03-10 23:58:21,506 maskrcnn_benchmark INFO: Model inference time: 0:19:21.356328 (0.46454253129959105 s / img per device, on 2 devices)
2020-03-11 00:02:50,099 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.2831
====================================================================================================
SGG eval:   R @ 20: 0.2335;   R @ 50: 0.2990;   R @ 100: 0.3428;  for mode=sgdet, type=Recall(Main).
SGG eval: ngR @ 20: 0.2392; ngR @ 50: 0.3154; ngR @ 100: 0.3762;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0000;  for mode=sgdet, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0346;  mR @ 50: 0.0452;  mR @ 100: 0.0539;  for mode=sgdet, type=Mean Recall.
(above:0.0129) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0453) (attached to:0.0000) (behind:0.0502) (belonging to:0.0000) (between:0.0000) (carrying:0.2083) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.4083) (holding:0.2916) (in:0.1307) (in front of:0.0000) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1207) (of:0.1925) (on:0.4820) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.0000) (says:0.0000) (sitting on:0.0754) (standing on:0.0000) (to:0.0000) (under:0.0230) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.6529) (wears:0.0000) (with:0.0028) 
====================================================================================================

2020-03-11 00:02:51,658 maskrcnn_benchmark INFO: Validation Result: 0.3428
2020-03-11 00:07:51,135 maskrcnn_benchmark INFO: eta: 1 day, 1:58:25  iter: 8200  loss: 1.4105 (1.4231)  auxiliary_ctx: 0.1693 (0.1782)  auxiliary_frq: 0.2169 (0.2086)  auxiliary_vis: 0.1972 (0.2002)  loss_refine_obj: 0.5062 (0.5467)  loss_rel: 0.3032 (0.2894)  time: 1.4922 (2.2370)  data: 0.0116 (0.7401)  lr: 0.120000  max mem: 6719
2020-03-11 00:12:51,999 maskrcnn_benchmark INFO: eta: 1 day, 1:38:52  iter: 8400  loss: 1.2333 (1.4206)  auxiliary_ctx: 0.1476 (0.1777)  auxiliary_frq: 0.1880 (0.2084)  auxiliary_vis: 0.1652 (0.1997)  loss_refine_obj: 0.4975 (0.5460)  loss_rel: 0.2178 (0.2887)  time: 1.4916 (2.2195)  data: 0.0114 (0.7227)  lr: 0.120000  max mem: 6719
2020-03-11 00:17:53,958 maskrcnn_benchmark INFO: eta: 1 day, 1:20:05  iter: 8600  loss: 1.3917 (1.4188)  auxiliary_ctx: 0.1708 (0.1773)  auxiliary_frq: 0.2104 (0.2083)  auxiliary_vis: 0.2013 (0.1994)  loss_refine_obj: 0.5123 (0.5454)  loss_rel: 0.3010 (0.2883)  time: 1.4892 (2.2030)  data: 0.0114 (0.7062)  lr: 0.120000  max mem: 6719
2020-03-11 00:22:55,567 maskrcnn_benchmark INFO: eta: 1 day, 1:01:53  iter: 8800  loss: 1.3507 (1.4173)  auxiliary_ctx: 0.1618 (0.1771)  auxiliary_frq: 0.2004 (0.2082)  auxiliary_vis: 0.1903 (0.1992)  loss_refine_obj: 0.5403 (0.5448)  loss_rel: 0.2538 (0.2880)  time: 1.5219 (2.1872)  data: 0.0116 (0.6904)  lr: 0.120000  max mem: 6719
2020-03-11 00:27:56,790 maskrcnn_benchmark INFO: eta: 1 day, 0:44:15  iter: 9000  loss: 1.3008 (1.4158)  auxiliary_ctx: 0.1486 (0.1767)  auxiliary_frq: 0.2036 (0.2082)  auxiliary_vis: 0.1805 (0.1989)  loss_refine_obj: 0.4917 (0.5443)  loss_rel: 0.2632 (0.2877)  time: 1.4866 (2.1721)  data: 0.0115 (0.6753)  lr: 0.120000  max mem: 6719
2020-03-11 00:32:57,738 maskrcnn_benchmark INFO: eta: 1 day, 0:27:09  iter: 9200  loss: 1.2853 (1.4142)  auxiliary_ctx: 0.1471 (0.1765)  auxiliary_frq: 0.1930 (0.2081)  auxiliary_vis: 0.1604 (0.1986)  loss_refine_obj: 0.5364 (0.5438)  loss_rel: 0.2330 (0.2873)  time: 1.5156 (2.1576)  data: 0.0117 (0.6609)  lr: 0.120000  max mem: 6719
2020-03-11 00:37:57,608 maskrcnn_benchmark INFO: eta: 1 day, 0:10:29  iter: 9400  loss: 1.3257 (1.4132)  auxiliary_ctx: 0.1594 (0.1763)  auxiliary_frq: 0.2111 (0.2081)  auxiliary_vis: 0.1919 (0.1985)  loss_refine_obj: 0.5255 (0.5430)  loss_rel: 0.2890 (0.2873)  time: 1.4921 (2.1436)  data: 0.0115 (0.6471)  lr: 0.120000  max mem: 6719
2020-03-11 00:42:57,322 maskrcnn_benchmark INFO: eta: 23:54:17  iter: 9600  loss: 1.3784 (1.4124)  auxiliary_ctx: 0.1724 (0.1762)  auxiliary_frq: 0.2138 (0.2082)  auxiliary_vis: 0.1894 (0.1984)  loss_refine_obj: 0.5157 (0.5424)  loss_rel: 0.2647 (0.2872)  time: 1.4968 (2.1301)  data: 0.0115 (0.6338)  lr: 0.120000  max mem: 6719
2020-03-11 00:47:56,093 maskrcnn_benchmark INFO: eta: 23:38:29  iter: 9800  loss: 1.3286 (1.4106)  auxiliary_ctx: 0.1677 (0.1759)  auxiliary_frq: 0.2022 (0.2081)  auxiliary_vis: 0.1899 (0.1982)  loss_refine_obj: 0.4901 (0.5416)  loss_rel: 0.2810 (0.2868)  time: 1.4850 (2.1172)  data: 0.0114 (0.6211)  lr: 0.120000  max mem: 6719
2020-03-11 00:52:55,775 maskrcnn_benchmark INFO: eta: 23:23:11  iter: 10000  loss: 1.3039 (1.4088)  auxiliary_ctx: 0.1496 (0.1756)  auxiliary_frq: 0.1998 (0.2080)  auxiliary_vis: 0.1818 (0.1979)  loss_refine_obj: 0.4903 (0.5409)  loss_rel: 0.2544 (0.2864)  time: 1.4903 (2.1048)  data: 0.0116 (0.6089)  lr: 0.120000  max mem: 6719
2020-03-11 00:52:55,777 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgdet/model_0010000.pth
2020-03-11 00:52:56,941 maskrcnn_benchmark INFO: Start validating
2020-03-11 00:52:56,958 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-11 01:13:14,919 maskrcnn_benchmark INFO: Total run time: 0:20:17.961143 (0.4871844570159912 s / img per device, on 2 devices)
2020-03-11 01:13:14,919 maskrcnn_benchmark INFO: Model inference time: 0:19:17.760001 (0.4631040002822876 s / img per device, on 2 devices)
2020-03-11 01:17:42,685 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.2843
====================================================================================================
SGG eval:   R @ 20: 0.2270;   R @ 50: 0.2913;   R @ 100: 0.3359;  for mode=sgdet, type=Recall(Main).
SGG eval: ngR @ 20: 0.2322; ngR @ 50: 0.3079; ngR @ 100: 0.3710;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0000;  for mode=sgdet, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0305;  mR @ 50: 0.0415;  mR @ 100: 0.0509;  for mode=sgdet, type=Mean Recall.
(above:0.0229) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0551) (attached to:0.0000) (behind:0.0728) (belonging to:0.0000) (between:0.0000) (carrying:0.0000) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.4307) (holding:0.2951) (in:0.1452) (in front of:0.0021) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1064) (of:0.1463) (on:0.4608) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.0610) (says:0.0000) (sitting on:0.0724) (standing on:0.0000) (to:0.0000) (under:0.0102) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0000) (wearing:0.6634) (wears:0.0000) (with:0.0018) 
====================================================================================================

2020-03-11 01:17:44,142 maskrcnn_benchmark INFO: Validation Result: 0.3359
2020-03-11 01:17:44,143 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-03-11 01:22:43,935 maskrcnn_benchmark INFO: eta: 1 day, 0:45:04  iter: 10200  loss: 1.2620 (1.4064)  auxiliary_ctx: 0.1525 (0.1752)  auxiliary_frq: 0.1916 (0.2079)  auxiliary_vis: 0.1635 (0.1975)  loss_refine_obj: 0.4867 (0.5399)  loss_rel: 0.2118 (0.2859)  time: 1.5038 (2.2388)  data: 0.0118 (0.7432)  lr: 0.012000  max mem: 6719
2020-03-11 01:27:43,332 maskrcnn_benchmark INFO: eta: 1 day, 0:28:12  iter: 10400  loss: 1.2155 (1.4041)  auxiliary_ctx: 0.1448 (0.1749)  auxiliary_frq: 0.1971 (0.2079)  auxiliary_vis: 0.1672 (0.1972)  loss_refine_obj: 0.4640 (0.5388)  loss_rel: 0.2382 (0.2854)  time: 1.5008 (2.2246)  data: 0.0114 (0.7291)  lr: 0.012000  max mem: 6719
2020-03-11 01:32:41,252 maskrcnn_benchmark INFO: eta: 1 day, 0:11:41  iter: 10600  loss: 1.2357 (1.4012)  auxiliary_ctx: 0.1388 (0.1744)  auxiliary_frq: 0.1968 (0.2079)  auxiliary_vis: 0.1629 (0.1967)  loss_refine_obj: 0.4642 (0.5375)  loss_rel: 0.2458 (0.2847)  time: 1.4952 (2.2107)  data: 0.0115 (0.7155)  lr: 0.012000  max mem: 6719
2020-03-11 01:37:39,100 maskrcnn_benchmark INFO: eta: 23:55:35  iter: 10800  loss: 1.2382 (1.3982)  auxiliary_ctx: 0.1450 (0.1739)  auxiliary_frq: 0.2020 (0.2077)  auxiliary_vis: 0.1696 (0.1962)  loss_refine_obj: 0.4702 (0.5364)  loss_rel: 0.2384 (0.2840)  time: 1.4863 (2.1973)  data: 0.0113 (0.7025)  lr: 0.012000  max mem: 6719
2020-03-11 01:42:36,823 maskrcnn_benchmark INFO: eta: 23:39:53  iter: 11000  loss: 1.2480 (1.3960)  auxiliary_ctx: 0.1571 (0.1736)  auxiliary_frq: 0.2005 (0.2077)  auxiliary_vis: 0.1715 (0.1959)  loss_refine_obj: 0.4580 (0.5352)  loss_rel: 0.2470 (0.2836)  time: 1.4827 (2.1844)  data: 0.0114 (0.6899)  lr: 0.012000  max mem: 6719
2020-03-11 01:47:35,100 maskrcnn_benchmark INFO: eta: 23:24:36  iter: 11200  loss: 1.2060 (1.3934)  auxiliary_ctx: 0.1340 (0.1732)  auxiliary_frq: 0.1877 (0.2076)  auxiliary_vis: 0.1602 (0.1954)  loss_refine_obj: 0.4846 (0.5342)  loss_rel: 0.2151 (0.2830)  time: 1.4847 (2.1721)  data: 0.0114 (0.6778)  lr: 0.012000  max mem: 6719
2020-03-11 01:52:33,176 maskrcnn_benchmark INFO: eta: 23:09:40  iter: 11400  loss: 1.2086 (1.3911)  auxiliary_ctx: 0.1410 (0.1728)  auxiliary_frq: 0.1983 (0.2076)  auxiliary_vis: 0.1516 (0.1950)  loss_refine_obj: 0.4503 (0.5332)  loss_rel: 0.2189 (0.2824)  time: 1.4950 (2.1601)  data: 0.0114 (0.6661)  lr: 0.012000  max mem: 6719
2020-03-11 01:57:31,706 maskrcnn_benchmark INFO: eta: 22:55:06  iter: 11600  loss: 1.2023 (1.3884)  auxiliary_ctx: 0.1397 (0.1724)  auxiliary_frq: 0.1938 (0.2075)  auxiliary_vis: 0.1625 (0.1946)  loss_refine_obj: 0.4572 (0.5321)  loss_rel: 0.2254 (0.2817)  time: 1.4875 (2.1486)  data: 0.0113 (0.6548)  lr: 0.012000  max mem: 6719
2020-03-11 02:02:29,639 maskrcnn_benchmark INFO: eta: 22:40:49  iter: 11800  loss: 1.3144 (1.3861)  auxiliary_ctx: 0.1608 (0.1720)  auxiliary_frq: 0.2211 (0.2075)  auxiliary_vis: 0.1921 (0.1943)  loss_refine_obj: 0.4584 (0.5311)  loss_rel: 0.2930 (0.2812)  time: 1.4788 (2.1374)  data: 0.0107 (0.6439)  lr: 0.012000  max mem: 6719
2020-03-11 02:07:28,357 maskrcnn_benchmark INFO: ---Total norm 0.66073 clip coef 7.56741-----------------
2020-03-11 02:07:28,366 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.34407, (torch.Size([4096, 12544]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.28383, (torch.Size([4096, 4096]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.24132, (torch.Size([3072, 5136]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.22705, (torch.Size([151, 512]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.22380, (torch.Size([4096, 12544]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.13370, (torch.Size([256, 1024, 3, 3]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.12363, (torch.Size([4096, 4096]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.07995, (torch.Size([51, 4096]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.07502, (torch.Size([2048, 4808]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.07054, (torch.Size([51, 4096]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.07030, (torch.Size([4096, 1024]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.06308, (torch.Size([2048, 4808]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.05805, (torch.Size([2560, 512]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.05692, (torch.Size([512, 32]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.05539, (torch.Size([256, 128, 3, 3]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.04581, (torch.Size([512, 1024]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.04129, (torch.Size([128, 2, 7, 7]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.03988, (torch.Size([4096, 512]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.02278, (torch.Size([4096]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01794, (torch.Size([256]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.01778, (torch.Size([151]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.01715, (torch.Size([512]))
2020-03-11 02:07:28,367 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.01685, (torch.Size([1024, 512]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01487, (torch.Size([22801, 51]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01451, (torch.Size([151, 200]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01233, (torch.Size([512]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.01175, (torch.Size([151, 200]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.01109, (torch.Size([3072]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01036, (torch.Size([128]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01008, (torch.Size([2048, 512]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.00942, (torch.Size([4096]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00898, (torch.Size([256]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.00835, (torch.Size([51]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00824, (torch.Size([2048, 512]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.00762, (torch.Size([51]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00742, (torch.Size([32, 9]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00705, (torch.Size([128]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00698, (torch.Size([152, 200]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.00648, (torch.Size([2560]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00567, (torch.Size([4096]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00484, (torch.Size([128, 32]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00424, (torch.Size([2048, 4424]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00409, (torch.Size([128]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00382, (torch.Size([512, 1024]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00382, (torch.Size([4096]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00374, (torch.Size([1024]))
2020-03-11 02:07:28,368 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00369, (torch.Size([2048]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00369, (torch.Size([2048]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00356, (torch.Size([256]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00349, (torch.Size([2048]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00349, (torch.Size([2048]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00334, (torch.Size([2048, 4424]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00312, (torch.Size([4096]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00209, (torch.Size([128]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00195, (torch.Size([4096]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00188, (torch.Size([512]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00177, (torch.Size([32]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00136, (torch.Size([256]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00112, (torch.Size([32]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00042, (torch.Size([2048, 512]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00028, (torch.Size([2048]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00028, (torch.Size([2048]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00028, (torch.Size([2048, 512]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00020, (torch.Size([2048]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00020, (torch.Size([2048]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-11 02:07:28,369 maskrcnn_benchmark INFO: -------------------------------
2020-03-11 02:07:28,372 maskrcnn_benchmark INFO: eta: 22:26:54  iter: 12000  loss: 1.1440 (1.3836)  auxiliary_ctx: 0.1228 (0.1716)  auxiliary_frq: 0.1803 (0.2074)  auxiliary_vis: 0.1482 (0.1939)  loss_refine_obj: 0.4705 (0.5301)  loss_rel: 0.1938 (0.2806)  time: 1.4897 (2.1267)  data: 0.0113 (0.6334)  lr: 0.012000  max mem: 6719
2020-03-11 02:07:28,374 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgdet/model_0012000.pth
2020-03-11 02:07:29,481 maskrcnn_benchmark INFO: Start validating
2020-03-11 02:07:29,498 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-11 02:27:37,988 maskrcnn_benchmark INFO: Total run time: 0:20:08.489190 (0.483395675945282 s / img per device, on 2 devices)
2020-03-11 02:27:37,988 maskrcnn_benchmark INFO: Model inference time: 0:19:14.298160 (0.46171926403045654 s / img per device, on 2 devices)
2020-03-11 02:32:01,806 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.2927
====================================================================================================
SGG eval:   R @ 20: 0.2425;   R @ 50: 0.3061;   R @ 100: 0.3516;  for mode=sgdet, type=Recall(Main).
SGG eval: ngR @ 20: 0.2489; ngR @ 50: 0.3265; ngR @ 100: 0.3880;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0044;  for mode=sgdet, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0351;  mR @ 50: 0.0466;  mR @ 100: 0.0564;  for mode=sgdet, type=Mean Recall.
(above:0.0115) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0253) (attached to:0.0000) (behind:0.0668) (belonging to:0.0000) (between:0.0000) (carrying:0.0658) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.4249) (holding:0.3094) (in:0.1414) (in front of:0.0060) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1457) (of:0.1913) (on:0.4852) (on back of:0.0000) (over:0.0000) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.1146) (says:0.0000) (sitting on:0.1059) (standing on:0.0000) (to:0.0000) (under:0.0306) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0098) (wearing:0.6657) (wears:0.0000) (with:0.0184) 
====================================================================================================

2020-03-11 02:32:03,260 maskrcnn_benchmark INFO: Validation Result: 0.3516
2020-03-11 02:37:00,658 maskrcnn_benchmark INFO: eta: 23:29:22  iter: 12200  loss: 1.2307 (1.3814)  auxiliary_ctx: 0.1464 (0.1713)  auxiliary_frq: 0.2073 (0.2073)  auxiliary_vis: 0.1642 (0.1935)  loss_refine_obj: 0.4448 (0.5291)  loss_rel: 0.2590 (0.2801)  time: 1.4830 (2.2371)  data: 0.0114 (0.7441)  lr: 0.012000  max mem: 6719
2020-03-11 02:41:58,508 maskrcnn_benchmark INFO: eta: 23:14:21  iter: 12400  loss: 1.1985 (1.3791)  auxiliary_ctx: 0.1354 (0.1710)  auxiliary_frq: 0.1939 (0.2073)  auxiliary_vis: 0.1562 (0.1932)  loss_refine_obj: 0.4383 (0.5281)  loss_rel: 0.1989 (0.2796)  time: 1.4685 (2.2250)  data: 0.0114 (0.7323)  lr: 0.012000  max mem: 6719
2020-03-11 02:46:55,883 maskrcnn_benchmark INFO: eta: 22:59:38  iter: 12600  loss: 1.1568 (1.3773)  auxiliary_ctx: 0.1349 (0.1707)  auxiliary_frq: 0.1946 (0.2073)  auxiliary_vis: 0.1541 (0.1929)  loss_refine_obj: 0.4411 (0.5271)  loss_rel: 0.2109 (0.2792)  time: 1.4778 (2.2133)  data: 0.0114 (0.7208)  lr: 0.012000  max mem: 6719
2020-03-11 02:51:53,798 maskrcnn_benchmark INFO: eta: 22:45:15  iter: 12800  loss: 1.2030 (1.3751)  auxiliary_ctx: 0.1321 (0.1704)  auxiliary_frq: 0.1917 (0.2072)  auxiliary_vis: 0.1606 (0.1926)  loss_refine_obj: 0.4693 (0.5263)  loss_rel: 0.2134 (0.2786)  time: 1.4847 (2.2020)  data: 0.0114 (0.7097)  lr: 0.012000  max mem: 6719
2020-03-11 02:56:51,886 maskrcnn_benchmark INFO: eta: 22:31:09  iter: 13000  loss: 1.1320 (1.3728)  auxiliary_ctx: 0.1232 (0.1700)  auxiliary_frq: 0.1928 (0.2071)  auxiliary_vis: 0.1400 (0.1922)  loss_refine_obj: 0.4765 (0.5255)  loss_rel: 0.1938 (0.2781)  time: 1.4997 (2.1911)  data: 0.0109 (0.6990)  lr: 0.012000  max mem: 6719
2020-03-11 03:01:50,493 maskrcnn_benchmark INFO: eta: 22:17:22  iter: 13200  loss: 1.2144 (1.3706)  auxiliary_ctx: 0.1488 (0.1696)  auxiliary_frq: 0.1942 (0.2070)  auxiliary_vis: 0.1701 (0.1918)  loss_refine_obj: 0.4674 (0.5247)  loss_rel: 0.2245 (0.2775)  time: 1.4896 (2.1805)  data: 0.0099 (0.6885)  lr: 0.012000  max mem: 6731
2020-03-11 03:06:49,292 maskrcnn_benchmark INFO: eta: 22:03:51  iter: 13400  loss: 1.2040 (1.3687)  auxiliary_ctx: 0.1394 (0.1693)  auxiliary_frq: 0.2028 (0.2070)  auxiliary_vis: 0.1616 (0.1915)  loss_refine_obj: 0.4564 (0.5239)  loss_rel: 0.2551 (0.2770)  time: 1.4845 (2.1702)  data: 0.0095 (0.6784)  lr: 0.012000  max mem: 6731
2020-03-11 03:11:48,218 maskrcnn_benchmark INFO: eta: 21:50:35  iter: 13600  loss: 1.2454 (1.3669)  auxiliary_ctx: 0.1474 (0.1690)  auxiliary_frq: 0.2054 (0.2070)  auxiliary_vis: 0.1711 (0.1912)  loss_refine_obj: 0.4662 (0.5231)  loss_rel: 0.2555 (0.2766)  time: 1.4782 (2.1603)  data: 0.0113 (0.6686)  lr: 0.012000  max mem: 6731
2020-03-11 03:16:46,075 maskrcnn_benchmark INFO: eta: 21:37:31  iter: 13800  loss: 1.1962 (1.3650)  auxiliary_ctx: 0.1314 (0.1687)  auxiliary_frq: 0.1927 (0.2069)  auxiliary_vis: 0.1602 (0.1909)  loss_refine_obj: 0.4713 (0.5223)  loss_rel: 0.2178 (0.2761)  time: 1.4816 (2.1506)  data: 0.0113 (0.6591)  lr: 0.012000  max mem: 6731
2020-03-11 03:21:43,889 maskrcnn_benchmark INFO: eta: 21:24:40  iter: 14000  loss: 1.2417 (1.3635)  auxiliary_ctx: 0.1574 (0.1685)  auxiliary_frq: 0.2004 (0.2069)  auxiliary_vis: 0.1641 (0.1907)  loss_refine_obj: 0.4386 (0.5215)  loss_rel: 0.2411 (0.2759)  time: 1.4824 (2.1411)  data: 0.0115 (0.6498)  lr: 0.012000  max mem: 6731
2020-03-11 03:21:43,891 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgdet/model_0014000.pth
2020-03-11 03:21:45,005 maskrcnn_benchmark INFO: Start validating
2020-03-11 03:21:45,024 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-11 03:42:03,929 maskrcnn_benchmark INFO: Total run time: 0:20:18.904041 (0.487561616230011 s / img per device, on 2 devices)
2020-03-11 03:42:03,929 maskrcnn_benchmark INFO: Model inference time: 0:19:16.800733 (0.4627202933311462 s / img per device, on 2 devices)
2020-03-11 03:46:21,015 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.2958
====================================================================================================
SGG eval:   R @ 20: 0.2447;   R @ 50: 0.3103;   R @ 100: 0.3553;  for mode=sgdet, type=Recall(Main).
SGG eval: ngR @ 20: 0.2504; ngR @ 50: 0.3291; ngR @ 100: 0.3924;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0089;  for mode=sgdet, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0387;  mR @ 50: 0.0514;  mR @ 100: 0.0611;  for mode=sgdet, type=Mean Recall.
(above:0.0172) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0164) (attached to:0.0000) (behind:0.0897) (belonging to:0.0000) (between:0.0000) (carrying:0.1075) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.4040) (holding:0.3122) (in:0.1479) (in front of:0.0158) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1143) (of:0.2042) (on:0.4944) (on back of:0.0000) (over:0.0122) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2336) (says:0.0000) (sitting on:0.1222) (standing on:0.0000) (to:0.0000) (under:0.0281) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0490) (wearing:0.6750) (wears:0.0000) (with:0.0092) 
====================================================================================================

2020-03-11 03:46:22,462 maskrcnn_benchmark INFO: Validation Result: 0.3553
2020-03-11 03:51:19,518 maskrcnn_benchmark INFO: eta: 22:14:09  iter: 14200  loss: 1.1706 (1.3616)  auxiliary_ctx: 0.1447 (0.1682)  auxiliary_frq: 0.1926 (0.2068)  auxiliary_vis: 0.1647 (0.1903)  loss_refine_obj: 0.4754 (0.5208)  loss_rel: 0.2271 (0.2754)  time: 1.4844 (2.2360)  data: 0.0116 (0.7449)  lr: 0.012000  max mem: 6731
2020-03-11 03:56:19,739 maskrcnn_benchmark INFO: eta: 22:00:39  iter: 14400  loss: 1.1775 (1.3599)  auxiliary_ctx: 0.1402 (0.1680)  auxiliary_frq: 0.1979 (0.2068)  auxiliary_vis: 0.1572 (0.1900)  loss_refine_obj: 0.4619 (0.5201)  loss_rel: 0.2351 (0.2750)  time: 1.4902 (2.2258)  data: 0.0115 (0.7348)  lr: 0.012000  max mem: 6731
2020-03-11 04:01:18,119 maskrcnn_benchmark INFO: eta: 21:47:17  iter: 14600  loss: 1.2178 (1.3581)  auxiliary_ctx: 0.1439 (0.1677)  auxiliary_frq: 0.2037 (0.2068)  auxiliary_vis: 0.1578 (0.1898)  loss_refine_obj: 0.4474 (0.5193)  loss_rel: 0.2196 (0.2746)  time: 1.4861 (2.2158)  data: 0.0116 (0.7248)  lr: 0.012000  max mem: 6731
2020-03-11 04:06:17,510 maskrcnn_benchmark INFO: eta: 21:34:12  iter: 14800  loss: 1.2534 (1.3562)  auxiliary_ctx: 0.1510 (0.1674)  auxiliary_frq: 0.2008 (0.2067)  auxiliary_vis: 0.1613 (0.1894)  loss_refine_obj: 0.4861 (0.5186)  loss_rel: 0.2572 (0.2741)  time: 1.4927 (2.2060)  data: 0.0114 (0.7152)  lr: 0.012000  max mem: 6731
2020-03-11 04:11:15,304 maskrcnn_benchmark INFO: eta: 21:21:17  iter: 15000  loss: 1.2039 (1.3543)  auxiliary_ctx: 0.1464 (0.1671)  auxiliary_frq: 0.1999 (0.2067)  auxiliary_vis: 0.1675 (0.1891)  loss_refine_obj: 0.4404 (0.5178)  loss_rel: 0.2367 (0.2736)  time: 1.4737 (2.1965)  data: 0.0114 (0.7058)  lr: 0.012000  max mem: 6731
2020-03-11 04:16:13,903 maskrcnn_benchmark INFO: eta: 21:08:35  iter: 15200  loss: 1.1282 (1.3523)  auxiliary_ctx: 0.1385 (0.1668)  auxiliary_frq: 0.1890 (0.2066)  auxiliary_vis: 0.1512 (0.1887)  loss_refine_obj: 0.4864 (0.5170)  loss_rel: 0.1888 (0.2731)  time: 1.4839 (2.1872)  data: 0.0113 (0.6967)  lr: 0.012000  max mem: 6731
2020-03-11 04:21:13,020 maskrcnn_benchmark INFO: eta: 20:56:07  iter: 15400  loss: 1.2001 (1.3505)  auxiliary_ctx: 0.1374 (0.1665)  auxiliary_frq: 0.1946 (0.2065)  auxiliary_vis: 0.1489 (0.1884)  loss_refine_obj: 0.4649 (0.5163)  loss_rel: 0.2250 (0.2727)  time: 1.4980 (2.1782)  data: 0.0115 (0.6878)  lr: 0.012000  max mem: 6731
2020-03-11 04:26:10,975 maskrcnn_benchmark INFO: eta: 20:43:48  iter: 15600  loss: 1.1650 (1.3486)  auxiliary_ctx: 0.1373 (0.1663)  auxiliary_frq: 0.1944 (0.2065)  auxiliary_vis: 0.1548 (0.1881)  loss_refine_obj: 0.4311 (0.5155)  loss_rel: 0.2097 (0.2722)  time: 1.4867 (2.1694)  data: 0.0113 (0.6791)  lr: 0.012000  max mem: 6731
2020-03-11 04:31:10,112 maskrcnn_benchmark INFO: eta: 20:31:42  iter: 15800  loss: 1.2076 (1.3468)  auxiliary_ctx: 0.1507 (0.1660)  auxiliary_frq: 0.2011 (0.2064)  auxiliary_vis: 0.1629 (0.1878)  loss_refine_obj: 0.4289 (0.5148)  loss_rel: 0.2383 (0.2717)  time: 1.5046 (2.1609)  data: 0.0114 (0.6707)  lr: 0.012000  max mem: 6731
2020-03-11 04:36:08,773 maskrcnn_benchmark INFO: ---Total norm 1.26963 clip coef 3.93814-----------------
2020-03-11 04:36:08,782 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.60509, (torch.Size([4096, 12544]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.45574, (torch.Size([4096, 12544]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.40412, (torch.Size([4096, 4096]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.35020, (torch.Size([51, 4096]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.34225, (torch.Size([51, 4096]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.33947, (torch.Size([256, 1024, 3, 3]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.33270, (torch.Size([4096, 4096]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.29157, (torch.Size([4096, 1024]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.26218, (torch.Size([512, 32]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.20456, (torch.Size([2048, 4808]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.19152, (torch.Size([151, 512]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.19117, (torch.Size([3072, 5136]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.18262, (torch.Size([4096, 512]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.17745, (torch.Size([2048, 4808]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.13764, (torch.Size([512, 1024]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.11798, (torch.Size([256, 128, 3, 3]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.09326, (torch.Size([4096]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.09222, (torch.Size([128, 2, 7, 7]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.07401, (torch.Size([512]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.06188, (torch.Size([51]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.05272, (torch.Size([51]))
2020-03-11 04:36:08,783 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.05161, (torch.Size([1024, 512]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.04749, (torch.Size([2560, 512]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.03757, (torch.Size([512]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.03460, (torch.Size([22801, 51]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.03321, (torch.Size([256]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.02742, (torch.Size([151, 200]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.02450, (torch.Size([4096]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.02199, (torch.Size([2048, 512]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.01832, (torch.Size([256]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01770, (torch.Size([2048, 512]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.01750, (torch.Size([151]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.01747, (torch.Size([128]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.01406, (torch.Size([128]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01213, (torch.Size([4096]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01124, (torch.Size([2048]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01124, (torch.Size([2048]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01099, (torch.Size([1024]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.00995, (torch.Size([3072]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.00921, (torch.Size([151, 200]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00898, (torch.Size([2048]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00898, (torch.Size([2048]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00854, (torch.Size([4096]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00799, (torch.Size([32, 9]))
2020-03-11 04:36:08,784 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00744, (torch.Size([4096]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00740, (torch.Size([128, 32]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00606, (torch.Size([512, 1024]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00593, (torch.Size([256]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00570, (torch.Size([2048, 4424]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.00548, (torch.Size([2560]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00544, (torch.Size([2048, 4424]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00522, (torch.Size([152, 200]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00505, (torch.Size([128]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00324, (torch.Size([512]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00317, (torch.Size([32]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00310, (torch.Size([256]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00302, (torch.Size([128]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00257, (torch.Size([4096]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00209, (torch.Size([32]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00051, (torch.Size([2048, 512]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00047, (torch.Size([2048, 512]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00042, (torch.Size([2048]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00042, (torch.Size([2048]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00039, (torch.Size([2048]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00039, (torch.Size([2048]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-11 04:36:08,785 maskrcnn_benchmark INFO: -------------------------------
2020-03-11 04:36:08,788 maskrcnn_benchmark INFO: eta: 20:19:46  iter: 16000  loss: 1.2261 (1.3453)  auxiliary_ctx: 0.1477 (0.1658)  auxiliary_frq: 0.1989 (0.2064)  auxiliary_vis: 0.1665 (0.1876)  loss_refine_obj: 0.4638 (0.5142)  loss_rel: 0.2248 (0.2714)  time: 1.4948 (2.1526)  data: 0.0115 (0.6624)  lr: 0.012000  max mem: 6731
2020-03-11 04:36:08,790 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgdet/model_0016000.pth
2020-03-11 04:36:09,895 maskrcnn_benchmark INFO: Start validating
2020-03-11 04:36:09,915 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-11 04:56:27,775 maskrcnn_benchmark INFO: Total run time: 0:20:17.859580 (0.48714383182525633 s / img per device, on 2 devices)
2020-03-11 04:56:27,775 maskrcnn_benchmark INFO: Model inference time: 0:19:15.231275 (0.4620925101280212 s / img per device, on 2 devices)
2020-03-11 05:00:55,754 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.2950
====================================================================================================
SGG eval:   R @ 20: 0.2430;   R @ 50: 0.3073;   R @ 100: 0.3541;  for mode=sgdet, type=Recall(Main).
SGG eval: ngR @ 20: 0.2492; ngR @ 50: 0.3267; ngR @ 100: 0.3918;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0133;  for mode=sgdet, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0380;  mR @ 50: 0.0517;  mR @ 100: 0.0643;  for mode=sgdet, type=Mean Recall.
(above:0.0201) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0523) (attached to:0.0000) (behind:0.1069) (belonging to:0.0000) (between:0.0000) (carrying:0.0877) (covered in:0.0000) (covering:0.0000) (eating:0.0714) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.4380) (holding:0.3005) (in:0.1438) (in front of:0.0163) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1313) (of:0.1894) (on:0.4826) (on back of:0.0000) (over:0.0122) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2336) (says:0.0000) (sitting on:0.1222) (standing on:0.0000) (to:0.0000) (under:0.0289) (using:0.0000) (walking in:0.0000) (walking on:0.0638) (watching:0.0294) (wearing:0.6730) (wears:0.0000) (with:0.0123) 
====================================================================================================

2020-03-11 05:00:57,207 maskrcnn_benchmark INFO: Validation Result: 0.3541
2020-03-11 05:05:55,030 maskrcnn_benchmark INFO: eta: 20:59:44  iter: 16200  loss: 1.1984 (1.3440)  auxiliary_ctx: 0.1584 (0.1656)  auxiliary_frq: 0.2023 (0.2064)  auxiliary_vis: 0.1686 (0.1873)  loss_refine_obj: 0.4698 (0.5136)  loss_rel: 0.2363 (0.2711)  time: 1.4836 (2.2362)  data: 0.0114 (0.7463)  lr: 0.012000  max mem: 6731
2020-03-11 05:10:51,775 maskrcnn_benchmark INFO: eta: 20:47:09  iter: 16400  loss: 1.1629 (1.3425)  auxiliary_ctx: 0.1416 (0.1654)  auxiliary_frq: 0.2036 (0.2064)  auxiliary_vis: 0.1591 (0.1871)  loss_refine_obj: 0.4229 (0.5129)  loss_rel: 0.2232 (0.2708)  time: 1.4670 (2.2271)  data: 0.0113 (0.7373)  lr: 0.012000  max mem: 6731
2020-03-11 05:15:51,185 maskrcnn_benchmark INFO: eta: 20:34:50  iter: 16600  loss: 1.1937 (1.3410)  auxiliary_ctx: 0.1537 (0.1652)  auxiliary_frq: 0.1991 (0.2064)  auxiliary_vis: 0.1608 (0.1869)  loss_refine_obj: 0.4438 (0.5122)  loss_rel: 0.2249 (0.2704)  time: 1.4857 (2.2183)  data: 0.0114 (0.7286)  lr: 0.012000  max mem: 6731
2020-03-11 05:20:49,610 maskrcnn_benchmark INFO: eta: 20:22:39  iter: 16800  loss: 1.1938 (1.3395)  auxiliary_ctx: 0.1459 (0.1649)  auxiliary_frq: 0.2034 (0.2063)  auxiliary_vis: 0.1667 (0.1866)  loss_refine_obj: 0.4524 (0.5116)  loss_rel: 0.2355 (0.2700)  time: 1.5078 (2.2096)  data: 0.0113 (0.7200)  lr: 0.012000  max mem: 6731
2020-03-11 05:25:47,777 maskrcnn_benchmark INFO: eta: 20:10:38  iter: 17000  loss: 1.1878 (1.3381)  auxiliary_ctx: 0.1492 (0.1647)  auxiliary_frq: 0.2081 (0.2063)  auxiliary_vis: 0.1635 (0.1864)  loss_refine_obj: 0.4464 (0.5110)  loss_rel: 0.2253 (0.2697)  time: 1.4889 (2.2012)  data: 0.0113 (0.7117)  lr: 0.012000  max mem: 6731
2020-03-11 05:30:46,098 maskrcnn_benchmark INFO: eta: 19:58:47  iter: 17200  loss: 1.1558 (1.3367)  auxiliary_ctx: 0.1504 (0.1645)  auxiliary_frq: 0.1915 (0.2063)  auxiliary_vis: 0.1602 (0.1861)  loss_refine_obj: 0.4100 (0.5104)  loss_rel: 0.2136 (0.2693)  time: 1.4883 (2.1929)  data: 0.0113 (0.7035)  lr: 0.012000  max mem: 6731
2020-03-11 05:35:44,085 maskrcnn_benchmark INFO: eta: 19:47:05  iter: 17400  loss: 1.2286 (1.3354)  auxiliary_ctx: 0.1353 (0.1643)  auxiliary_frq: 0.2003 (0.2063)  auxiliary_vis: 0.1723 (0.1859)  loss_refine_obj: 0.4668 (0.5099)  loss_rel: 0.2381 (0.2690)  time: 1.4776 (2.1848)  data: 0.0111 (0.6956)  lr: 0.012000  max mem: 6731
2020-03-11 05:40:42,283 maskrcnn_benchmark INFO: eta: 19:35:33  iter: 17600  loss: 1.1558 (1.3339)  auxiliary_ctx: 0.1330 (0.1641)  auxiliary_frq: 0.2012 (0.2062)  auxiliary_vis: 0.1457 (0.1856)  loss_refine_obj: 0.4547 (0.5093)  loss_rel: 0.2145 (0.2686)  time: 1.4958 (2.1769)  data: 0.0113 (0.6878)  lr: 0.012000  max mem: 6731
2020-03-11 05:45:40,024 maskrcnn_benchmark INFO: eta: 19:24:08  iter: 17800  loss: 1.1405 (1.3322)  auxiliary_ctx: 0.1560 (0.1639)  auxiliary_frq: 0.2046 (0.2061)  auxiliary_vis: 0.1686 (0.1854)  loss_refine_obj: 0.4205 (0.5087)  loss_rel: 0.2174 (0.2682)  time: 1.4808 (2.1692)  data: 0.0113 (0.6802)  lr: 0.012000  max mem: 6731
2020-03-11 05:50:37,729 maskrcnn_benchmark INFO: eta: 19:12:52  iter: 18000  loss: 1.1646 (1.3310)  auxiliary_ctx: 0.1483 (0.1637)  auxiliary_frq: 0.2034 (0.2061)  auxiliary_vis: 0.1608 (0.1852)  loss_refine_obj: 0.4552 (0.5082)  loss_rel: 0.2200 (0.2679)  time: 1.4982 (2.1617)  data: 0.0112 (0.6728)  lr: 0.012000  max mem: 6731
2020-03-11 05:50:37,730 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgdet/model_0018000.pth
2020-03-11 05:50:38,828 maskrcnn_benchmark INFO: Start validating
2020-03-11 05:50:38,843 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-11 06:10:48,643 maskrcnn_benchmark INFO: Total run time: 0:20:09.800199 (0.48392007970809936 s / img per device, on 2 devices)
2020-03-11 06:10:48,643 maskrcnn_benchmark INFO: Model inference time: 0:19:15.744568 (0.4622978272438049 s / img per device, on 2 devices)
2020-03-11 06:15:14,647 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.2952
====================================================================================================
SGG eval:   R @ 20: 0.2453;   R @ 50: 0.3098;   R @ 100: 0.3573;  for mode=sgdet, type=Recall(Main).
SGG eval: ngR @ 20: 0.2502; ngR @ 50: 0.3277; ngR @ 100: 0.3929;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0044;  for mode=sgdet, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0405;  mR @ 50: 0.0525;  mR @ 100: 0.0631;  for mode=sgdet, type=Mean Recall.
(above:0.0172) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0126) (attached to:0.0000) (behind:0.0932) (belonging to:0.0000) (between:0.0000) (carrying:0.2478) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.4193) (holding:0.2939) (in:0.1581) (in front of:0.0060) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1511) (of:0.2281) (on:0.4883) (on back of:0.0000) (over:0.0122) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2068) (says:0.0000) (sitting on:0.1046) (standing on:0.0000) (to:0.0000) (under:0.0289) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0098) (wearing:0.6706) (wears:0.0000) (with:0.0055) 
====================================================================================================

2020-03-11 06:15:16,094 maskrcnn_benchmark INFO: Validation Result: 0.3573
2020-03-11 06:20:12,499 maskrcnn_benchmark INFO: eta: 19:44:46  iter: 18200  loss: 1.1880 (1.3300)  auxiliary_ctx: 0.1526 (0.1635)  auxiliary_frq: 0.2008 (0.2061)  auxiliary_vis: 0.1725 (0.1850)  loss_refine_obj: 0.4378 (0.5077)  loss_rel: 0.2392 (0.2677)  time: 1.4674 (2.2354)  data: 0.0115 (0.7467)  lr: 0.012000  max mem: 6731
2020-03-11 06:25:09,913 maskrcnn_benchmark INFO: eta: 19:33:02  iter: 18400  loss: 1.1130 (1.3286)  auxiliary_ctx: 0.1339 (0.1633)  auxiliary_frq: 0.1894 (0.2060)  auxiliary_vis: 0.1515 (0.1848)  loss_refine_obj: 0.4433 (0.5072)  loss_rel: 0.2020 (0.2673)  time: 1.4786 (2.2273)  data: 0.0114 (0.7387)  lr: 0.012000  max mem: 6731
2020-03-11 06:30:07,915 maskrcnn_benchmark INFO: eta: 19:21:27  iter: 18600  loss: 1.0549 (1.3275)  auxiliary_ctx: 0.1201 (0.1631)  auxiliary_frq: 0.1779 (0.2060)  auxiliary_vis: 0.1374 (0.1846)  loss_refine_obj: 0.4638 (0.5067)  loss_rel: 0.1511 (0.2670)  time: 1.4704 (2.2194)  data: 0.0115 (0.7309)  lr: 0.012000  max mem: 6731
2020-03-11 06:35:04,794 maskrcnn_benchmark INFO: eta: 19:09:59  iter: 18800  loss: 1.2860 (1.3265)  auxiliary_ctx: 0.1488 (0.1630)  auxiliary_frq: 0.2222 (0.2060)  auxiliary_vis: 0.1764 (0.1844)  loss_refine_obj: 0.4816 (0.5063)  loss_rel: 0.2507 (0.2668)  time: 1.4979 (2.2115)  data: 0.0114 (0.7233)  lr: 0.012000  max mem: 6731
2020-03-11 06:40:02,255 maskrcnn_benchmark INFO: eta: 18:58:41  iter: 19000  loss: 1.2018 (1.3253)  auxiliary_ctx: 0.1326 (0.1628)  auxiliary_frq: 0.1962 (0.2060)  auxiliary_vis: 0.1486 (0.1842)  loss_refine_obj: 0.4807 (0.5059)  loss_rel: 0.2211 (0.2665)  time: 1.5004 (2.2039)  data: 0.0112 (0.7158)  lr: 0.012000  max mem: 6731
2020-03-11 06:44:59,311 maskrcnn_benchmark INFO: eta: 18:47:29  iter: 19200  loss: 1.2344 (1.3243)  auxiliary_ctx: 0.1535 (0.1627)  auxiliary_frq: 0.2128 (0.2060)  auxiliary_vis: 0.1592 (0.1840)  loss_refine_obj: 0.4702 (0.5054)  loss_rel: 0.2392 (0.2662)  time: 1.4797 (2.1964)  data: 0.0113 (0.7084)  lr: 0.012000  max mem: 6731
2020-03-11 06:49:55,550 maskrcnn_benchmark INFO: eta: 18:36:24  iter: 19400  loss: 1.1655 (1.3229)  auxiliary_ctx: 0.1313 (0.1625)  auxiliary_frq: 0.1889 (0.2059)  auxiliary_vis: 0.1473 (0.1838)  loss_refine_obj: 0.4524 (0.5049)  loss_rel: 0.2217 (0.2659)  time: 1.4730 (2.1890)  data: 0.0109 (0.7012)  lr: 0.012000  max mem: 6731
2020-03-11 06:54:54,464 maskrcnn_benchmark INFO: eta: 18:25:31  iter: 19600  loss: 1.1526 (1.3216)  auxiliary_ctx: 0.1413 (0.1623)  auxiliary_frq: 0.2055 (0.2059)  auxiliary_vis: 0.1602 (0.1835)  loss_refine_obj: 0.4316 (0.5044)  loss_rel: 0.2183 (0.2655)  time: 1.4875 (2.1820)  data: 0.0111 (0.6942)  lr: 0.012000  max mem: 6731
2020-03-11 06:59:54,447 maskrcnn_benchmark INFO: eta: 18:14:47  iter: 19800  loss: 1.1067 (1.3202)  auxiliary_ctx: 0.1437 (0.1621)  auxiliary_frq: 0.1993 (0.2058)  auxiliary_vis: 0.1475 (0.1833)  loss_refine_obj: 0.4555 (0.5039)  loss_rel: 0.2027 (0.2652)  time: 1.4988 (2.1751)  data: 0.0111 (0.6873)  lr: 0.012000  max mem: 6731
2020-03-11 07:04:52,943 maskrcnn_benchmark INFO: ---Total norm 0.83660 clip coef 5.97659-----------------
2020-03-11 07:04:52,953 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.39227, (torch.Size([4096, 12544]))
2020-03-11 07:04:52,953 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.35088, (torch.Size([4096, 4096]))
2020-03-11 07:04:52,953 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.31833, (torch.Size([4096, 12544]))
2020-03-11 07:04:52,953 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.30948, (torch.Size([151, 512]))
2020-03-11 07:04:52,953 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.29950, (torch.Size([3072, 5136]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.15829, (torch.Size([256, 1024, 3, 3]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.14297, (torch.Size([4096, 4096]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.12808, (torch.Size([51, 4096]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.12748, (torch.Size([51, 4096]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.10138, (torch.Size([4096, 1024]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.09996, (torch.Size([2048, 4808]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.08298, (torch.Size([2048, 4808]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.08273, (torch.Size([512, 32]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.06991, (torch.Size([2560, 512]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.06714, (torch.Size([4096, 512]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.05871, (torch.Size([256, 128, 3, 3]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.05418, (torch.Size([512, 1024]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.04139, (torch.Size([151]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.03932, (torch.Size([128, 2, 7, 7]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.02380, (torch.Size([4096]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.02070, (torch.Size([1024, 512]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.02064, (torch.Size([51]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.01835, (torch.Size([51]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.01826, (torch.Size([512]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.01809, (torch.Size([512]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.01806, (torch.Size([3072]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.01591, (torch.Size([256]))
2020-03-11 07:04:52,954 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.01576, (torch.Size([151, 200]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.01512, (torch.Size([22801, 51]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.01202, (torch.Size([151, 200]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.01179, (torch.Size([2048, 512]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.01116, (torch.Size([32, 9]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.01073, (torch.Size([4096]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.00967, (torch.Size([2560]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.00904, (torch.Size([256]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.00830, (torch.Size([2048, 512]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00786, (torch.Size([128, 32]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.00779, (torch.Size([128]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00752, (torch.Size([152, 200]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.00738, (torch.Size([128]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00640, (torch.Size([2048, 4424]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00636, (torch.Size([4096]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00621, (torch.Size([128]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00590, (torch.Size([2048]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00590, (torch.Size([2048]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00565, (torch.Size([512, 1024]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00537, (torch.Size([1024]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00494, (torch.Size([2048, 4424]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00484, (torch.Size([4096]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.00483, (torch.Size([128]))
2020-03-11 07:04:52,955 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00471, (torch.Size([2048]))
2020-03-11 07:04:52,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00471, (torch.Size([2048]))
2020-03-11 07:04:52,956 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00401, (torch.Size([256]))
2020-03-11 07:04:52,956 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00370, (torch.Size([4096]))
2020-03-11 07:04:52,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00366, (torch.Size([512]))
2020-03-11 07:04:52,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00305, (torch.Size([32]))
2020-03-11 07:04:52,956 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00221, (torch.Size([4096]))
2020-03-11 07:04:52,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00182, (torch.Size([32]))
2020-03-11 07:04:52,956 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00163, (torch.Size([256]))
2020-03-11 07:04:52,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00058, (torch.Size([2048, 512]))
2020-03-11 07:04:52,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00055, (torch.Size([2048]))
2020-03-11 07:04:52,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00055, (torch.Size([2048]))
2020-03-11 07:04:52,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00039, (torch.Size([2048]))
2020-03-11 07:04:52,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00039, (torch.Size([2048]))
2020-03-11 07:04:52,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00037, (torch.Size([2048, 512]))
2020-03-11 07:04:52,956 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-11 07:04:52,956 maskrcnn_benchmark INFO: -------------------------------
2020-03-11 07:04:52,959 maskrcnn_benchmark INFO: eta: 18:04:07  iter: 20000  loss: 1.1506 (1.3190)  auxiliary_ctx: 0.1271 (0.1619)  auxiliary_frq: 0.1948 (0.2058)  auxiliary_vis: 0.1447 (0.1831)  loss_refine_obj: 0.4315 (0.5034)  loss_rel: 0.2078 (0.2649)  time: 1.4897 (2.1682)  data: 0.0111 (0.6805)  lr: 0.012000  max mem: 6731
2020-03-11 07:04:52,960 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgdet/model_0020000.pth
2020-03-11 07:04:54,100 maskrcnn_benchmark INFO: Start validating
2020-03-11 07:04:54,119 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-11 07:25:07,721 maskrcnn_benchmark INFO: Total run time: 0:20:13.602092 (0.4854408369064331 s / img per device, on 2 devices)
2020-03-11 07:25:07,721 maskrcnn_benchmark INFO: Model inference time: 0:19:14.648662 (0.4618594647407532 s / img per device, on 2 devices)
2020-03-11 07:29:31,176 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.2963
====================================================================================================
SGG eval:   R @ 20: 0.2437;   R @ 50: 0.3124;   R @ 100: 0.3597;  for mode=sgdet, type=Recall(Main).
SGG eval: ngR @ 20: 0.2519; ngR @ 50: 0.3331; ngR @ 100: 0.3999;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0178;  for mode=sgdet, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0400;  mR @ 50: 0.0527;  mR @ 100: 0.0630;  for mode=sgdet, type=Mean Recall.
(above:0.0229) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0918) (attached to:0.0000) (behind:0.0858) (belonging to:0.0000) (between:0.0000) (carrying:0.2215) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.4175) (holding:0.2951) (in:0.1586) (in front of:0.0355) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1523) (of:0.2116) (on:0.4923) (on back of:0.0000) (over:0.0122) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.0997) (says:0.0000) (sitting on:0.1169) (standing on:0.0000) (to:0.0000) (under:0.0281) (using:0.0000) (walking in:0.0000) (walking on:0.0000) (watching:0.0196) (wearing:0.6713) (wears:0.0000) (with:0.0172) 
====================================================================================================

2020-03-11 07:29:32,627 maskrcnn_benchmark INFO: Validation Result: 0.3597
2020-03-11 07:34:31,078 maskrcnn_benchmark INFO: eta: 18:29:57  iter: 20200  loss: 1.1871 (1.3177)  auxiliary_ctx: 0.1311 (0.1617)  auxiliary_frq: 0.1957 (0.2058)  auxiliary_vis: 0.1482 (0.1829)  loss_refine_obj: 0.4612 (0.5029)  loss_rel: 0.1951 (0.2645)  time: 1.5026 (2.2348)  data: 0.0115 (0.7472)  lr: 0.012000  max mem: 6731
2020-03-11 07:39:30,338 maskrcnn_benchmark INFO: eta: 18:18:55  iter: 20400  loss: 1.1463 (1.3167)  auxiliary_ctx: 0.1335 (0.1616)  auxiliary_frq: 0.1903 (0.2058)  auxiliary_vis: 0.1527 (0.1827)  loss_refine_obj: 0.4622 (0.5024)  loss_rel: 0.1943 (0.2643)  time: 1.4954 (2.2276)  data: 0.0117 (0.7399)  lr: 0.012000  max mem: 6731
2020-03-11 07:44:28,766 maskrcnn_benchmark INFO: eta: 18:08:00  iter: 20600  loss: 1.1271 (1.3154)  auxiliary_ctx: 0.1328 (0.1614)  auxiliary_frq: 0.1916 (0.2057)  auxiliary_vis: 0.1505 (0.1824)  loss_refine_obj: 0.4829 (0.5020)  loss_rel: 0.1928 (0.2639)  time: 1.4970 (2.2204)  data: 0.0115 (0.7329)  lr: 0.012000  max mem: 6731
2020-03-11 07:49:29,254 maskrcnn_benchmark INFO: eta: 17:57:14  iter: 20800  loss: 1.1220 (1.3143)  auxiliary_ctx: 0.1293 (0.1612)  auxiliary_frq: 0.1812 (0.2057)  auxiliary_vis: 0.1532 (0.1823)  loss_refine_obj: 0.4643 (0.5015)  loss_rel: 0.1921 (0.2636)  time: 1.5126 (2.2135)  data: 0.0117 (0.7259)  lr: 0.012000  max mem: 6731
2020-03-11 07:54:29,809 maskrcnn_benchmark INFO: eta: 17:46:35  iter: 21000  loss: 1.1428 (1.3132)  auxiliary_ctx: 0.1477 (0.1610)  auxiliary_frq: 0.1997 (0.2057)  auxiliary_vis: 0.1553 (0.1820)  loss_refine_obj: 0.4292 (0.5011)  loss_rel: 0.2100 (0.2633)  time: 1.5020 (2.2068)  data: 0.0115 (0.7191)  lr: 0.012000  max mem: 6731
2020-03-11 07:59:29,409 maskrcnn_benchmark INFO: eta: 17:36:01  iter: 21200  loss: 1.2465 (1.3121)  auxiliary_ctx: 0.1473 (0.1609)  auxiliary_frq: 0.2117 (0.2056)  auxiliary_vis: 0.1623 (0.1818)  loss_refine_obj: 0.4552 (0.5007)  loss_rel: 0.2440 (0.2630)  time: 1.4719 (2.2001)  data: 0.0093 (0.7124)  lr: 0.012000  max mem: 6731
2020-03-11 08:04:27,717 maskrcnn_benchmark INFO: eta: 17:25:32  iter: 21400  loss: 1.2081 (1.3112)  auxiliary_ctx: 0.1462 (0.1607)  auxiliary_frq: 0.1907 (0.2056)  auxiliary_vis: 0.1540 (0.1817)  loss_refine_obj: 0.4716 (0.5003)  loss_rel: 0.2351 (0.2628)  time: 1.4968 (2.1934)  data: 0.0093 (0.7059)  lr: 0.012000  max mem: 6731
2020-03-11 08:09:25,746 maskrcnn_benchmark INFO: eta: 17:15:08  iter: 21600  loss: 1.1406 (1.3101)  auxiliary_ctx: 0.1402 (0.1606)  auxiliary_frq: 0.1936 (0.2056)  auxiliary_vis: 0.1606 (0.1815)  loss_refine_obj: 0.4301 (0.4999)  loss_rel: 0.2116 (0.2626)  time: 1.4682 (2.1869)  data: 0.0093 (0.6994)  lr: 0.012000  max mem: 6731
2020-03-11 08:14:23,706 maskrcnn_benchmark INFO: eta: 17:04:51  iter: 21800  loss: 1.1488 (1.3091)  auxiliary_ctx: 0.1287 (0.1604)  auxiliary_frq: 0.1853 (0.2056)  auxiliary_vis: 0.1505 (0.1813)  loss_refine_obj: 0.4495 (0.4995)  loss_rel: 0.2200 (0.2623)  time: 1.4989 (2.1805)  data: 0.0094 (0.6931)  lr: 0.012000  max mem: 6731
2020-03-11 08:19:21,670 maskrcnn_benchmark INFO: eta: 16:54:39  iter: 22000  loss: 1.2372 (1.3083)  auxiliary_ctx: 0.1611 (0.1603)  auxiliary_frq: 0.2009 (0.2055)  auxiliary_vis: 0.1681 (0.1812)  loss_refine_obj: 0.4360 (0.4991)  loss_rel: 0.2385 (0.2621)  time: 1.4858 (2.1743)  data: 0.0093 (0.6869)  lr: 0.012000  max mem: 6731
2020-03-11 08:19:21,672 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgdet/model_0022000.pth
2020-03-11 08:19:22,786 maskrcnn_benchmark INFO: Start validating
2020-03-11 08:19:22,806 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-11 08:39:34,795 maskrcnn_benchmark INFO: Total run time: 0:20:11.988440 (0.484795375919342 s / img per device, on 2 devices)
2020-03-11 08:39:34,795 maskrcnn_benchmark INFO: Model inference time: 0:19:19.503802 (0.4638015208244324 s / img per device, on 2 devices)
2020-03-11 08:44:00,803 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.2961
====================================================================================================
SGG eval:   R @ 20: 0.2443;   R @ 50: 0.3128;   R @ 100: 0.3596;  for mode=sgdet, type=Recall(Main).
SGG eval: ngR @ 20: 0.2528; ngR @ 50: 0.3342; ngR @ 100: 0.3985;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0044;  zR @ 100: 0.0133;  for mode=sgdet, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0413;  mR @ 50: 0.0548;  mR @ 100: 0.0664;  for mode=sgdet, type=Mean Recall.
(above:0.0315) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0826) (attached to:0.0000) (behind:0.1159) (belonging to:0.0000) (between:0.0000) (carrying:0.1360) (covered in:0.0000) (covering:0.0000) (eating:0.0000) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.3999) (holding:0.3235) (in:0.1529) (in front of:0.0364) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1331) (of:0.2313) (on:0.4904) (on back of:0.0000) (over:0.0366) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2396) (says:0.0000) (sitting on:0.1227) (standing on:0.0000) (to:0.0000) (under:0.0255) (using:0.0000) (walking in:0.0000) (walking on:0.0447) (watching:0.0294) (wearing:0.6765) (wears:0.0000) (with:0.0119) 
====================================================================================================

2020-03-11 08:44:02,277 maskrcnn_benchmark INFO: Validation Result: 0.3596
2020-03-11 08:49:00,212 maskrcnn_benchmark INFO: eta: 17:15:27  iter: 22200  loss: 1.1773 (1.3073)  auxiliary_ctx: 0.1386 (0.1602)  auxiliary_frq: 0.2016 (0.2055)  auxiliary_vis: 0.1563 (0.1810)  loss_refine_obj: 0.4716 (0.4988)  loss_rel: 0.2016 (0.2618)  time: 1.4948 (2.2348)  data: 0.0106 (0.7475)  lr: 0.012000  max mem: 6731
2020-03-11 08:53:57,566 maskrcnn_benchmark INFO: eta: 17:04:55  iter: 22400  loss: 1.1500 (1.3063)  auxiliary_ctx: 0.1313 (0.1600)  auxiliary_frq: 0.2013 (0.2055)  auxiliary_vis: 0.1571 (0.1808)  loss_refine_obj: 0.4432 (0.4983)  loss_rel: 0.2248 (0.2616)  time: 1.4774 (2.2281)  data: 0.0113 (0.7409)  lr: 0.012000  max mem: 6731
2020-03-11 08:58:56,891 maskrcnn_benchmark INFO: eta: 16:54:32  iter: 22600  loss: 1.1559 (1.3053)  auxiliary_ctx: 0.1360 (0.1599)  auxiliary_frq: 0.1928 (0.2054)  auxiliary_vis: 0.1522 (0.1807)  loss_refine_obj: 0.4543 (0.4980)  loss_rel: 0.2054 (0.2613)  time: 1.4892 (2.2216)  data: 0.0113 (0.7345)  lr: 0.012000  max mem: 6731
2020-03-11 09:03:55,877 maskrcnn_benchmark INFO: eta: 16:44:15  iter: 22800  loss: 1.0759 (1.3044)  auxiliary_ctx: 0.1193 (0.1597)  auxiliary_frq: 0.1800 (0.2054)  auxiliary_vis: 0.1347 (0.1805)  loss_refine_obj: 0.4534 (0.4977)  loss_rel: 0.1812 (0.2611)  time: 1.4870 (2.2153)  data: 0.0113 (0.7281)  lr: 0.012000  max mem: 6731
2020-03-11 09:08:55,320 maskrcnn_benchmark INFO: eta: 16:34:03  iter: 23000  loss: 1.2044 (1.3037)  auxiliary_ctx: 0.1416 (0.1597)  auxiliary_frq: 0.1902 (0.2054)  auxiliary_vis: 0.1643 (0.1804)  loss_refine_obj: 0.4675 (0.4973)  loss_rel: 0.2311 (0.2609)  time: 1.4950 (2.2090)  data: 0.0113 (0.7219)  lr: 0.012000  max mem: 6731
2020-03-11 09:13:54,304 maskrcnn_benchmark INFO: eta: 16:23:56  iter: 23200  loss: 1.2546 (1.3027)  auxiliary_ctx: 0.1441 (0.1595)  auxiliary_frq: 0.2113 (0.2054)  auxiliary_vis: 0.1598 (0.1802)  loss_refine_obj: 0.4857 (0.4970)  loss_rel: 0.2525 (0.2607)  time: 1.5205 (2.2029)  data: 0.0114 (0.7157)  lr: 0.012000  max mem: 6731
2020-03-11 09:18:53,741 maskrcnn_benchmark INFO: eta: 16:13:55  iter: 23400  loss: 1.2691 (1.3020)  auxiliary_ctx: 0.1479 (0.1594)  auxiliary_frq: 0.2085 (0.2054)  auxiliary_vis: 0.1683 (0.1801)  loss_refine_obj: 0.4700 (0.4966)  loss_rel: 0.2427 (0.2605)  time: 1.4865 (2.1968)  data: 0.0114 (0.7097)  lr: 0.012000  max mem: 6731
2020-03-11 09:23:54,058 maskrcnn_benchmark INFO: eta: 16:04:00  iter: 23600  loss: 1.1459 (1.3011)  auxiliary_ctx: 0.1366 (0.1593)  auxiliary_frq: 0.1995 (0.2053)  auxiliary_vis: 0.1567 (0.1799)  loss_refine_obj: 0.4310 (0.4963)  loss_rel: 0.2243 (0.2602)  time: 1.4997 (2.1909)  data: 0.0111 (0.7038)  lr: 0.012000  max mem: 6731
2020-03-11 09:28:55,027 maskrcnn_benchmark INFO: eta: 15:54:11  iter: 23800  loss: 1.1602 (1.3003)  auxiliary_ctx: 0.1190 (0.1592)  auxiliary_frq: 0.1792 (0.2053)  auxiliary_vis: 0.1518 (0.1798)  loss_refine_obj: 0.4587 (0.4960)  loss_rel: 0.1997 (0.2600)  time: 1.5168 (2.1852)  data: 0.0114 (0.6980)  lr: 0.012000  max mem: 6731
2020-03-11 09:33:56,439 maskrcnn_benchmark INFO: ---Total norm 1.00779 clip coef 4.96136-----------------
2020-03-11 09:33:56,448 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.59052, (torch.Size([4096, 12544]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.38545, (torch.Size([4096, 12544]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.34803, (torch.Size([4096, 4096]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.29136, (torch.Size([256, 1024, 3, 3]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.22308, (torch.Size([4096, 4096]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.20820, (torch.Size([151, 512]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.20668, (torch.Size([3072, 5136]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.17864, (torch.Size([2048, 4808]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.15029, (torch.Size([51, 4096]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.14438, (torch.Size([4096, 1024]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.14357, (torch.Size([2048, 4808]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.14191, (torch.Size([51, 4096]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.12516, (torch.Size([256, 128, 3, 3]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.09476, (torch.Size([512, 32]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.09290, (torch.Size([4096, 512]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.08984, (torch.Size([128, 2, 7, 7]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.08289, (torch.Size([512, 1024]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.05086, (torch.Size([2560, 512]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.03224, (torch.Size([4096]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.03142, (torch.Size([1024, 512]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.03094, (torch.Size([256]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.02791, (torch.Size([512]))
2020-03-11 09:33:56,449 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.02575, (torch.Size([151, 200]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.02491, (torch.Size([22801, 51]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.02182, (torch.Size([128]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.02045, (torch.Size([2048, 512]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.02027, (torch.Size([128]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.02026, (torch.Size([512]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.01977, (torch.Size([51]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.01936, (torch.Size([51]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.01894, (torch.Size([128]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.01676, (torch.Size([4096]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.01473, (torch.Size([256]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.01294, (torch.Size([151]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.01280, (torch.Size([2048, 512]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.01191, (torch.Size([256]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.01074, (torch.Size([151, 200]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.00990, (torch.Size([3072]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00718, (torch.Size([4096]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.00696, (torch.Size([2048]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.00696, (torch.Size([2048]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.00688, (torch.Size([4096]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.00666, (torch.Size([1024]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00624, (torch.Size([152, 200]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00622, (torch.Size([4096]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.00525, (torch.Size([2048]))
2020-03-11 09:33:56,450 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.00525, (torch.Size([2048]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00510, (torch.Size([2048, 4424]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.00502, (torch.Size([32, 9]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.00501, (torch.Size([2560]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00481, (torch.Size([512, 1024]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00418, (torch.Size([2048, 4424]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00399, (torch.Size([128, 32]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00284, (torch.Size([256]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00245, (torch.Size([512]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00222, (torch.Size([128]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00215, (torch.Size([4096]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00140, (torch.Size([32]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00126, (torch.Size([32]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00047, (torch.Size([2048, 512]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00041, (torch.Size([2048]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00041, (torch.Size([2048]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00036, (torch.Size([2048]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00036, (torch.Size([2048]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00035, (torch.Size([2048, 512]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-11 09:33:56,451 maskrcnn_benchmark INFO: -------------------------------
2020-03-11 09:33:56,454 maskrcnn_benchmark INFO: eta: 15:44:27  iter: 24000  loss: 1.2882 (1.2995)  auxiliary_ctx: 0.1588 (0.1590)  auxiliary_frq: 0.2085 (0.2053)  auxiliary_vis: 0.1771 (0.1796)  loss_refine_obj: 0.4558 (0.4957)  loss_rel: 0.2549 (0.2598)  time: 1.5068 (2.1795)  data: 0.0113 (0.6923)  lr: 0.012000  max mem: 6731
2020-03-11 09:33:56,455 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgdet/model_0024000.pth
2020-03-11 09:33:57,584 maskrcnn_benchmark INFO: Start validating
2020-03-11 09:33:57,603 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-11 09:54:14,781 maskrcnn_benchmark INFO: Total run time: 0:20:17.177275 (0.48687091016769407 s / img per device, on 2 devices)
2020-03-11 09:54:14,781 maskrcnn_benchmark INFO: Model inference time: 0:19:16.628198 (0.46265127935409545 s / img per device, on 2 devices)
2020-03-11 09:58:35,121 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.2951
====================================================================================================
SGG eval:   R @ 20: 0.2473;   R @ 50: 0.3126;   R @ 100: 0.3593;  for mode=sgdet, type=Recall(Main).
SGG eval: ngR @ 20: 0.2531; ngR @ 50: 0.3315; ngR @ 100: 0.3950;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0133;  for mode=sgdet, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0448;  mR @ 50: 0.0584;  mR @ 100: 0.0726;  for mode=sgdet, type=Mean Recall.
(above:0.0229) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0572) (attached to:0.0000) (behind:0.1018) (belonging to:0.0000) (between:0.0000) (carrying:0.3070) (covered in:0.0000) (covering:0.0000) (eating:0.0714) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.4202) (holding:0.2827) (in:0.1549) (in front of:0.0151) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1593) (of:0.2165) (on:0.4828) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.4301) (says:0.0000) (sitting on:0.1200) (standing on:0.0022) (to:0.0000) (under:0.0302) (using:0.0000) (walking in:0.0000) (walking on:0.0027) (watching:0.0392) (wearing:0.6771) (wears:0.0000) (with:0.0119) 
====================================================================================================

2020-03-11 09:58:36,566 maskrcnn_benchmark INFO: Validation Result: 0.3593
2020-03-11 09:58:36,566 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-03-11 10:03:34,402 maskrcnn_benchmark INFO: eta: 16:01:02  iter: 24200  loss: 1.1464 (1.2985)  auxiliary_ctx: 0.1269 (0.1589)  auxiliary_frq: 0.1988 (0.2053)  auxiliary_vis: 0.1389 (0.1795)  loss_refine_obj: 0.4301 (0.4953)  loss_rel: 0.2122 (0.2595)  time: 1.4880 (2.2350)  data: 0.0113 (0.7478)  lr: 0.001200  max mem: 6731
2020-03-11 10:08:33,994 maskrcnn_benchmark INFO: eta: 15:51:00  iter: 24400  loss: 1.0914 (1.2974)  auxiliary_ctx: 0.1224 (0.1587)  auxiliary_frq: 0.1927 (0.2052)  auxiliary_vis: 0.1360 (0.1793)  loss_refine_obj: 0.4617 (0.4949)  loss_rel: 0.1801 (0.2593)  time: 1.5048 (2.2289)  data: 0.0113 (0.7418)  lr: 0.001200  max mem: 6731
2020-03-11 10:13:34,390 maskrcnn_benchmark INFO: eta: 15:41:04  iter: 24600  loss: 1.1288 (1.2963)  auxiliary_ctx: 0.1314 (0.1586)  auxiliary_frq: 0.1910 (0.2052)  auxiliary_vis: 0.1486 (0.1791)  loss_refine_obj: 0.4442 (0.4945)  loss_rel: 0.1874 (0.2590)  time: 1.5005 (2.2230)  data: 0.0113 (0.7358)  lr: 0.001200  max mem: 6731
2020-03-11 10:18:34,725 maskrcnn_benchmark INFO: eta: 15:31:13  iter: 24800  loss: 1.1471 (1.2952)  auxiliary_ctx: 0.1334 (0.1584)  auxiliary_frq: 0.1959 (0.2052)  auxiliary_vis: 0.1495 (0.1788)  loss_refine_obj: 0.4580 (0.4941)  loss_rel: 0.2159 (0.2586)  time: 1.4953 (2.2172)  data: 0.0113 (0.7300)  lr: 0.001200  max mem: 6731
2020-03-11 10:23:34,546 maskrcnn_benchmark INFO: eta: 15:21:26  iter: 25000  loss: 1.0869 (1.2941)  auxiliary_ctx: 0.1193 (0.1582)  auxiliary_frq: 0.1886 (0.2051)  auxiliary_vis: 0.1307 (0.1786)  loss_refine_obj: 0.4567 (0.4938)  loss_rel: 0.1683 (0.2583)  time: 1.5067 (2.2115)  data: 0.0113 (0.7242)  lr: 0.001200  max mem: 6731
2020-03-11 10:28:33,551 maskrcnn_benchmark INFO: eta: 15:11:43  iter: 25200  loss: 1.0801 (1.2932)  auxiliary_ctx: 0.1243 (0.1581)  auxiliary_frq: 0.1931 (0.2051)  auxiliary_vis: 0.1372 (0.1785)  loss_refine_obj: 0.4359 (0.4934)  loss_rel: 0.1955 (0.2581)  time: 1.4774 (2.2058)  data: 0.0109 (0.7186)  lr: 0.001200  max mem: 6731
2020-03-11 10:33:33,138 maskrcnn_benchmark INFO: eta: 15:02:04  iter: 25400  loss: 1.1740 (1.2922)  auxiliary_ctx: 0.1376 (0.1579)  auxiliary_frq: 0.2066 (0.2051)  auxiliary_vis: 0.1432 (0.1783)  loss_refine_obj: 0.4609 (0.4930)  loss_rel: 0.2211 (0.2578)  time: 1.4945 (2.2002)  data: 0.0093 (0.7130)  lr: 0.001200  max mem: 6731
2020-03-11 10:38:32,986 maskrcnn_benchmark INFO: eta: 14:52:31  iter: 25600  loss: 1.1373 (1.2913)  auxiliary_ctx: 0.1373 (0.1578)  auxiliary_frq: 0.1945 (0.2051)  auxiliary_vis: 0.1480 (0.1781)  loss_refine_obj: 0.4374 (0.4926)  loss_rel: 0.2067 (0.2576)  time: 1.4885 (2.1947)  data: 0.0096 (0.7075)  lr: 0.001200  max mem: 6731
2020-03-11 10:43:33,418 maskrcnn_benchmark INFO: eta: 14:43:02  iter: 25800  loss: 1.1401 (1.2905)  auxiliary_ctx: 0.1278 (0.1577)  auxiliary_frq: 0.1945 (0.2051)  auxiliary_vis: 0.1390 (0.1780)  loss_refine_obj: 0.4602 (0.4923)  loss_rel: 0.2070 (0.2574)  time: 1.5097 (2.1894)  data: 0.0107 (0.7021)  lr: 0.001200  max mem: 6731
2020-03-11 10:48:32,805 maskrcnn_benchmark INFO: eta: 14:33:36  iter: 26000  loss: 1.1289 (1.2896)  auxiliary_ctx: 0.1443 (0.1576)  auxiliary_frq: 0.1985 (0.2051)  auxiliary_vis: 0.1615 (0.1778)  loss_refine_obj: 0.4430 (0.4919)  loss_rel: 0.2120 (0.2572)  time: 1.4845 (2.1840)  data: 0.0116 (0.6968)  lr: 0.001200  max mem: 6731
2020-03-11 10:48:32,807 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgdet/model_0026000.pth
2020-03-11 10:48:33,965 maskrcnn_benchmark INFO: Start validating
2020-03-11 10:48:33,982 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-11 11:08:49,510 maskrcnn_benchmark INFO: Total run time: 0:20:15.527991 (0.4862111965179443 s / img per device, on 2 devices)
2020-03-11 11:08:49,511 maskrcnn_benchmark INFO: Model inference time: 0:19:17.184024 (0.4628736096382141 s / img per device, on 2 devices)
2020-03-11 11:13:18,492 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.2961
====================================================================================================
SGG eval:   R @ 20: 0.2467;   R @ 50: 0.3122;   R @ 100: 0.3590;  for mode=sgdet, type=Recall(Main).
SGG eval: ngR @ 20: 0.2541; ngR @ 50: 0.3336; ngR @ 100: 0.3976;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0000;  zR @ 100: 0.0133;  for mode=sgdet, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0433;  mR @ 50: 0.0569;  mR @ 100: 0.0709;  for mode=sgdet, type=Mean Recall.
(above:0.0287) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0380) (attached to:0.0000) (behind:0.1112) (belonging to:0.0000) (between:0.0000) (carrying:0.2939) (covered in:0.0000) (covering:0.0000) (eating:0.0714) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.4180) (holding:0.2853) (in:0.1580) (in front of:0.0163) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1493) (of:0.2092) (on:0.4865) (on back of:0.0000) (over:0.0366) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.3229) (says:0.0000) (sitting on:0.1226) (standing on:0.0022) (to:0.0000) (under:0.0366) (using:0.0000) (walking in:0.0000) (walking on:0.0193) (watching:0.0490) (wearing:0.6778) (wears:0.0000) (with:0.0135) 
====================================================================================================

2020-03-11 11:13:20,176 maskrcnn_benchmark INFO: Validation Result: 0.3590
2020-03-11 11:18:18,637 maskrcnn_benchmark INFO: eta: 14:46:45  iter: 26200  loss: 1.1504 (1.2887)  auxiliary_ctx: 0.1279 (0.1574)  auxiliary_frq: 0.1958 (0.2051)  auxiliary_vis: 0.1390 (0.1777)  loss_refine_obj: 0.4423 (0.4916)  loss_rel: 0.1968 (0.2570)  time: 1.4943 (2.2355)  data: 0.0111 (0.7483)  lr: 0.001200  max mem: 6731
2020-03-11 11:23:18,523 maskrcnn_benchmark INFO: eta: 14:37:06  iter: 26400  loss: 1.1353 (1.2878)  auxiliary_ctx: 0.1375 (0.1573)  auxiliary_frq: 0.2042 (0.2051)  auxiliary_vis: 0.1592 (0.1775)  loss_refine_obj: 0.4281 (0.4912)  loss_rel: 0.2174 (0.2567)  time: 1.4737 (2.2299)  data: 0.0113 (0.7427)  lr: 0.001200  max mem: 6731
2020-03-11 11:28:16,923 maskrcnn_benchmark INFO: eta: 14:27:30  iter: 26600  loss: 1.1574 (1.2869)  auxiliary_ctx: 0.1289 (0.1572)  auxiliary_frq: 0.2049 (0.2051)  auxiliary_vis: 0.1478 (0.1773)  loss_refine_obj: 0.4506 (0.4908)  loss_rel: 0.2170 (0.2565)  time: 1.4897 (2.2244)  data: 0.0111 (0.7372)  lr: 0.001200  max mem: 6731
2020-03-11 11:33:17,213 maskrcnn_benchmark INFO: eta: 14:18:00  iter: 26800  loss: 1.1623 (1.2860)  auxiliary_ctx: 0.1346 (0.1571)  auxiliary_frq: 0.2020 (0.2051)  auxiliary_vis: 0.1504 (0.1772)  loss_refine_obj: 0.4352 (0.4904)  loss_rel: 0.2226 (0.2562)  time: 1.4808 (2.2190)  data: 0.0113 (0.7318)  lr: 0.001200  max mem: 6731
2020-03-11 11:38:16,967 maskrcnn_benchmark INFO: eta: 14:08:34  iter: 27000  loss: 1.1643 (1.2851)  auxiliary_ctx: 0.1367 (0.1569)  auxiliary_frq: 0.2030 (0.2050)  auxiliary_vis: 0.1487 (0.1770)  loss_refine_obj: 0.4408 (0.4901)  loss_rel: 0.2235 (0.2560)  time: 1.4808 (2.2137)  data: 0.0113 (0.7265)  lr: 0.001200  max mem: 6731
2020-03-11 11:43:17,012 maskrcnn_benchmark INFO: eta: 13:59:11  iter: 27200  loss: 1.1267 (1.2842)  auxiliary_ctx: 0.1276 (0.1568)  auxiliary_frq: 0.1949 (0.2050)  auxiliary_vis: 0.1422 (0.1769)  loss_refine_obj: 0.4409 (0.4898)  loss_rel: 0.2090 (0.2558)  time: 1.4932 (2.2084)  data: 0.0115 (0.7212)  lr: 0.001200  max mem: 6731
2020-03-11 11:48:16,628 maskrcnn_benchmark INFO: eta: 13:49:53  iter: 27400  loss: 1.0676 (1.2832)  auxiliary_ctx: 0.1249 (0.1566)  auxiliary_frq: 0.1861 (0.2050)  auxiliary_vis: 0.1403 (0.1767)  loss_refine_obj: 0.4384 (0.4895)  loss_rel: 0.1912 (0.2555)  time: 1.5021 (2.2032)  data: 0.0115 (0.7160)  lr: 0.001200  max mem: 6731
2020-03-11 11:53:16,077 maskrcnn_benchmark INFO: eta: 13:40:37  iter: 27600  loss: 1.1641 (1.2825)  auxiliary_ctx: 0.1356 (0.1565)  auxiliary_frq: 0.1933 (0.2050)  auxiliary_vis: 0.1555 (0.1765)  loss_refine_obj: 0.4324 (0.4891)  loss_rel: 0.2126 (0.2553)  time: 1.4952 (2.1981)  data: 0.0114 (0.7109)  lr: 0.001200  max mem: 6731
2020-03-11 11:58:15,575 maskrcnn_benchmark INFO: eta: 13:31:26  iter: 27800  loss: 1.1773 (1.2817)  auxiliary_ctx: 0.1508 (0.1564)  auxiliary_frq: 0.2072 (0.2050)  auxiliary_vis: 0.1550 (0.1764)  loss_refine_obj: 0.4489 (0.4888)  loss_rel: 0.2290 (0.2551)  time: 1.4824 (2.1931)  data: 0.0113 (0.7059)  lr: 0.001200  max mem: 6731
2020-03-11 12:03:14,616 maskrcnn_benchmark INFO: ---Total norm 1.30725 clip coef 3.82481-----------------
2020-03-11 12:03:14,626 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.weight: 0.63929, (torch.Size([4096, 12544]))
2020-03-11 12:03:14,626 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.weight: 0.56931, (torch.Size([4096, 12544]))
2020-03-11 12:03:14,626 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.weight: 0.51598, (torch.Size([4096, 4096]))
2020-03-11 12:03:14,626 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.weight: 0.31434, (torch.Size([256, 1024, 3, 3]))
2020-03-11 12:03:14,626 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.weight: 0.28304, (torch.Size([4096, 4096]))
2020-03-11 12:03:14,626 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.weight: 0.28203, (torch.Size([51, 4096]))
2020-03-11 12:03:14,626 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0: 0.26647, (torch.Size([2048, 4808]))
2020-03-11 12:03:14,626 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.weight: 0.25224, (torch.Size([3072, 5136]))
2020-03-11 12:03:14,626 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.weight: 0.23825, (torch.Size([4096, 1024]))
2020-03-11 12:03:14,626 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.weight: 0.23710, (torch.Size([151, 512]))
2020-03-11 12:03:14,626 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.weight: 0.23626, (torch.Size([51, 4096]))
2020-03-11 12:03:14,626 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_ih_l0_reverse: 0.22472, (torch.Size([2048, 4808]))
2020-03-11 12:03:14,626 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.weight: 0.16686, (torch.Size([4096, 512]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.weight: 0.12642, (torch.Size([512, 1024]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.weight: 0.10924, (torch.Size([512, 32]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.weight: 0.10852, (torch.Size([256, 128, 3, 3]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.weight: 0.08393, (torch.Size([128, 2, 7, 7]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.weight: 0.05876, (torch.Size([2560, 512]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.weight: 0.05394, (torch.Size([1024, 512]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.2.bias: 0.05180, (torch.Size([4096]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_edge_h.bias: 0.04508, (torch.Size([512]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.ctx_compress.bias: 0.03964, (torch.Size([51]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.bias: 0.03497, (torch.Size([256]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.vis_compress.bias: 0.03426, (torch.Size([51]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed2.weight: 0.03304, (torch.Size([151, 200]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0: 0.02853, (torch.Size([2048, 512]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.spt_emb.0.bias: 0.02639, (torch.Size([512]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.weight_hh_l0_reverse: 0.02323, (torch.Size([2048, 512]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.freq_bias.obj_baseline.weight: 0.02313, (torch.Size([22801, 51]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc7.bias: 0.02283, (torch.Size([4096]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.weight: 0.02070, (torch.Size([128]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.out_obj.bias: 0.01920, (torch.Size([151]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.0.bias: 0.01556, (torch.Size([128]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.2.bias: 0.01518, (torch.Size([128]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_emb.bias : 0.01455, (torch.Size([1024]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0: 0.01451, (torch.Size([2048]))
2020-03-11 12:03:14,627 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0: 0.01451, (torch.Size([2048]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.6.weight: 0.01424, (torch.Size([256]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.post_cat.0.bias: 0.01401, (torch.Size([4096]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_embed1.weight: 0.01395, (torch.Size([151, 200]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_ih_l0_reverse: 0.01223, (torch.Size([2048]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.edge_ctx_rnn.bias_hh_l0_reverse: 0.01223, (torch.Size([2048]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.weight: 0.01123, (torch.Size([32, 9]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.input_linearity.bias: 0.01076, (torch.Size([3072]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.rect_conv.4.bias: 0.00959, (torch.Size([256]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc7.bias: 0.00953, (torch.Size([4096]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0_reverse: 0.00826, (torch.Size([2048, 4424]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.fc6.bias: 0.00816, (torch.Size([4096]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_ih_l0: 0.00779, (torch.Size([2048, 4424]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.weight: 0.00755, (torch.Size([512, 1024]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.obj_embed.weight: 0.00712, (torch.Size([152, 200]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.weight: 0.00618, (torch.Size([128, 32]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.decoder_rnn.state_linearity.bias: 0.00600, (torch.Size([2560]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.lin_obj_h.bias: 0.00391, (torch.Size([512]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.2.bias: 0.00344, (torch.Size([128]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.union_feature_extractor.feature_extractor.pooler.reduce_channel.0.bias: 0.00330, (torch.Size([256]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.box_feature_extractor.fc6.bias: 0.00328, (torch.Size([4096]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.bias: 0.00240, (torch.Size([32]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.1.weight: 0.00153, (torch.Size([32]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0_reverse: 0.00084, (torch.Size([2048, 512]))
2020-03-11 12:03:14,628 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.weight_hh_l0: 0.00064, (torch.Size([2048, 512]))
2020-03-11 12:03:14,629 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0_reverse: 0.00058, (torch.Size([2048]))
2020-03-11 12:03:14,629 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0_reverse: 0.00058, (torch.Size([2048]))
2020-03-11 12:03:14,629 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_ih_l0: 0.00056, (torch.Size([2048]))
2020-03-11 12:03:14,629 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.obj_ctx_rnn.bias_hh_l0: 0.00056, (torch.Size([2048]))
2020-03-11 12:03:14,629 maskrcnn_benchmark INFO: module.roi_heads.relation.predictor.context_layer.pos_embed.0.bias: 0.00000, (torch.Size([32]))
2020-03-11 12:03:14,629 maskrcnn_benchmark INFO: -------------------------------
2020-03-11 12:03:14,631 maskrcnn_benchmark INFO: eta: 13:22:18  iter: 28000  loss: 1.1039 (1.2809)  auxiliary_ctx: 0.1254 (0.1563)  auxiliary_frq: 0.1959 (0.2050)  auxiliary_vis: 0.1477 (0.1763)  loss_refine_obj: 0.4400 (0.4885)  loss_rel: 0.1845 (0.2549)  time: 1.5016 (2.1881)  data: 0.0114 (0.7009)  lr: 0.001200  max mem: 6731
2020-03-11 12:03:14,633 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /home/kaihua/checkpoints/upload_causal_motif_sgdet/model_0028000.pth
2020-03-11 12:03:15,726 maskrcnn_benchmark INFO: Start validating
2020-03-11 12:03:15,745 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_val dataset(5000 images).
2020-03-11 12:23:34,781 maskrcnn_benchmark INFO: Total run time: 0:20:19.036236 (0.48761449422836306 s / img per device, on 2 devices)
2020-03-11 12:23:34,782 maskrcnn_benchmark INFO: Model inference time: 0:19:15.271307 (0.462108522605896 s / img per device, on 2 devices)
2020-03-11 12:27:59,399 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.2955
====================================================================================================
SGG eval:   R @ 20: 0.2472;   R @ 50: 0.3132;   R @ 100: 0.3597;  for mode=sgdet, type=Recall(Main).
SGG eval: ngR @ 20: 0.2537; ngR @ 50: 0.3340; ngR @ 100: 0.3991;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0000;  zR @ 50: 0.0044;  zR @ 100: 0.0133;  for mode=sgdet, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0416;  mR @ 50: 0.0554;  mR @ 100: 0.0685;  for mode=sgdet, type=Mean Recall.
(above:0.0315) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.0468) (attached to:0.0000) (behind:0.1013) (belonging to:0.0000) (between:0.0000) (carrying:0.2149) (covered in:0.0000) (covering:0.0000) (eating:0.0714) (flying in:0.0000) (for:0.0000) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.4222) (holding:0.3157) (in:0.1568) (in front of:0.0148) (laying on:0.0000) (looking at:0.0000) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1488) (of:0.2094) (on:0.4898) (on back of:0.0000) (over:0.0244) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2693) (says:0.0000) (sitting on:0.1226) (standing on:0.0022) (to:0.0000) (under:0.0315) (using:0.0000) (walking in:0.0000) (walking on:0.0135) (watching:0.0490) (wearing:0.6745) (wears:0.0000) (with:0.0135) 
====================================================================================================

2020-03-11 12:28:00,845 maskrcnn_benchmark INFO: Validation Result: 0.3597
2020-03-11 12:28:00,845 maskrcnn_benchmark INFO: Trigger Schedule Decay, RL has been reduced by factor 0.1
2020-03-11 12:28:00,845 maskrcnn_benchmark INFO: Trigger MAX_DECAY_STEP at iteration 28000.
2020-03-11 12:28:01,173 maskrcnn_benchmark INFO: Total training time: 17:25:53.197688 (1.2551 s / it)
2020-03-11 12:28:02,517 maskrcnn_benchmark INFO: Start evaluation on VG_stanford_filtered_with_attribute_test dataset(26446 images).
2020-03-11 14:15:59,718 maskrcnn_benchmark INFO: Total run time: 1:47:57.200044 (0.48984345790794087 s / img per device, on 2 devices)
2020-03-11 14:15:59,718 maskrcnn_benchmark INFO: Model inference time: 1:42:45.101501 (0.4662407548562992 s / img per device, on 2 devices)
2020-03-11 14:42:41,319 maskrcnn_benchmark INFO: 
====================================================================================================
Detection evaluation mAp=0.2949
====================================================================================================
SGG eval:   R @ 20: 0.2542;   R @ 50: 0.3245;   R @ 100: 0.3726;  for mode=sgdet, type=Recall(Main).
SGG eval: ngR @ 20: 0.2662; ngR @ 50: 0.3564; ngR @ 100: 0.4267;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:  zR @ 20: 0.0002;  zR @ 50: 0.0008;  zR @ 100: 0.0024;  for mode=sgdet, type=Zero Shot Recall.
SGG eval:  mR @ 20: 0.0436;  mR @ 50: 0.0583;  mR @ 100: 0.0708;  for mode=sgdet, type=Mean Recall.
(above:0.0277) (across:0.0000) (against:0.0000) (along:0.0000) (and:0.0000) (at:0.1063) (attached to:0.0000) (behind:0.1898) (belonging to:0.0000) (between:0.0000) (carrying:0.0887) (covered in:0.0000) (covering:0.0000) (eating:0.0265) (flying in:0.0000) (for:0.0027) (from:0.0000) (growing on:0.0000) (hanging from:0.0000) (has:0.4943) (holding:0.3874) (in:0.1525) (in front of:0.0063) (laying on:0.0000) (looking at:0.0080) (lying on:0.0000) (made of:0.0000) (mounted on:0.0000) (near:0.1248) (of:0.3476) (on:0.4251) (on back of:0.0000) (over:0.0124) (painted on:0.0000) (parked on:0.0000) (part of:0.0000) (playing:0.0000) (riding:0.2290) (says:0.0000) (sitting on:0.1032) (standing on:0.0004) (to:0.0000) (under:0.0876) (using:0.0302) (walking in:0.0000) (walking on:0.0027) (watching:0.0000) (wearing:0.6746) (wears:0.0000) (with:0.0135) 
====================================================================================================

